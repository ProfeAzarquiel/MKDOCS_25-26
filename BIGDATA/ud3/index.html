
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Sitio para englobar los contenidos teórico/prácticos de varios del os módulos profesionales impartidos en la especialidad de Informática del IES Azarquiel.">
      
      
        <meta name="author" content="Lorenzo LV">
      
      
        <link rel="canonical" href="https://profeazarquiel.github.io/MKDOCS_25-26/BIGDATA/ud3/">
      
      
        <link rel="prev" href="../ud2/">
      
      
        <link rel="next" href="../../WEB/indexw/">
      
      
        
      
      
      <link rel="icon" href="../../img/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>UD3. Ecosistema Hadoop - MATERIALES INFORMÁTICA IES AZARQUIEL</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="deep-orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#apache-hadoop" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="MATERIALES INFORMÁTICA IES AZARQUIEL" class="md-header__button md-logo" aria-label="MATERIALES INFORMÁTICA IES AZARQUIEL" data-md-component="logo">
      
  <img src="../../img/logo2.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MATERIALES INFORMÁTICA IES AZARQUIEL
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              UD3. Ecosistema Hadoop
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="deep-orange"  aria-label="Cambiar a modo oscuro"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Cambiar a modo oscuro" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="deep-orange"  aria-label="Cambiar a modo claro"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Cambiar a modo claro" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="MATERIALES INFORMÁTICA IES AZARQUIEL" class="md-nav__button md-logo" aria-label="MATERIALES INFORMÁTICA IES AZARQUIEL" data-md-component="logo">
      
  <img src="../../img/logo2.png" alt="logo">

    </a>
    MATERIALES INFORMÁTICA IES AZARQUIEL
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    INICIO
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    COMPUTACIÓN EN LA NUBE
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    COMPUTACIÓN EN LA NUBE
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/indexc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Indice
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/ud0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD0. Libros de referencia
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/ud1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD1. Infraestructura de Red
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/ud2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD2. Infraestructura Cloud
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/ud3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD3. Virtualización
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/ud4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD4. Docker
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/ud5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD5. Kubernetes
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    BIGDATA APLICADO
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    BIGDATA APLICADO
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../indexb/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Indice
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ud0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD0. Libros de referencia
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ud1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD1. Introducción a BigData
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ud2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD2. Ingesta de Datos
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    UD3. Ecosistema Hadoop
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    UD3. Ecosistema Hadoop
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#arquitectura-basica" class="md-nav__link">
    <span class="md-ellipsis">
      
        ARQUITECTURA BÁSICA
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#instalacion-de-apache-ambari-sobre-docker" class="md-nav__link">
    <span class="md-ellipsis">
      
        INSTALACIÓN DE APACHE AMBARI SOBRE DOCKER
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuracion-de-hadoop-desde-ambari" class="md-nav__link">
    <span class="md-ellipsis">
      
        CONFIGURACIÓN DE HADOOP DESDE AMBARI
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    DISEÑO WEB
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    DISEÑO WEB
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../WEB/indexw/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Indice
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../WEB/ud0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD0. Libros de referencia
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../WEB/ud1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD1. Principios del Diseño
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../WEB/ud2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD2. Maquetación CSS
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../WEB/ud3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD3. Preprocesadores CSS
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    PYTHON
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    PYTHON
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PYTHON/indexp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Indice
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PYTHON/ud0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD0. Libros de referencia
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PYTHON/ud1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD1. Fundamentos
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PYTHON/ud2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD2. Análisis de Datos
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PYTHON/ud3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD3. Creación de APIs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#arquitectura-basica" class="md-nav__link">
    <span class="md-ellipsis">
      
        ARQUITECTURA BÁSICA
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#instalacion-de-apache-ambari-sobre-docker" class="md-nav__link">
    <span class="md-ellipsis">
      
        INSTALACIÓN DE APACHE AMBARI SOBRE DOCKER
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuracion-de-hadoop-desde-ambari" class="md-nav__link">
    <span class="md-ellipsis">
      
        CONFIGURACIÓN DE HADOOP DESDE AMBARI
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="apache-hadoop">APACHE HADOOP</h1>
<p>Hadoop es un proyecto open source que aglutina una serie de herramientas para el procesamiento distribuido de grandes conjuntos de datos a través de clústers de ordenadores utilizando modelos de programación sencillos.</p>
<figure>
    <img alt="Hadoop Logo" src="https://upload.wikimedia.org/wikipedia/commons/0/0e/Hadoop_logo.svg" width="450" />
    <small><figcaption>Logo Apache Hadoop</figcaption></small>
</figure>
<h2 id="arquitectura-basica">ARQUITECTURA BÁSICA</h2>
<ul>
<li><strong>COMMON UTILITIES</strong>: conjunto de librerias y ficheros necesarios para ejecutar Haddop.</li>
<li><strong>YARN</strong>: gestor de recursos, se encarga de repartir los recursos disponibles en cada nodo entre las distitnas aplicaciones.</li>
<li><strong>HDFS</strong>: sistema de archivos distribuidos instalado en los distintos nodos del cluster y va almacenando mediante replicación los datos.</li>
<li><strong>MapReduce</strong>: son los procesos implementados en código por el usuario, para procesar los datos.</li>
</ul>
<p><img alt="Hadoop Arquitecture" src="https://media.geeksforgeeks.org/wp-content/uploads/20250628162844186405/Hadoop_architecture.webp" /></p>
<p>Si queremos empezar a utilizar Hadoop y todo su ecosistema, disponemos de diversas distribuciones con toda la arquitectura, herramientas y configuración ya preparadas. Las más reseñables son:</p>
<ul>
<li><strong>EMR de AWS</strong> (Amazon Elastic MapReduce)</li>
<li><strong>CDP de Cloudera</strong>: es la evolución de CDH y HDP (antiguas distribuciones de código abierto de Apache Hadoop y otros proyectos relacionados, actualmente sin soporte). Cloudera ofrecia estas distribuciones de forma gratuita, cosa que ya no sucede con CDP, pero aún se puede descargar la MV de HDP en el siguiente <a href="https://archive.cloudera.com/hwx-sandbox/hdp/hdp-3.0.1/HDP_3.0.1_virtualbox_181205.ova">enlace</a>.</li>
<li><strong>Azure HDInsight</strong> de Microsoft.</li>
<li><strong>DataProc</strong> de Google.</li>
</ul>
<p>Nosotros vamos a usar una <strong><code>Apache Ambari</code></strong>, proyecto dedicado a simplificar la administración, aprovisionamiento, la gestión y la monitorización de clústeres Apache Hadoop; proporcionando una interfaz web de administración intuitiva y fácil de usar.</p>
<div class="admonition quote">
<p class="admonition-title">No todo el monte es Orégano <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M23 7v6h-2V7m0 8h2v2h-2M12 2a2 2 0 0 0-2 2 2 2 0 0 0 0 .29C7.12 5.14 5 7.82 5 11v6l-2 2v1h18v-1l-2-2v-6c0-3.18-2.12-5.86-5-6.71A2 2 0 0 0 14 4a2 2 0 0 0-2-2m-2 19a2 2 0 0 0 2 2 2 2 0 0 0 2-2Z"/></svg></span></p>
<p>Hadoop facilita el trabajo con grandes volúmenes de datos, pero montar un clúster funcional no es una cosa trivial. Existen gestores de clústers que hacen las cosas un poco más sencillas (como <em>Apache Ambari</em> o <em>Apache Mesos</em>), aunque la tendencia es utilizar una solución cloud que nos evita toda la instalación y configuración.</p>
</div>
<h3 id="hdfs"><strong>HDFS</strong></h3>
<p>Es la capa de almacenamiento de Hadoop o lo que es lo mismo, un sistema de ficheros distribuido, con gran tolerancia a fallos, facil de escalar de forma incremental y capaz de almacenar grandes volúmenes de datos.</p>
<p>Su funcionamiento se basa en repartir los datos entre todos los nodos del clúster, dividiendo los ficheros en bloques y almacenando copias duplicadas en diferentes nodos. Por defecto cada bloque se replica en 3 nodos distintos (esto se conoce como <strong>factor de replicación</strong>).</p>
<p>Está planteado para escribir los datos una vez y leerlos muchas veces, <strong>Write Once, Read Many</strong> (WORM). Además, una vez escritos, los datos son inmutables; es decir, cada fichero de HDFS solo permite añadir contenido (append-only) o eliminar el fichero completo.</p>
<div class="admonition tip">
<p class="admonition-title">Modificación de datos en HDFS</p>
<p>Tanto <strong>HBase</strong> como <strong>Hive</strong> ofrecen una capa por encima de HDFS para dar soporte a la modificación de los datos, como en cualquier base de datos.</p>
</div>
<h4 id="tipos-de-nodos"><strong>Tipos de Nodos</strong></h4>
<p>En HDFS vamos a distinguir 2 tipos de máquinas o roles:</p>
<ul>
<li>
<p><strong>Namenode</strong>: actúa como máster y almacena todos los metadatos necesarios para construir el sistema de ficheros a partir de sus bloques. Tiene control sobre dónde están todos los bloques.</p>
</li>
<li>
<p><strong>Datanode</strong>: son los nodos esclavo, se limitan a almacenar los bloques que componen cada fichero.</p>
</li>
</ul>
<h4 id="los-bloques"><strong>Los Bloques</strong></h4>
<p>Un bloque es la cantidad mínima de datos que puede ser leída o escrita en HDFS, su tamaño predeterminado son 128 MB.</p>
<p>Todos los ficheros en HDFS estan divididos en bloques, por lo que si subimos un fichero de 600MB, se dividirá en 5 bloques de 128MB, que se distribuirán por todos los nodos de datos del clúster.</p>
<p>Además, a través del factor de replicación (por defecto 3), cada bloque se almacena varias veces en diferentes nodos. Así que finalmente, nuestro archivo de 600MB estará repartido en 15 bloques entre todos los nodos del clúster.</p>
<figure>
    <img alt="Replicación HDFS" src="https://substackcdn.com/image/fetch/$s_!_cKl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8321d7f4-8e50-4990-a3c2-169c33106c5c_582x394.png" width="400" />
    <small><figcaption>División y replicación HDFS</figcaption></small>
</figure>
<h3 id="yarn-yet-another-resource-negotiator"><strong>YARN</strong> (Yet Another Resource Negotiator)</h3>
<p>Este framework proporciona un <strong>planificador de recursos</strong> desvinculado de los trabajos que se encuentran en ejecución en el clúster, ya que <strong>separa</strong> la <strong>gestión de recursos</strong> y la <strong>planificación y monitorización</strong><em> de trabajos. Lo que hace posible tener un gestor global (Resource Manager) por cluster y un Application Master por aplicación (considerando aplicación tanto un único </em>job<em>, como un conjunto de </em>jobs* cíclicos).</p>
<p>Se divide en <strong>tres componentes principales</strong>: un Resource Manager, múltiples Node Manager y varios ApplicationMaster.</p>
<p>El Resource Manager y el Node Manager componen el framework de computación de datos. En concreto, el ResourceManager controla el arranque de la aplicación, siendo la autoridad que orquesta los recursos entre todas las aplicaciones del sistema. A su vez, tendremos tantos NodeManager como datanodes tenga nuestro clúster, siendo responsables de gestionar y monitorizar los recursos de cada nodo (CPU, memoria, disco y red) y reportar estos datos al Resource Manager.</p>
<p>El Application Master es una librería específica encargada de negociar los recursos con el ResourceManager y de trabajar con los Node Manager para ejecutar y monitorizar las tareas.</p>
<p>Finalmente, en nuestro clúster, tendremos corriendo un Job History Server encargado de archivar los fichero de log de los jobs. Aunque es un proceso opcional, se recomienda su uso para monitorizar los jobs ejecutados.</p>
<figure>
    <img alt="YARN Architecture" src="../../img/yarn_schema.png" width="600" />
    <small><figcaption>Arquitectura YARN</figcaption></small>
</figure>
<h3 id="map-reduce"><strong>MAP-REDUCE</strong></h3>
<p>Hadoop MapReduce es un paradigma de procesamiento de datos caracterizado por dividirse en dos fases o pasos diferenciados: Map y Reduce. Estos subprocesos asociados a la tarea se ejecutan de manera distribuida, en diferentes nodos de procesamiento o esclavos. Para controlar y gestionar su ejecución, existe un proceso Master o Job Tracker. También es el encargado de aceptar los nuevos trabajos enviados al sistema por los clientes. Los resultados del procesamiento se pueden almacenar en el mismo sistema de almacenamiento o bien en una base de datos o sistema externo.</p>
<h4 id="fases-de-hadoop-mapreduce"><strong>Fases de Hadoop MapReduce</strong></h4>
<p><strong>Map</strong>: se ejecuta en subtareas llamadas mappers. Estos componentes son los responsables de generar pares clave-valor filtrando, agrupando, ordenando o transformando los datos originales. Los pares de datos intermedios, no se almacenan en HDFS.</p>
<p><strong>Shuffle</strong>: puede no ser necesaria. Es el paso intermedio entre Map y reduce que ayuda a recoger los datos y ordenarlos de manera conveniente para el procesamiento. Con esta fase, se pretende agregar las ocurrencias repetidas en cada uno de los mappers.</p>
<p><strong>Reduce</strong>: gestiona la agregación de los valores producidos por todos los mappers del sistema (o por la fase shuffle) de tipo clave-valor en función de su clave. Por último, cada reducer genera su fichero de salida de forma independiente, generalmente escrito en HDFS.</p>
<figure>
    <img alt="Fases MapReduce" src="https://storage.googleapis.com/algodailyrandomassets/curriculum/systems-design/map-reduce/example.png" />
    <small><figcaption>Fases MapReduce</figcaption></small>
</figure>
<h4 id="limitaciones"><strong>Limitaciones</strong></h4>
<p>MapReduce es la implementación básica de un framework de procesamiento en paralelo para cargas big data, por lo que al final tiene ciertas limitaciones como, por ejemplo, hasta que la fase map completa su procesamiento, los reducers no empiezan a ejecutarse; o que no se puede controlar su orden de ejecución.</p>
<p>Es por ello, que existen alternativas como Apache Spark, Apache Hive o Pig; las cuales mantienen los principales puntos de MapReduce, pero son capaces de usar HDFS de manera más eficiente. La que resalta más entre el resto es <strong>SPARK</strong>, la cual veremos más adelante.</p>
<p><em><small><a href="https://aitor-medrano.github.io/iabd/">Fuente 1: Aitor Medrano</a></small></em>, <em><small><a href="https://aprenderbigdata.com/hadoop/">Fuente 2: Oscar Fernández</a></small></em></p>
<h2 id="instalacion-de-apache-ambari-sobre-docker">INSTALACIÓN DE APACHE AMBARI SOBRE DOCKER</h2>
<h3 id="escenario-e-imagen-empleada">ESCENARIO E IMAGEN EMPLEADA</h3>
<p>Partimos de una máquina con Ubuntu Desktop 25.10, en la que tenemos instalado Docker 28.5.1. En ella, vamos a desplegar un entorno con cuatro contenedores, consistente en:</p>
<ul>
<li><strong>Un contenedor</strong> ( bigtop-hostname0) para el servidor Ambari.</li>
<li><strong>Tres contenedores</strong> ( bigtop-hostname1, bigtop-hostname2, bigtop-hostname3) para agentes de Ambari.</li>
<li><strong>Un volumen</strong> compartido para el repositorio Ambari.</li>
</ul>
<p>La imagen que usaremos <code>bigtop/puppet:trunk-rockylinux-8imagen</code>, forma parte del proyecto Apache BigTop y proporciona un marco de trabajo para la creación y prueba de proyectos relacionados con Hadoop, ya que viene preconfigurada con muchas de las dependencias necesarias para los servicios de Ambari y Hadoop. Esta imagen incluye:</p>
<ul>
<li>Rocky Linux 8 como sistema operativo base</li>
<li>Java y herramientas de desarrollo preinstaladas</li>
<li>Puppet para la gestión de la configuración</li>
<li>Configuraciones de sistema optimizadas para los servicios del ecosistema Hadoop</li>
</ul>
<h3 id="configuracion-del-entorno">CONFIGURACIÓN DEL ENTORNO</h3>
<h4 id="atajo-util-para-docker">ATAJO ÚTIL PARA DOCKER</h4>
<p>Este es un paso opcional, pero que puede ahorrarnos mucho tiempo en el futuro. Vamos a crear una función para conectarnos más facilmente al terminal de consola de un contenedor:</p>
<div class="language-text highlight"><pre><span></span><code>sudo su -

nano /etc/profile

# Añadimos la siguiente función al final del fichero
con() {
    docker exec -it &quot;$1&quot; /bin/bash
}

# Aplicamos los cambios inmediatemente
source /etc/profile
</code></pre></div>
<p>Tras añadir esta función, podrá acceder rápidamente a cualquier contenedor utilizando:</p>
<div class="language-text highlight"><pre><span></span><code>con contenedor_linux
</code></pre></div>
<h4 id="creacion-de-carpetas-y-fichero-hosts">CREACIÓN DE CARPETAS Y FICHERO HOSTS</h4>
<p>Creamos una carpeta <em>Ambari</em> y dentro de ella, añadiremos dos carpetas más:</p>
<div class="language-text highlight"><pre><span></span><code>mkdir -p Ambari
cd Ambari
mkdir -p ambari-repo
mkdir -p conf
</code></pre></div>
<p>Por un lado, accedemos a la carpeta <strong>ambari-repo</strong> y descargamos los páquetes RPM de Ambari y Bigtop:</p>
<div class="language-text highlight"><pre><span></span><code>cd ambari-repo/

//PARA ROCKY LINUX 8 (que es el SO que vamos a usar para nuestros nodos)
wget -r -np -nH --cut-dirs=4 --reject &#39;index.html*&#39; https://www.apache-ambari.com/dist/ambari/3.0.0/rocky8/
wget -r -np -nH --cut-dirs=4 --reject &#39;index.html*&#39; https://www.apache-ambari.com/dist/bigtop/3.3.0/rocky8/
</code></pre></div>
<p>Por otro lado, accedemos a la carpeta <em>conf</em> y creamos el fichero <em>hosts</em>, con la siguiente información:</p>
<div class="language-text highlight"><pre><span></span><code>cd conf

cat &gt; hosts &lt;&lt; EOF
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

# Container hostnames
192.168.20.2  bigtop-hostname0.iabd.local
192.168.20.3  bigtop-hostname1.iabd.local
192.168.20.4  bigtop-hostname2.iabd.local
192.168.20.5  bigtop-hostname3.iabd.local
EOF
</code></pre></div>
<div class="admonition warning">
<p class="admonition-title">ATENCIóN:</p>
<p>Los valores indicados más arriba para el fichero <strong><em>hosts</em></strong>, deben personalizarse según la instalación de cada uno, estos están configurados para que coincidan con el docker-compose.yaml que vemos más abajo. Pero es muy recomendable <strong>confirmar</strong> bien estos datos, <strong>despues de levantar el escenario Docker Compose</strong> si queremos evitarnos problemas durante la instalación de Hadoop.
Por un lado, comprobar el <strong>direccionamiento</strong> que se le ha asignado a cada contenedor con <code>docker network inspect ambari_net</code>; y por otro lado, los <strong>hostnames</strong> deben ser los que les asignemos más adelante a cada nodo <a href="#actualizacion-del-hostname-de-cada-nodo">(ver apartado)</a>, seguidos de un nombre de dominio inventado (esto es necesario para que luego ambari los reconozca como hostnames válidos).</p>
</div>
<h4 id="el-fichero-docker-compose">EL FICHERO DOCKER-COMPOSE</h4>
<p>Utilizaremos el siguiente fichero <code>docker-compose.yaml</code> para desplegar nuestro escenario:</p>
<details class="abstract">
<summary>nano docker-compose.yaml</summary>
<div class="language-text highlight"><pre><span></span><code>services:
    bigtop-hostname0:
        container_name: ambari_server
        hostname: bigtop-hostname0
        command: /sbin/init
        domainname: bigtop.apache.org
        image: bigtop/puppet:trunk-rockylinux-8
        mem_limit: 8g
        mem_swappiness: 0
        ports:
            - &quot;8080:8080&quot;
        privileged: true
        networks:
        red_cluster:
            ipv4_address: 192.168.20.2
        volumes:
            - ./ambari-repo:/var/repo/ambari
            - ./conf/hosts:/etc/hosts

    bigtop-hostname1:
        container_name: ambari_agent1
        hostname: bigtop-hostname1
        command: /sbin/init
        domainname: bigtop.apache.org
        image: bigtop/puppet:trunk-rockylinux-8
        mem_limit: 8g
        mem_swappiness: 0
        privileged: true
        networks:
            red_cluster:
                ipv4_address: 192.168.20.3
        volumes:
            - ./ambari-repo:/var/repo/ambari
            - ./conf/hosts:/etc/hosts

    bigtop-hostname2:
        container_name: ambari_agent2
        hostname: bigtop-hostname2
        command: /sbin/init
        domainname: bigtop.apache.org
        image: bigtop/puppet:trunk-rockylinux-8
        mem_limit: 8g
        mem_swappiness: 0
        privileged: true
        networks:
            red_cluster:
                ipv4_address: 192.168.20.4
        volumes:
            - ./ambari-repo:/var/repo/ambari
            - ./conf/hosts:/etc/hosts

    bigtop-hostname3:
        container_name: ambari_agent3
        hostname: bigtop-hostname3
        command: /sbin/init
        domainname: bigtop.apache.org
        image: bigtop/puppet:trunk-rockylinux-8
        mem_limit: 8g
        mem_swappiness: 0
        privileged: true
        networks:
            red_cluster:
                ipv4_address: 192.168.20.5
        volumes:
            - ./ambari-repo:/var/repo/ambari
            - ./conf/hosts:/etc/hosts

networks:
    red_cluster:
        name: ambari_net
        driver: bridge
        ipam:
            driver: default
            config:
                - subnet: 192.168.20.0/24
                gateway: 192.168.20.1
</code></pre></div>
</details>
<p>Arrancamos el escenario con el comando:</p>
<div class="language-text highlight"><pre><span></span><code>docker compose up -d
</code></pre></div>
<p>Y verificamos que se han creado nuestros contenedores y que hay conectividad entre ellos:</p>
<div class="language-text highlight"><pre><span></span><code>docker ps

docker exec -it ambari-bigtop-hostname0 ping -c 4 ambari-bigtop-hostname1
docker exec -it ambari-bigtop-hostname0 ping -c 4 ambari-bigtop-hostname2
docker exec -it ambari-bigtop-hostname0 ping -c 4 ambari-bigtop-hostname3
</code></pre></div>
<h4 id="actualizacion-del-hostname-de-cada-nodo">ACTUALIZACION DEL HOSTNAME DE CADA NODO</h4>
<p>Nos conectamos a cada nodo de nuestro cluster y si vemos que el hostname de la máquina no coincide con el que hemos configurado en el fichero <em>hosts</em>, lo actualizamos con el siguiente comando (es posible que haya que lanzarlo 2 veces):</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server
hostnamectl set-hostname bigtop-server
</code></pre></div>
<h4 id="conexion-ssh-entre-los-contenedores">CONEXION SSH ENTRE LOS CONTENEDORES</h4>
<p>Mediante la función que creamos al prinicipio, vamos conectandonos al terminal de consola de cada uno de nuestros contenedores e instalamos OPENSSH:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server
dnf install -y sudo openssh-server openssh-clients which iproute net-tools less vim-enhanced
ssh-keygen -t rsa -N &quot;&quot; -f ~/.ssh/id_rsa
systemctl enable sshd
systemctl start sshd
exit
</code></pre></div>
<p>Luego desde nuestra máquina ubuntu copiamos la clave del SERVIDOR y luego la pegamos en cada uno de los AGENTES:</p>
<div class="language-text highlight"><pre><span></span><code>docker exec -i ambari-bigtop-hostname0 bash -c &#39;cat ~/.ssh/id_rsa.pub&#39; &gt; id_rsa.pub

cat id_rsa.pub | docker exec -i ambari-bigtop-hostname1 bash -c &#39;cat &gt;&gt; ~/.ssh/authorized_keys&#39;
cat id_rsa.pub | docker exec -i ambari-bigtop-hostname2 bash -c &#39;cat &gt;&gt; ~/.ssh/authorized_keys&#39;
cat id_rsa.pub | docker exec -i ambari-bigtop-hostname3 bash -c &#39;cat &gt;&gt; ~/.ssh/authorized_keys&#39;

rm id_rsa.pub
</code></pre></div>
<p>Finalmente nos volvemos a conectar al SERVIDOR y comprobamos la conectividad con los agentes:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server
ssh -o StrictHostKeyChecking=no ambari-bigtop-hostname1 echo &quot;Connection successful&quot;
ssh -o StrictHostKeyChecking=no ambari-bigtop-hostname2 echo &quot;Connection successful&quot;
ssh -o StrictHostKeyChecking=no ambari-bigtop-hostname3 echo &quot;Connection successful&quot;
</code></pre></div>
<h4 id="instalacion-de-software-externo-necesario">INSTALACIÓN DE SOFTWARE EXTERNO NECESARIO</h4>
<p>Repetimos los siguientes pasos en todos los nodos del cluster:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server
dnf install -y initscripts wget curl tar unzip git
dnf install -y dnf-plugins-core
dnf config-manager --set-enabled powertools
dnf update -y
dnf install -y nano
dnf install -y python3
</code></pre></div>
<p>Editar el siguiente fichero para que indique <code>enabled=1</code> y no tenga ninguna linea comentada, excepto las dos superiores:</p>
<div class="language-text highlight"><pre><span></span><code>nano /etc/yum.repos.d/Rocky-Devel.repo
dnf repolist | grep devel
</code></pre></div>
<h3 id="instalacion-de-ambari">INSTALACIÓN DE AMBARI</h3>
<h4 id="acceso-al-repositorio-local">ACCESO AL REPOSITORIO LOCAL</h4>
<p>Luego configuramos el acceso de los paquetes de estos repositorios, en todos los nodos del Cluster:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server
dnf install -y createrepo
cd /var/repo/ambari/
createrepo .

tee /etc/yum.repos.d/ambari.repo &lt;&lt; EOF
[ambari]
name=Ambari Repository
baseurl=file:///var/repo/ambari
gpgcheck=0
enabled=1
EOF
</code></pre></div>
<h4 id="instalacion-de-paquetes">INSTALACIÓN DE PAQUETES</h4>
<p>Instalamos los siguientes paquetes en todos los nodos del cluster:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server

yum install -y iproute
yum install -y python3-distro
yum install -y java-17-openjdk-devel
yum install -y java-1.8.0-openjdk-devel
yum install -y chrony
yum install -y ambari-agent

yum remove -y rubygem-multi_json rubygem-semantic_puppet cpp-hocon rubygem-hocon rubygem-puppet-resource_api hiera leatherman ruby-facter rubygem-concurrent-ruby rubygem-deep_merge puppet rubygem-httpclient ruby-augeas facter yaml-cpp

dnf clean all
dnf makecache
</code></pre></div>
<p>Y además de lo anterior, solo en el SERVIDOR, instalamos lo siguiente:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server

yum install -y python3-psycopg2
yum install -y ambari-server
</code></pre></div>
<h4 id="instalacion-y-configuracion-de-mysql">INSTALACIÓN Y CONFIGURACIÓN DE MYSQL</h4>
<p>Seguimos conectados al SERVIDOR y configuramos lo siguiente:</p>
<div class="language-text highlight"><pre><span></span><code>rpm -qa | grep mysql
rpm -ev mysql-server --nodeps
rpm -ev mysql-community-server --nodeps

yum -y install https://dev.mysql.com/get/mysql80-community-release-el8-1.noarch.rpm

yum -y install mysql-server
systemctl start mysqld.service
systemctl enable mysqld.service
</code></pre></div>
<p>Ahora configuramos en MySQL las BBDD y Usuarios que usaremos en el ecosistema Hadoop:</p>
<div class="language-text highlight"><pre><span></span><code>mysql

CREATE USER &#39;ambari&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;ambari&#39;;
GRANT ALL PRIVILEGES ON *.* TO &#39;ambari&#39;@&#39;localhost&#39;;
CREATE USER &#39;ambari&#39;@&#39;%&#39; IDENTIFIED BY &#39;ambari&#39;;
GRANT ALL PRIVILEGES ON *.* TO &#39;ambari&#39;@&#39;%&#39;;

CREATE DATABASE ambari CHARACTER SET utf8 COLLATE utf8_general_ci;
CREATE DATABASE hive;
CREATE DATABASE ranger;
CREATE DATABASE rangerkms;

CREATE USER &#39;hive&#39;@&#39;%&#39; IDENTIFIED BY &#39;hive&#39;;
GRANT ALL PRIVILEGES ON hive.* TO &#39;hive&#39;@&#39;%&#39;;

CREATE USER &#39;ranger&#39;@&#39;%&#39; IDENTIFIED BY &#39;ranger&#39;;
GRANT ALL PRIVILEGES ON *.* TO &#39;ranger&#39;@&#39;%&#39; WITH GRANT OPTION;

CREATE USER &#39;rangerkms&#39;@&#39;%&#39; IDENTIFIED BY &#39;rangerkms&#39;;
GRANT ALL PRIVILEGES ON rangerkms.* TO &#39;rangerkms&#39;@&#39;%&#39;;

FLUSH PRIVILEGES;

exit

mysql -uambari -pambari ambari &lt; /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql
</code></pre></div>
<h4 id="arranque-de-los-serivicios-en-el-servidor">ARRANQUE DE LOS SERIVICIOS EN EL SERVIDOR</h4>
<p>Continuamos sin salir del SERVIDOR Ambari, y pasamos a arrancar los servicios JAVA, Amberi-Server y Ambari-Agent:</p>
<div class="language-text highlight"><pre><span></span><code>wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.28/mysql-connector-java-8.0.28.jar -O /usr/share/java/mysql-connector-java.jar

ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar

echo &quot;server.jdbc.url=jdbc:mysql://localhost:3306/ambari?useSSL=true&amp;verifyServerCertificate=false&amp;enabledTLSProtocols=TLSv1.2&quot; &gt;&gt; /etc/ambari-server/conf/ambari.properties

ambari-server setup -s -j /usr/lib/jvm/java-1.8.0-openjdk --ambari-java-home /usr/lib/jvm/java-17-openjdk --database=mysql --databasehost=localhost --databaseport=3306 --databasename=ambari --databaseusername=ambari --databasepassword=ambari

ambari-server start

# ¡OJO! En el siguiente comando estamos indicando el hostname del servidor, por lo que deberá modificarse ese dato para que coincida con el de nuestro nodo servidor:
sed -i &quot;s/hostname=.*/hostname=bigtop-hostname0.iabd.local/&quot; /etc/ambari-agent/conf/ambari-agent.ini

systemctl enable chronyd
systemctl start chronyd
ambari-agent start
</code></pre></div>
<h4 id="arranque-del-servicio-en-los-agentes">ARRANQUE DEL SERVICIO EN LOS AGENTES</h4>
<p>Por último, vamos accediendo a los nodos Agente y ejecutamos lo siguiente:</p>
<div class="language-text highlight"><pre><span></span><code># ¡OJO! En el siguiente comando estamos indicando el hostname del servidor, por lo que deberá modificarse ese dato para que coincida con el de nuestro nodo servidor:
sed -i &quot;s/hostname=.*/hostname=bigtop-hostname0.iabd.local/&quot; /etc/ambari-agent/conf/ambari-agent.ini

systemctl enable chronyd
systemctl start chronyd
ambari-agent start
</code></pre></div>
<div class="admonition bug">
<p class="admonition-title">POSIBLE BUG</p>
<p>Es posible que nos lance un error al arrancar los Agentes, debido a que el enlace al binario de Python no se crea automáticamente. En ese caso, ejecutando los siguientes comandos debería solucionarse:</p>
<div class="language-text highlight"><pre><span></span><code>dnf install -y python3
ln -s /usr/bin/python3 /usr/bin/ambari-python-wrap

yum reinstall -y ambari-agent
ambari-agent start
</code></pre></div>
</div>
<p>Si todo ha ido bien, ya tenemos nuestro cluster Ambari operativo, y podemos acceder a él vía web, como veremos en el siguiente apartado.</p>
<h2 id="configuracion-de-hadoop-desde-ambari">CONFIGURACIÓN DE HADOOP DESDE AMBARI</h2>
<h3 id="acceso-a-la-interfaz-grafica">ACCESO A LA INTERFAZ GRÁFICA</h3>
<p>Una vez tenemos arrancados el servidor y los agentes Ambari, podemos ir a nuestro navegador y acceder a su interfaz gráfica a través de la dirección:</p>
<div class="language-text highlight"><pre><span></span><code>https://localhost:8080
</code></pre></div>
<div class="admonition tip">
<p class="admonition-title">CREDENCIALES</p>
<p>Tanto el usuario como la contraseña para acceder la primera vez es <code>admin</code>.</p>
</div>
<h3 id="instalacion-de-hadoop">INSTALACION DE HADOOP</h3>
<p>Cuando iniciemos sesión en Ambari, veremos que no hay nada configurado y la primera opción que nos muestra es la de crear nuestro cluster Hadoop usando un assitente de instalación, para ello pulsamos en el botón:</p>
<p><a class="md-button" href="# ."><small>LAUNCH INSTALL WIZARD</small></a></p>
<p>Comenzamos por poner un nombre a nuestro cluster y luego seleccionamos la versión de BIGTOP que queremos, nosotros elegimos la 3.3.0, ya que es la que hemos utilizado en nuestros nodos.</p>
<p>Más abajo, en esta misma página debemos marcar la opción de <strong>Usar Repositorio Local</strong> e indicar que distribución de SO tenemos, en nuestro caso Rocky Linux 8, esta basado en <strong>Red Hat 8</strong>. El resto de distribuciones las debemos borrar haciendo click en el botón <strong><code>- Remove</code></strong> que aparece en la parte izquierda de cada una de ellas.</p>
<p>Por último, especificamos en el campo <strong>"Base URL"</strong> donde se encuentra nuestro repositorio local. Aquí debemos indicar el valor que pusimos al configurar el <a href="#acceso-al-repositorio-local">Repositorio Local</a> en los nodos:</p>
<div class="language-text highlight"><pre><span></span><code>file:///var/repo/ambari
</code></pre></div>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small></a></p>
<p>En la siguiente página, donde dice <strong>Target Hosts</strong> tenemos que indicar el hostname de cada nodo de nuestro cluster, separados por saltos de línea.</p>
<p>Luego en el apartado de <strong>Host Registration Information</strong> como nosotros ya hemos copiado manualmente la clave SSH del servidor en el fichero de autorizados de los agentes, simplemente marcamos la opción de <code>Perform Manual Registration on Hosts</code>.</p>
<p><a class="md-button md-button--primary" href="# ."><small>REGISTER AND CONFIRM</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>Esperamos a que finalice el proceso de registro de los nodos y si todo va bien recibiremos un mensaje que dirá <code>All hosts checks passed on 4 registered hosts</code>.</p>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>Pasaremos a la siguiente ventana donde vamos a elegir los servicios que queremos instalar. En nuestro caso, como estamos creando un laboratorio de prácticas y nuestros recursos son limitados, seleccionaremos los más esenciales para empezar (siempre podemos instalar servicios más adelante, una vez que esté funcionando nuestro cluster desde la sección <em><code>Stack an Versions</code></em>).</p>
<p>Por lo tanto, solo mantendremos seleccionados <strong>HDFS</strong>, <strong>YARN</strong>, <strong>MapReduce2</strong>, <strong>ZooKeeper</strong> y <strong>Ambari Metrics</strong>. Más adelante, por ejemplo tendremos que instalar <strong>HBase</strong>, ya que sin él no funcionará Ambari Metrics.</p>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 13h-4v4h-2v-4H7v-2h4V7h2v4h4m2-8H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"/></svg></span> <a class="md-button" href="# ."><small>PROCEED ANYWAY</small></a></p>
<p>Continuaremos con la opción de <strong>Asign Masters</strong>, esto es personalizable según las necesidades y recursos de cada cluster, pero un ejemplo para un laboratorio similar al nuestro, podría ser el siguiente:</p>
<p><img alt="Ejemplo Masters Hadoop" src="../../img/mastersAmbari.png" /></p>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>Al igual que pasaba en el paso anterior, la configuración de <strong>Assign Slaves and Clients</strong> puede variar de un escenario a otro, en este caso podemos establecer algo como lo siguiente:</p>
<p><img alt="Ejemplo Slaves Hadoop" src="../../img/slavesAmbari.png" /></p>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>En la pestaña <strong>Credentials</strong> nos pedirá configurar usauraio y contraseña para Grafana, podemos dejarlo como <code>admin / admin</code>.</p>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>En las siguientes pestañas <strong>Directories</strong>, <strong>Accounts</strong> y <strong>All Configurations</strong>; podremos hacer cambios más adelante si fuese necesario, pero por el momento vamos a dejarlos con sus valores por defecto, así que solo pulsamos en siguiente para avanzar.</p>
<p><a class="md-button md-button--primary" href="# ."><small>DEPLOY</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>Comenzará el despliegue de los servicios en los nodos de nuestro cluster, esto puede llevar un tiempo según las caracteristicas de nuestra máquina</p>
<p>Además, el servicio <em>Timeline Service V2</em> va a fallar, pero no es un problema, así que vamos a ignorarlo por el momento. El resto de servicios, deberían instalarse con éxito, si no es así, podemos pulsar en el botón <strong><code>RETRY</code><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 3a9 9 0 0 0-9 9H0l4 4 4-4H5a7 7 0 0 1 7-7 7 7 0 0 1 7 7 7 7 0 0 1-7 7c-1.5 0-2.91-.5-4.06-1.3L6.5 19.14A9.1 9.1 0 0 0 12 21a9 9 0 0 0 9-9 9 9 0 0 0-9-9m2 9a2 2 0 0 0-2-2 2 2 0 0 0-2 2 2 2 0 0 0 2 2 2 2 0 0 0 2-2"/></svg></span></strong>, para volver a intentarlo. Si todo va bien, debería finalizar el despliegue con 2 o 3 warnings, pero sin errores.</p>
<div class="admonition warning">
<p class="admonition-title">FALTA DE RECURSOS</p>
<p>Si por algún motivo, como recursos insuficientes el despliegue se queda congelado y no responde; podemos conectarnos a la consola de nuestro nodo SERVIDOR y ejecutar el siguiente comando:
    ambari-server restart</p>
</div>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 13h-4v4h-2v-4H7v-2h4V7h2v4h4m2-8H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"/></svg></span> <a class="md-button" href="# ."><small>COMPLETE</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>Dejaremos unos segundos (o minutos) a que los servicios terminen de arrancar y podremos conectarnos a nuestro nodo SERVIDOR y comprobar que efectivamente tenemos habilitado el sistema de archivos de Hadoop:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server
hadoop fs -ls /
</code></pre></div>
<p><em><small><a href="https://ambari.apache.org/docs/3.0.0/quick-start/environment-setup/docker-environment-setup/">Fuente 1: Ambari Docker Environmet Setup</a></small></em> , <em><small><a href="https://ambari.apache.org/docs/3.0.0/quick-start/installation-guide">Fuente 2: Ambari Installation Guide</a></small></em> , <em><small><a href="https://youtu.be/Ao95xAGsA20">Fuente 3: Edward Viaene</a></small></em></p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Licencia CC BY-NC-SA 4.0 | Lorenzo LV - 2025
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
    <a href="https://github.com/ProfeAzarquiel" target="_blank" rel="noopener" title="Lorenzo on GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["content.code.copy", "content.tabs.link", "navigation.indexes"], "search": "../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
    
  </body>
</html>