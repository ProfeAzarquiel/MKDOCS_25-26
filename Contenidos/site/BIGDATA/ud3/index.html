
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Sitio para englobar los contenidos teórico/prácticos de varios del os módulos profesionales impartidos en la especialidad de Informática del IES Azarquiel.">
      
      
        <meta name="author" content="Lorenzo LV">
      
      
        <link rel="canonical" href="https://profeazarquiel.github.io/MKDOCS_25-26/BIGDATA/ud3/">
      
      
        <link rel="prev" href="../ud2/">
      
      
        <link rel="next" href="../ud4/">
      
      
        
      
      
      <link rel="icon" href="../../img/favicon2.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>UD3. Ecosistema Hadoop - MATERIALES INFORMÁTICA IES AZARQUIEL</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="deep-orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#apache-hadoop" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="MATERIALES INFORMÁTICA IES AZARQUIEL" class="md-header__button md-logo" aria-label="MATERIALES INFORMÁTICA IES AZARQUIEL" data-md-component="logo">
      
  <img src="../../img/logo2.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MATERIALES INFORMÁTICA IES AZARQUIEL
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              UD3. Ecosistema Hadoop
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="deep-orange"  aria-label="Cambiar a modo oscuro"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Cambiar a modo oscuro" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="deep-orange"  aria-label="Cambiar a modo claro"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Cambiar a modo claro" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="MATERIALES INFORMÁTICA IES AZARQUIEL" class="md-nav__button md-logo" aria-label="MATERIALES INFORMÁTICA IES AZARQUIEL" data-md-component="logo">
      
  <img src="../../img/logo2.png" alt="logo">

    </a>
    MATERIALES INFORMÁTICA IES AZARQUIEL
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    INICIO
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    COMPUTACIÓN EN LA NUBE
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    COMPUTACIÓN EN LA NUBE
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/indexc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Indice
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/ud0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD0. Libros y Herramientas Útiles
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/ud1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD1. Infraestructura de Red
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/ud2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD2. Infraestructura Cloud
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/ud3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD3. Virtualización
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/ud4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD4. Docker
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/ud5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD5. Kubernetes
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CLOUD/ud6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD6. Terraform
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    BIGDATA APLICADO
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    BIGDATA APLICADO
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../indexb/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Indice
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ud0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD0. Libros y Herramientas Útiles
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ud1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD1. Introducción a BigData
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ud2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD2. Ingesta de Datos
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    UD3. Ecosistema Hadoop
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    UD3. Ecosistema Hadoop
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#arquitectura-basica" class="md-nav__link">
    <span class="md-ellipsis">
      
        ARQUITECTURA BÁSICA
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#despliegue-cluster-hadoop-con-ambari-y-docker" class="md-nav__link">
    <span class="md-ellipsis">
      
        DESPLIEGUE CLÚSTER HADOOP CON AMBARI Y DOCKER
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuracion-de-hadoop-desde-ambari" class="md-nav__link">
    <span class="md-ellipsis">
      
        CONFIGURACIÓN DE HADOOP DESDE AMBARI
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#despliegue-cluster-hadoop-sobre-docker" class="md-nav__link">
    <span class="md-ellipsis">
      
        DESPLIEGUE CLÚSTER HADOOP SOBRE DOCKER
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practica-1-hola-mundo-en-hadoop" class="md-nav__link">
    <span class="md-ellipsis">
      
        PRÁCTICA 1: HOLA MUNDO EN HADOOP
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practica-2-trabajando-con-hdfs" class="md-nav__link">
    <span class="md-ellipsis">
      
        PRÁCTICA 2: TRABAJANDO CON HDFS
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ud4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD4. Apache Spark
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    DISEÑO WEB
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    DISEÑO WEB
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../WEB/indexw/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Indice
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../WEB/ud0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD0. Libros y Herramientas Útiles
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../WEB/ud1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD1. Principios del Diseño
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../WEB/ud2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD2. Maquetación CSS
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../WEB/ud3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD3. Preprocesadores CSS
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../WEB/ud4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD4. Implantación de contenidos Multimedia
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../WEB/ud5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD5. Frameworks CSS
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    PYTHON
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    PYTHON
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PYTHON/indexp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Indice
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PYTHON/ud0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD0. Libros y Herramientas Útiles
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PYTHON/ud1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD1. Fundamentos
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PYTHON/ud2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD2. Análisis de Datos
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PYTHON/ud3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD3. Creación de APIs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PYTHON/ud4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD4. Aplicaciones Web
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PYTHON/ud5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UD5. Redes Neuronales
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#arquitectura-basica" class="md-nav__link">
    <span class="md-ellipsis">
      
        ARQUITECTURA BÁSICA
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#despliegue-cluster-hadoop-con-ambari-y-docker" class="md-nav__link">
    <span class="md-ellipsis">
      
        DESPLIEGUE CLÚSTER HADOOP CON AMBARI Y DOCKER
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuracion-de-hadoop-desde-ambari" class="md-nav__link">
    <span class="md-ellipsis">
      
        CONFIGURACIÓN DE HADOOP DESDE AMBARI
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#despliegue-cluster-hadoop-sobre-docker" class="md-nav__link">
    <span class="md-ellipsis">
      
        DESPLIEGUE CLÚSTER HADOOP SOBRE DOCKER
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practica-1-hola-mundo-en-hadoop" class="md-nav__link">
    <span class="md-ellipsis">
      
        PRÁCTICA 1: HOLA MUNDO EN HADOOP
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practica-2-trabajando-con-hdfs" class="md-nav__link">
    <span class="md-ellipsis">
      
        PRÁCTICA 2: TRABAJANDO CON HDFS
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="apache-hadoop">APACHE HADOOP</h1>
<p>Hadoop es un proyecto open source que aglutina una serie de herramientas para el procesamiento distribuido de grandes conjuntos de datos a través de clústers de ordenadores utilizando modelos de programación sencillos.</p>
<figure>
    <img alt="Hadoop Logo" src="https://upload.wikimedia.org/wikipedia/commons/3/38/Hadoop_logo_new.svg" width="450" />
    <small><figcaption>Logo Apache Hadoop</figcaption></small>
</figure>
<h2 id="arquitectura-basica">ARQUITECTURA BÁSICA</h2>
<ul>
<li><strong>COMMON UTILITIES</strong>: conjunto de librerias y ficheros necesarios para ejecutar Haddop.</li>
<li><strong>YARN</strong>: gestor de recursos, se encarga de repartir los recursos disponibles en cada nodo entre las distitnas aplicaciones.</li>
<li><strong>HDFS</strong>: sistema de archivos distribuidos instalado en los distintos nodos del cluster y va almacenando mediante replicación los datos.</li>
<li><strong>MapReduce</strong>: son los procesos implementados en código por el usuario, para procesar los datos.</li>
</ul>
<p><img alt="Hadoop Arquitecture" src="https://media.geeksforgeeks.org/wp-content/uploads/20250628162844186405/Hadoop_architecture.webp" /></p>
<p>Si queremos empezar a utilizar Hadoop y todo su ecosistema, disponemos de diversas distribuciones con toda la arquitectura, herramientas y configuración ya preparadas. Las más reseñables son:</p>
<ul>
<li><strong>EMR de AWS</strong> (Amazon Elastic MapReduce)</li>
<li><strong>CDP de Cloudera</strong>: es la evolución de CDH y HDP (antiguas distribuciones de código abierto de Apache Hadoop y otros proyectos relacionados, actualmente sin soporte). Cloudera ofrecia estas distribuciones de forma gratuita, cosa que ya no sucede con CDP, pero aún se puede descargar la MV de HDP en el siguiente <a href="https://archive.cloudera.com/hwx-sandbox/hdp/hdp-3.0.1/HDP_3.0.1_virtualbox_181205.ova">enlace</a>.</li>
<li><strong>Azure HDInsight</strong> de Microsoft.</li>
<li><strong>DataProc</strong> de Google.</li>
</ul>
<p>Nosotros vamos a usar una <strong><code>Apache Ambari</code></strong>, proyecto dedicado a simplificar la administración, aprovisionamiento, la gestión y la monitorización de clústeres Apache Hadoop; proporcionando una interfaz web de administración intuitiva y fácil de usar.</p>
<div class="admonition quote">
<p class="admonition-title">No todo el monte es Orégano <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M23 7v6h-2V7m0 8h2v2h-2M12 2a2 2 0 0 0-2 2 2 2 0 0 0 0 .29C7.12 5.14 5 7.82 5 11v6l-2 2v1h18v-1l-2-2v-6c0-3.18-2.12-5.86-5-6.71A2 2 0 0 0 14 4a2 2 0 0 0-2-2m-2 19a2 2 0 0 0 2 2 2 2 0 0 0 2-2Z"/></svg></span></p>
<p>Hadoop facilita el trabajo con grandes volúmenes de datos, pero montar un clúster funcional no es una cosa trivial. Existen gestores de clústers que hacen las cosas un poco más sencillas (como <em>Apache Ambari</em> o <em>Apache Mesos</em>), aunque la tendencia es utilizar una solución cloud que nos evita toda la instalación y configuración.</p>
</div>
<h3 id="hdfs"><strong>HDFS</strong></h3>
<p>Es la capa de almacenamiento de Hadoop o lo que es lo mismo, un sistema de ficheros distribuido, con gran tolerancia a fallos, facil de escalar de forma incremental y capaz de almacenar grandes volúmenes de datos.</p>
<p>Su funcionamiento se basa en repartir los datos entre todos los nodos del clúster, dividiendo los ficheros en bloques y almacenando copias duplicadas en diferentes nodos. Por defecto cada bloque se replica en 3 nodos distintos (esto se conoce como <strong>factor de replicación</strong>).</p>
<p>Está planteado para escribir los datos una vez y leerlos muchas veces, <strong>Write Once, Read Many</strong> (WORM). Además, una vez escritos, los datos son inmutables; es decir, cada fichero de HDFS solo permite añadir contenido (append-only) o eliminar el fichero completo.</p>
<div class="admonition tip">
<p class="admonition-title">Modificación de datos en HDFS</p>
<p>Tanto <strong>HBase</strong> como <strong>Hive</strong> ofrecen una capa por encima de HDFS para dar soporte a la modificación de los datos, como en cualquier base de datos.</p>
</div>
<h4 id="tipos-de-nodos"><strong>Tipos de Nodos</strong></h4>
<p>En HDFS vamos a distinguir 2 tipos de máquinas o roles:</p>
<ul>
<li>
<p><strong>Namenode</strong>: actúa como máster y almacena todos los metadatos necesarios para construir el sistema de ficheros a partir de sus bloques. Tiene control sobre dónde están todos los bloques.</p>
</li>
<li>
<p><strong>Datanode</strong>: son los nodos esclavo, se limitan a almacenar los bloques que componen cada fichero.</p>
</li>
</ul>
<h4 id="los-bloques"><strong>Los Bloques</strong></h4>
<p>Un bloque es la cantidad mínima de datos que puede ser leída o escrita en HDFS, su tamaño predeterminado son 128 MB.</p>
<p>Todos los ficheros en HDFS estan divididos en bloques, por lo que si subimos un fichero de 600MB, se dividirá en 5 bloques de 128MB, que se distribuirán por todos los nodos de datos del clúster.</p>
<p>Además, a través del factor de replicación (por defecto 3), cada bloque se almacena varias veces en diferentes nodos. Así que finalmente, nuestro archivo de 600MB estará repartido en 15 bloques entre todos los nodos del clúster.</p>
<figure>
    <img alt="Replicación HDFS" src="https://substackcdn.com/image/fetch/$s_!_cKl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8321d7f4-8e50-4990-a3c2-169c33106c5c_582x394.png" width="400" />
    <small><figcaption>División y replicación HDFS</figcaption></small>
</figure>
<h3 id="yarn-yet-another-resource-negotiator"><strong>YARN</strong> (Yet Another Resource Negotiator)</h3>
<p>Este framework proporciona un <strong>planificador de recursos</strong> desvinculado de los trabajos que se encuentran en ejecución en el clúster, ya que <strong>separa</strong> la <strong>gestión de recursos</strong> y la <strong>planificación y monitorización</strong><em> de trabajos. Lo que hace posible tener un gestor global (Resource Manager) por cluster y un Application Master por aplicación (considerando aplicación tanto un único </em>job<em>, como un conjunto de </em>jobs* cíclicos).</p>
<p>Se divide en <strong>tres componentes principales</strong>: un Resource Manager, múltiples Node Manager y varios ApplicationMaster.</p>
<p>El Resource Manager y el Node Manager componen el framework de computación de datos. En concreto, el ResourceManager controla el arranque de la aplicación, siendo la autoridad que orquesta los recursos entre todas las aplicaciones del sistema. A su vez, tendremos tantos NodeManager como datanodes tenga nuestro clúster, siendo responsables de gestionar y monitorizar los recursos de cada nodo (CPU, memoria, disco y red) y reportar estos datos al Resource Manager.</p>
<p>El Application Master es una librería específica encargada de negociar los recursos con el ResourceManager y de trabajar con los Node Manager para ejecutar y monitorizar las tareas.</p>
<p>Finalmente, en nuestro clúster, tendremos corriendo un Job History Server encargado de archivar los fichero de log de los jobs. Aunque es un proceso opcional, se recomienda su uso para monitorizar los jobs ejecutados.</p>
<figure>
    <img alt="YARN Architecture" src="../../img/yarn_schema.png" width="600" />
    <small><figcaption>Arquitectura YARN</figcaption></small>
</figure>
<h3 id="map-reduce"><strong>MAP-REDUCE</strong></h3>
<p>Hadoop MapReduce es un paradigma de procesamiento de datos caracterizado por dividirse en dos fases o pasos diferenciados: Map y Reduce. Estos subprocesos asociados a la tarea se ejecutan de manera distribuida, en diferentes nodos de procesamiento o esclavos. Para controlar y gestionar su ejecución, existe un proceso Master o Job Tracker. También es el encargado de aceptar los nuevos trabajos enviados al sistema por los clientes. Los resultados del procesamiento se pueden almacenar en el mismo sistema de almacenamiento o bien en una base de datos o sistema externo.</p>
<h4 id="fases-de-hadoop-mapreduce"><strong>Fases de Hadoop MapReduce</strong></h4>
<p><strong>Map</strong>: se ejecuta en subtareas llamadas mappers. Estos componentes son los responsables de generar pares clave-valor filtrando, agrupando, ordenando o transformando los datos originales. Los pares de datos intermedios, no se almacenan en HDFS.</p>
<p><strong>Shuffle</strong>: puede no ser necesaria. Es el paso intermedio entre Map y reduce que ayuda a recoger los datos y ordenarlos de manera conveniente para el procesamiento. Con esta fase, se pretende agregar las ocurrencias repetidas en cada uno de los mappers.</p>
<p><strong>Reduce</strong>: gestiona la agregación de los valores producidos por todos los mappers del sistema (o por la fase shuffle) de tipo clave-valor en función de su clave. Por último, cada reducer genera su fichero de salida de forma independiente, generalmente escrito en HDFS.</p>
<figure>
    <img alt="Fases MapReduce" src="https://storage.googleapis.com/algodailyrandomassets/curriculum/systems-design/map-reduce/example.png" />
    <small><figcaption>Fases MapReduce</figcaption></small>
</figure>
<h4 id="limitaciones"><strong>Limitaciones</strong></h4>
<p>MapReduce es la implementación básica de un framework de procesamiento en paralelo para cargas big data, por lo que al final tiene ciertas limitaciones como, por ejemplo, hasta que la fase map completa su procesamiento, los reducers no empiezan a ejecutarse; o que no se puede controlar su orden de ejecución.</p>
<p>Es por ello, que existen alternativas como Apache Spark, Apache Hive o Pig; las cuales mantienen los principales puntos de MapReduce, pero son capaces de usar HDFS de manera más eficiente. La que resalta más entre el resto es <strong>SPARK</strong>, la cual veremos más adelante.</p>
<p><em><small><a href="https://aitor-medrano.github.io/iabd/">Fuente 1: Aitor Medrano</a></small></em>, <em><small><a href="https://aprenderbigdata.com/hadoop/">Fuente 2: Oscar Fernández</a></small></em></p>
<h2 id="despliegue-cluster-hadoop-con-ambari-y-docker">DESPLIEGUE CLÚSTER HADOOP CON AMBARI Y DOCKER</h2>
<figure>
    <img alt="Apache Ambari" src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Apache_Ambari_Logo.svg/2560px-Apache_Ambari_Logo.svg.png" width="500" />
    <small><figcaption>Logo Apache Ambari</figcaption></small>
</figure>
<h3 id="escenario-e-imagen-empleada">ESCENARIO E IMAGEN EMPLEADA</h3>
<p>Partimos de una máquina con Ubuntu Desktop 25.10, en la que tenemos instalado Docker 28.5.1. En ella, vamos a desplegar un entorno con cuatro contenedores, consistente en:</p>
<ul>
<li><strong>Un contenedor</strong> ( bigtop-hostname0) para el servidor Ambari.</li>
<li><strong>Tres contenedores</strong> ( bigtop-hostname1, bigtop-hostname2, bigtop-hostname3) para agentes de Ambari.</li>
<li><strong>Un volumen</strong> compartido para el repositorio Ambari.</li>
</ul>
<p>La imagen que usaremos <code>bigtop/puppet:trunk-rockylinux-8imagen</code>, forma parte del proyecto Apache BigTop y proporciona un marco de trabajo para la creación y prueba de proyectos relacionados con Hadoop, ya que viene preconfigurada con muchas de las dependencias necesarias para los servicios de Ambari y Hadoop. Esta imagen incluye:</p>
<ul>
<li>Rocky Linux 8 como sistema operativo base</li>
<li>Java y herramientas de desarrollo preinstaladas</li>
<li>Puppet para la gestión de la configuración</li>
<li>Configuraciones de sistema optimizadas para los servicios del ecosistema Hadoop</li>
</ul>
<h3 id="configuracion-del-entorno">CONFIGURACIÓN DEL ENTORNO</h3>
<h4 id="atajo-util-para-docker">ATAJO ÚTIL PARA DOCKER</h4>
<p>Este es un paso opcional, pero que puede ahorrarnos mucho tiempo en el futuro. Vamos a crear una función para conectarnos más facilmente al terminal de consola de un contenedor:</p>
<div class="language-text highlight"><pre><span></span><code>sudo su -

nano /etc/profile

# Añadimos la siguiente función al final del fichero
con() {
    docker exec -it &quot;$1&quot; /bin/bash
}

# Aplicamos los cambios inmediatemente
source /etc/profile
</code></pre></div>
<p>Tras añadir esta función, podrá acceder rápidamente a cualquier contenedor utilizando:</p>
<div class="language-text highlight"><pre><span></span><code>con contenedor_linux
</code></pre></div>
<h4 id="creacion-de-carpetas-y-fichero-hosts">CREACIÓN DE CARPETAS Y FICHERO HOSTS</h4>
<p>Creamos una carpeta <em>Ambari</em> y dentro de ella, añadiremos dos carpetas más:</p>
<div class="language-text highlight"><pre><span></span><code>mkdir -p Ambari
cd Ambari
mkdir -p ambari-repo
mkdir -p conf
</code></pre></div>
<p>Por un lado, accedemos a la carpeta <strong>ambari-repo</strong> y descargamos los páquetes RPM de Ambari y Bigtop:</p>
<div class="language-text highlight"><pre><span></span><code>cd ambari-repo/

//PARA ROCKY LINUX 8 (que es el SO que vamos a usar para nuestros nodos)
wget -r -np -nH --cut-dirs=4 --reject &#39;index.html*&#39; https://www.apache-ambari.com/dist/ambari/3.0.0/rocky8/
wget -r -np -nH --cut-dirs=4 --reject &#39;index.html*&#39; https://www.apache-ambari.com/dist/bigtop/3.3.0/rocky8/
</code></pre></div>
<p>Por otro lado, accedemos a la carpeta <em>conf</em> y creamos el fichero <em>hosts</em>, con la siguiente información:</p>
<div class="language-text highlight"><pre><span></span><code>cd conf

cat &gt; hosts &lt;&lt; EOF
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

# Container hostnames
192.168.20.2  bigtop-hostname0.iabd.local
192.168.20.3  bigtop-hostname1.iabd.local
192.168.20.4  bigtop-hostname2.iabd.local
192.168.20.5  bigtop-hostname3.iabd.local
EOF
</code></pre></div>
<div class="admonition warning">
<p class="admonition-title">ATENCIóN:</p>
<p>Los valores indicados más arriba para el fichero <strong><em>hosts</em></strong>, deben personalizarse según la instalación de cada uno, estos están configurados para que coincidan con el docker-compose.yaml que vemos más abajo. Pero es muy recomendable <strong>confirmar</strong> bien estos datos, <strong>despues de levantar el escenario Docker Compose</strong> si queremos evitarnos problemas durante la instalación de Hadoop.
Por un lado, comprobar el <strong>direccionamiento</strong> que se le ha asignado a cada contenedor con <code>docker network inspect ambari_net</code>; y por otro lado, los <strong>hostnames</strong> deben ser los que les asignemos más adelante a cada nodo <a href="#actualizacion-del-hostname-de-cada-nodo">(ver apartado)</a>, seguidos de un nombre de dominio inventado (esto es necesario para que luego ambari los reconozca como hostnames válidos).</p>
</div>
<h4 id="el-fichero-docker-compose">EL FICHERO DOCKER-COMPOSE</h4>
<p>Utilizaremos el siguiente fichero <code>docker-compose.yaml</code> para desplegar nuestro escenario:</p>
<details class="abstract">
<summary>nano docker-compose.yaml</summary>
<div class="language-text highlight"><pre><span></span><code>services:
    bigtop-hostname0:
        container_name: ambari_server
        hostname: bigtop-hostname0
        command: /sbin/init
        domainname: bigtop.apache.org
        image: bigtop/puppet:trunk-rockylinux-8
        mem_limit: 8g
        mem_swappiness: 0
        ports:
            - &quot;8080:8080&quot;
        privileged: true
        networks:
        red_cluster:
            ipv4_address: 192.168.20.2
        volumes:
            - ./ambari-repo:/var/repo/ambari
            - ./conf/hosts:/etc/hosts

    bigtop-hostname1:
        container_name: ambari_agent1
        hostname: bigtop-hostname1
        command: /sbin/init
        domainname: bigtop.apache.org
        image: bigtop/puppet:trunk-rockylinux-8
        mem_limit: 8g
        mem_swappiness: 0
        privileged: true
        networks:
            red_cluster:
                ipv4_address: 192.168.20.3
        volumes:
            - ./ambari-repo:/var/repo/ambari
            - ./conf/hosts:/etc/hosts

    bigtop-hostname2:
        container_name: ambari_agent2
        hostname: bigtop-hostname2
        command: /sbin/init
        domainname: bigtop.apache.org
        image: bigtop/puppet:trunk-rockylinux-8
        mem_limit: 8g
        mem_swappiness: 0
        privileged: true
        networks:
            red_cluster:
                ipv4_address: 192.168.20.4
        volumes:
            - ./ambari-repo:/var/repo/ambari
            - ./conf/hosts:/etc/hosts

    bigtop-hostname3:
        container_name: ambari_agent3
        hostname: bigtop-hostname3
        command: /sbin/init
        domainname: bigtop.apache.org
        image: bigtop/puppet:trunk-rockylinux-8
        mem_limit: 8g
        mem_swappiness: 0
        privileged: true
        networks:
            red_cluster:
                ipv4_address: 192.168.20.5
        volumes:
            - ./ambari-repo:/var/repo/ambari
            - ./conf/hosts:/etc/hosts

networks:
    red_cluster:
        name: ambari_net
        driver: bridge
        ipam:
            driver: default
            config:
                - subnet: 192.168.20.0/24
                gateway: 192.168.20.1
</code></pre></div>
</details>
<p>Arrancamos el escenario con el comando:</p>
<div class="language-text highlight"><pre><span></span><code>docker compose up -d
</code></pre></div>
<p>Y verificamos que se han creado nuestros contenedores y que hay conectividad entre ellos:</p>
<div class="language-text highlight"><pre><span></span><code>docker ps

docker exec -it ambari-bigtop-hostname0 ping -c 4 ambari-bigtop-hostname1
docker exec -it ambari-bigtop-hostname0 ping -c 4 ambari-bigtop-hostname2
docker exec -it ambari-bigtop-hostname0 ping -c 4 ambari-bigtop-hostname3
</code></pre></div>
<h4 id="actualizacion-del-hostname-de-cada-nodo">ACTUALIZACION DEL HOSTNAME DE CADA NODO</h4>
<p>Nos conectamos a cada nodo de nuestro cluster y si vemos que el hostname de la máquina no coincide con el que hemos configurado en el fichero <em>hosts</em>, lo actualizamos con el siguiente comando (es posible que haya que lanzarlo 2 veces):</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server
hostnamectl set-hostname bigtop-server
</code></pre></div>
<h4 id="conexion-ssh-entre-los-contenedores">CONEXION SSH ENTRE LOS CONTENEDORES</h4>
<p>Mediante la función que creamos al prinicipio, vamos conectandonos al terminal de consola de cada uno de nuestros contenedores e instalamos OPENSSH:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server
dnf install -y sudo openssh-server openssh-clients which iproute net-tools less vim-enhanced
ssh-keygen -t rsa -N &quot;&quot; -f ~/.ssh/id_rsa
systemctl enable sshd
systemctl start sshd
exit
</code></pre></div>
<p>Luego desde nuestra máquina ubuntu copiamos la clave del SERVIDOR y luego la pegamos en cada uno de los AGENTES:</p>
<div class="language-text highlight"><pre><span></span><code>docker exec -i ambari-bigtop-hostname0 bash -c &#39;cat ~/.ssh/id_rsa.pub&#39; &gt; id_rsa.pub

cat id_rsa.pub | docker exec -i ambari-bigtop-hostname1 bash -c &#39;cat &gt;&gt; ~/.ssh/authorized_keys&#39;
cat id_rsa.pub | docker exec -i ambari-bigtop-hostname2 bash -c &#39;cat &gt;&gt; ~/.ssh/authorized_keys&#39;
cat id_rsa.pub | docker exec -i ambari-bigtop-hostname3 bash -c &#39;cat &gt;&gt; ~/.ssh/authorized_keys&#39;

rm id_rsa.pub
</code></pre></div>
<p>Finalmente nos volvemos a conectar al SERVIDOR y comprobamos la conectividad con los agentes:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server
ssh -o StrictHostKeyChecking=no ambari-bigtop-hostname1 echo &quot;Connection successful&quot;
ssh -o StrictHostKeyChecking=no ambari-bigtop-hostname2 echo &quot;Connection successful&quot;
ssh -o StrictHostKeyChecking=no ambari-bigtop-hostname3 echo &quot;Connection successful&quot;
</code></pre></div>
<h4 id="instalacion-de-software-externo-necesario">INSTALACIÓN DE SOFTWARE EXTERNO NECESARIO</h4>
<p>Repetimos los siguientes pasos en todos los nodos del cluster:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server
dnf install -y initscripts wget curl tar unzip git
dnf install -y dnf-plugins-core
dnf config-manager --set-enabled powertools
dnf update -y
dnf install -y nano
dnf install -y python3
</code></pre></div>
<p>Editar el siguiente fichero para que indique <code>enabled=1</code> y no tenga ninguna linea comentada, excepto las dos superiores:</p>
<div class="language-text highlight"><pre><span></span><code>nano /etc/yum.repos.d/Rocky-Devel.repo
dnf repolist | grep devel
</code></pre></div>
<h3 id="instalacion-de-ambari">INSTALACIÓN DE AMBARI</h3>
<h4 id="acceso-al-repositorio-local">ACCESO AL REPOSITORIO LOCAL</h4>
<p>Luego configuramos el acceso de los paquetes de estos repositorios, en todos los nodos del Cluster:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server
dnf install -y createrepo
cd /var/repo/ambari/
createrepo .

tee /etc/yum.repos.d/ambari.repo &lt;&lt; EOF
[ambari]
name=Ambari Repository
baseurl=file:///var/repo/ambari
gpgcheck=0
enabled=1
EOF
</code></pre></div>
<h4 id="instalacion-de-paquetes">INSTALACIÓN DE PAQUETES</h4>
<p>Instalamos los siguientes paquetes en todos los nodos del cluster:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server

yum install -y iproute
yum install -y python3-distro
yum install -y java-17-openjdk-devel
yum install -y java-1.8.0-openjdk-devel
yum install -y chrony
yum install -y ambari-agent

yum remove -y rubygem-multi_json rubygem-semantic_puppet cpp-hocon rubygem-hocon rubygem-puppet-resource_api hiera leatherman ruby-facter rubygem-concurrent-ruby rubygem-deep_merge puppet rubygem-httpclient ruby-augeas facter yaml-cpp

dnf clean all
dnf makecache
</code></pre></div>
<p>Y además de lo anterior, solo en el SERVIDOR, instalamos lo siguiente:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server

yum install -y python3-psycopg2
yum install -y ambari-server
</code></pre></div>
<h4 id="instalacion-y-configuracion-de-mysql">INSTALACIÓN Y CONFIGURACIÓN DE MYSQL</h4>
<p>Seguimos conectados al SERVIDOR y configuramos lo siguiente:</p>
<div class="language-text highlight"><pre><span></span><code>rpm -qa | grep mysql
rpm -ev mysql-server --nodeps
rpm -ev mysql-community-server --nodeps

yum -y install https://dev.mysql.com/get/mysql80-community-release-el8-1.noarch.rpm

yum -y install mysql-server
systemctl start mysqld.service
systemctl enable mysqld.service
</code></pre></div>
<p>Ahora configuramos en MySQL las BBDD y Usuarios que usaremos en el ecosistema Hadoop:</p>
<div class="language-text highlight"><pre><span></span><code>mysql

CREATE USER &#39;ambari&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;ambari&#39;;
GRANT ALL PRIVILEGES ON *.* TO &#39;ambari&#39;@&#39;localhost&#39;;
CREATE USER &#39;ambari&#39;@&#39;%&#39; IDENTIFIED BY &#39;ambari&#39;;
GRANT ALL PRIVILEGES ON *.* TO &#39;ambari&#39;@&#39;%&#39;;

CREATE DATABASE ambari CHARACTER SET utf8 COLLATE utf8_general_ci;
CREATE DATABASE hive;
CREATE DATABASE ranger;
CREATE DATABASE rangerkms;

CREATE USER &#39;hive&#39;@&#39;%&#39; IDENTIFIED BY &#39;hive&#39;;
GRANT ALL PRIVILEGES ON hive.* TO &#39;hive&#39;@&#39;%&#39;;

CREATE USER &#39;ranger&#39;@&#39;%&#39; IDENTIFIED BY &#39;ranger&#39;;
GRANT ALL PRIVILEGES ON *.* TO &#39;ranger&#39;@&#39;%&#39; WITH GRANT OPTION;

CREATE USER &#39;rangerkms&#39;@&#39;%&#39; IDENTIFIED BY &#39;rangerkms&#39;;
GRANT ALL PRIVILEGES ON rangerkms.* TO &#39;rangerkms&#39;@&#39;%&#39;;

FLUSH PRIVILEGES;

exit

mysql -uambari -pambari ambari &lt; /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql
</code></pre></div>
<h4 id="arranque-de-los-serivicios-en-el-servidor">ARRANQUE DE LOS SERIVICIOS EN EL SERVIDOR</h4>
<p>Continuamos sin salir del SERVIDOR Ambari, y pasamos a arrancar los servicios JAVA, Amberi-Server y Ambari-Agent:</p>
<div class="language-text highlight"><pre><span></span><code>wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.28/mysql-connector-java-8.0.28.jar -O /usr/share/java/mysql-connector-java.jar

ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar

echo &quot;server.jdbc.url=jdbc:mysql://localhost:3306/ambari?useSSL=true&amp;verifyServerCertificate=false&amp;enabledTLSProtocols=TLSv1.2&quot; &gt;&gt; /etc/ambari-server/conf/ambari.properties

ambari-server setup -s -j /usr/lib/jvm/java-1.8.0-openjdk --ambari-java-home /usr/lib/jvm/java-17-openjdk --database=mysql --databasehost=localhost --databaseport=3306 --databasename=ambari --databaseusername=ambari --databasepassword=ambari

ambari-server start

# ¡OJO! En el siguiente comando estamos indicando el hostname del servidor, por lo que deberá modificarse ese dato para que coincida con el de nuestro nodo servidor:
sed -i &quot;s/hostname=.*/hostname=bigtop-hostname0.iabd.local/&quot; /etc/ambari-agent/conf/ambari-agent.ini

systemctl enable chronyd
systemctl start chronyd
ambari-agent start
</code></pre></div>
<h4 id="arranque-del-servicio-en-los-agentes">ARRANQUE DEL SERVICIO EN LOS AGENTES</h4>
<p>Por último, vamos accediendo a los nodos Agente y ejecutamos lo siguiente:</p>
<div class="language-text highlight"><pre><span></span><code># ¡OJO! En el siguiente comando estamos indicando el hostname del servidor, por lo que deberá modificarse ese dato para que coincida con el de nuestro nodo servidor:
sed -i &quot;s/hostname=.*/hostname=bigtop-hostname0.iabd.local/&quot; /etc/ambari-agent/conf/ambari-agent.ini

systemctl enable chronyd
systemctl start chronyd
ambari-agent start
</code></pre></div>
<div class="admonition bug">
<p class="admonition-title">POSIBLE BUG</p>
<p>Es posible que nos lance un error al arrancar los Agentes, debido a que el enlace al binario de Python no se crea automáticamente. En ese caso, ejecutando los siguientes comandos debería solucionarse:</p>
<div class="language-text highlight"><pre><span></span><code>dnf install -y python3
ln -s /usr/bin/python3 /usr/bin/ambari-python-wrap

yum reinstall -y ambari-agent
ambari-agent start
</code></pre></div>
</div>
<p>Si todo ha ido bien, ya tenemos nuestro cluster Ambari operativo, y podemos acceder a él vía web, como veremos en el siguiente apartado.</p>
<h2 id="configuracion-de-hadoop-desde-ambari">CONFIGURACIÓN DE HADOOP DESDE AMBARI</h2>
<h3 id="acceso-a-la-interfaz-grafica">ACCESO A LA INTERFAZ GRÁFICA</h3>
<p>Una vez tenemos arrancados el servidor y los agentes Ambari, podemos ir a nuestro navegador y acceder a su interfaz gráfica a través de la dirección:</p>
<div class="language-text highlight"><pre><span></span><code>https://localhost:8080
</code></pre></div>
<div class="admonition tip">
<p class="admonition-title">CREDENCIALES</p>
<p>Tanto el usuario como la contraseña para acceder la primera vez es <code>admin</code>.</p>
</div>
<h3 id="instalacion-de-hadoop">INSTALACION DE HADOOP</h3>
<p>Cuando iniciemos sesión en Ambari, veremos que no hay nada configurado y la primera opción que nos muestra es la de crear nuestro cluster Hadoop usando un assitente de instalación, para ello pulsamos en el botón:</p>
<p><a class="md-button" href="# ."><small>LAUNCH INSTALL WIZARD</small></a></p>
<p>Comenzamos por poner un nombre a nuestro cluster y luego seleccionamos la versión de BIGTOP que queremos, nosotros elegimos la 3.3.0, ya que es la que hemos utilizado en nuestros nodos.</p>
<p>Más abajo, en esta misma página debemos marcar la opción de <strong>Usar Repositorio Local</strong> e indicar que distribución de SO tenemos, en nuestro caso Rocky Linux 8, esta basado en <strong>Red Hat 8</strong>. El resto de distribuciones las debemos borrar haciendo click en el botón <strong><code>- Remove</code></strong> que aparece en la parte izquierda de cada una de ellas.</p>
<p>Por último, especificamos en el campo <strong>"Base URL"</strong> donde se encuentra nuestro repositorio local. Aquí debemos indicar el valor que pusimos al configurar el <a href="#acceso-al-repositorio-local">Repositorio Local</a> en los nodos:</p>
<div class="language-text highlight"><pre><span></span><code>file:///var/repo/ambari
</code></pre></div>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small></a></p>
<p>En la siguiente página, donde dice <strong>Target Hosts</strong> tenemos que indicar el hostname de cada nodo de nuestro cluster, separados por saltos de línea.</p>
<p>Luego en el apartado de <strong>Host Registration Information</strong> como nosotros ya hemos copiado manualmente la clave SSH del servidor en el fichero de autorizados de los agentes, simplemente marcamos la opción de <code>Perform Manual Registration on Hosts</code>.</p>
<p><a class="md-button md-button--primary" href="# ."><small>REGISTER AND CONFIRM</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>Esperamos a que finalice el proceso de registro de los nodos y si todo va bien recibiremos un mensaje que dirá <code>All hosts checks passed on 4 registered hosts</code>.</p>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>Pasaremos a la siguiente ventana donde vamos a elegir los servicios que queremos instalar. En nuestro caso, como estamos creando un laboratorio de prácticas y nuestros recursos son limitados, seleccionaremos los más esenciales para empezar (siempre podemos instalar servicios más adelante, una vez que esté funcionando nuestro cluster desde la sección <em><code>Stack an Versions</code></em>).</p>
<p>Por lo tanto, solo mantendremos seleccionados <strong>HDFS</strong>, <strong>YARN</strong>, <strong>MapReduce2</strong>, <strong>ZooKeeper</strong> y <strong>Ambari Metrics</strong>. Más adelante, por ejemplo tendremos que instalar <strong>HBase</strong>, ya que sin él no funcionará Ambari Metrics.</p>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 13h-4v4h-2v-4H7v-2h4V7h2v4h4m2-8H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"/></svg></span> <a class="md-button" href="# ."><small>PROCEED ANYWAY</small></a></p>
<p>Continuaremos con la opción de <strong>Asign Masters</strong>, esto es personalizable según las necesidades y recursos de cada cluster, pero un ejemplo para un laboratorio similar al nuestro, podría ser el siguiente:</p>
<p><img alt="Ejemplo Masters Hadoop" src="../../img/mastersAmbari.png" /></p>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>Al igual que pasaba en el paso anterior, la configuración de <strong>Assign Slaves and Clients</strong> puede variar de un escenario a otro, en este caso podemos establecer algo como lo siguiente:</p>
<p><img alt="Ejemplo Slaves Hadoop" src="../../img/slavesAmbari.png" /></p>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>En la pestaña <strong>Credentials</strong> nos pedirá configurar usauraio y contraseña para Grafana, podemos dejarlo como <code>admin / admin</code>.</p>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>En las siguientes pestañas <strong>Directories</strong>, <strong>Accounts</strong> y <strong>All Configurations</strong>; podremos hacer cambios más adelante si fuese necesario, pero por el momento vamos a dejarlos con sus valores por defecto, así que solo pulsamos en siguiente para avanzar.</p>
<p><a class="md-button md-button--primary" href="# ."><small>DEPLOY</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>Comenzará el despliegue de los servicios en los nodos de nuestro cluster, esto puede llevar un tiempo según las caracteristicas de nuestra máquina</p>
<p>Además, el servicio <em>Timeline Service V2</em> va a fallar, pero no es un problema, así que vamos a ignorarlo por el momento. El resto de servicios, deberían instalarse con éxito, si no es así, podemos pulsar en el botón <strong><code>RETRY</code><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 3a9 9 0 0 0-9 9H0l4 4 4-4H5a7 7 0 0 1 7-7 7 7 0 0 1 7 7 7 7 0 0 1-7 7c-1.5 0-2.91-.5-4.06-1.3L6.5 19.14A9.1 9.1 0 0 0 12 21a9 9 0 0 0 9-9 9 9 0 0 0-9-9m2 9a2 2 0 0 0-2-2 2 2 0 0 0-2 2 2 2 0 0 0 2 2 2 2 0 0 0 2-2"/></svg></span></strong>, para volver a intentarlo. Si todo va bien, debería finalizar el despliegue con 2 o 3 warnings, pero sin errores.</p>
<div class="admonition warning">
<p class="admonition-title">FALTA DE RECURSOS</p>
<p>Si por algún motivo, como recursos insuficientes el despliegue se queda congelado y no responde; podemos conectarnos a la consola de nuestro nodo SERVIDOR y ejecutar el siguiente comando:
    ambari-server restart</p>
</div>
<p><a class="md-button md-button--primary" href="# ."><small>NEXT</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 13h-4v4h-2v-4H7v-2h4V7h2v4h4m2-8H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"/></svg></span> <a class="md-button" href="# ."><small>COMPLETE</small> <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14 16.94v-4H5.08l-.03-2.01H14V6.94l5 5Z"/></svg></span></a></p>
<p>Dejaremos unos segundos (o minutos) a que los servicios terminen de arrancar y podremos conectarnos a nuestro nodo SERVIDOR y comprobar que efectivamente tenemos habilitado el sistema de archivos de Hadoop:</p>
<div class="language-text highlight"><pre><span></span><code>con ambari_server
hadoop fs -ls /
</code></pre></div>
<p><em><small><a href="https://ambari.apache.org/docs/3.0.0/quick-start/environment-setup/docker-environment-setup/">Fuente 1: Ambari Docker Environmet Setup</a></small></em> , <em><small><a href="https://ambari.apache.org/docs/3.0.0/quick-start/installation-guide">Fuente 2: Ambari Installation Guide</a></small></em> , <em><small><a href="https://youtu.be/Ao95xAGsA20">Fuente 3: Edward Viaene</a></small></em></p>
<h2 id="despliegue-cluster-hadoop-sobre-docker">DESPLIEGUE CLÚSTER HADOOP SOBRE DOCKER</h2>
<figure>
    <img alt="Hadoop over Docker" src="https://miro.medium.com/v2/resize:fit:1200/0*yJCSYpFpPk_VU2zi.png" width="450" />
    <small><figcaption>Hadoop on Docker</figcaption></small>
</figure>
<p>El despliegue anterior nos serviría para un entorno de producción (sustituyendo los nodos virtuales por máquinas físicas), pero si queremos desplegar Hadoop para un entorno de desarrollo o laboratorio práctico, existen imágenes de docker ya preparadas para realizar esta tarea de una forma más rápida y menos compleja.</p>
<p>Existen varios repositorios Github donde podemos encontrar los archivos de configuración necesarios para llevar a cabo esta seugnda opción, pero uno de los más completos y estables es el de <a href="https://github.com/big-data-europe/" target="_blank">Big Data Europe</a>. Que podemos descargar en el siguiente <a href="https://github.com/big-data-europe/docker-hadoop/archive/refs/heads/master.zip" target="_blank">archivo comprimido</a> <img alt="📥" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4e5.svg" title=":inbox_tray:" />.</p>
<figure>
    <img alt="Big Data Europe" src="https://project-iasis.eu/sites/default/files/BDE.png" width="300" />
    <small><figcaption>Logo Big Data Europe</figcaption></small>
</figure>
<div class="admonition bug inline">
<p class="admonition-title">POSIBLE ERROR:</p>
<p>En ocasiones, uno de los contenedores se queda reseteando por falta de recursos. Así que en caso de que solo veamos 4 contenedores en ejecución, deberemos editar el fichero <code>docker-compose.yml</code> y añadir las siguientes líneas al final de la descripción de cada servicio:
    ulimits:
        nofile:
            soft: 65536
            hard: 65536</p>
</div>
<p>Descomprimimos el archivo y se nos creará la carpeta <strong>"docker-hadoop"</strong>. Abrimos un terminal en esta carpeta y ejecutamos el comando para hacer el despliegue mediante docker:</p>
<div class="language-text highlight"><pre><span></span><code>cd docker-hadoop
docker compose up -d
</code></pre></div>
<p>Una vez acabe de ejecutarse, podemos ver la red que ha creado para los contenedores con el comando:</p>
<div class="language-text highlight"><pre><span></span><code>docker network ls
</code></pre></div>
<p>Copiamos el nombre de la red y lo usaremos en el siguiente comando, para <strong>ver los nombres de los contenedores</strong> que se han creado <strong>y sus direcciones IP asignadas</strong> (debes sustituir dentro del comando el nombre de tu red):</p>
<div class="language-text highlight"><pre><span></span><code>docker network inspect &lt;nombre_de_la_red&gt; --format &#39;{{range .Containers}}{{.Name}}: {{.IPv4Address}}{{println}}{{end}}&#39;
</code></pre></div>
<p>Ahora, según lo que nos muestre el comando anterior, <strong>debemos añadir las direcciones IP (sin máscaras de red) con sus respectivos hostname al final del fichero <code>/etc/hosts</code></strong>. Para que podamos acceder a los diferentes recursos del clúster a través de nuestro navegador, usando sus nombres:</p>
<ul>
<li><strong>HDFS Master</strong>: http://namenode:9870</li>
<li><strong>HDFS Slave</strong>: http://datanode:9864</li>
<li><strong>Map Reduce</strong>: http://historyserver:8188</li>
<li><strong>YARN Slave</strong>: http://nodemanager:8042</li>
<li><strong>YARN Master</strong>: http://resourcemanager:8088</li>
</ul>
<p>Además de esas, hay que añadir dos traducciones más a <code>/etc/hosts</code>, que podemos ver en la interfaz gráfica de los servicios:</p>
<figure style="display: inline-block; margin-left: 2rem">
    <img alt="HDFS Datanode" src="../../img/azarquiel.png" width="275" />
    <small><figcaption>Captura Datanode</figcaption></small>
</figure>
<figure style="display: inline-block; margin-left: 2rem">
    <img alt="YARN Nodemanager" src="../../img/azarquiel.png" width="275" />
    <small><figcaption>Captura Nodemanager</figcaption></small>
</figure>
<p>Y con esto tendríamos nuestro clúster Hadoop listo. Que aunque sea un clúster simulado, pues los nodos corren como servicios dentro de una única máquina física, estós se configuran para actuar como nodos de un clúster distribuido, permitiendo ejecutar aplicaciones MapReduce y usar HDFS.</p>
<p><em><small><a href="https://escueladeinformatica.com/">Fuente 1: Escuela de Informática</a></small></em>, <em><small><a href="https://www.tutorialspoint.com/hadoop/index.htm">Fuente 2: Tutorials Point</a></small></em></p>
<h2 id="practica-1-hola-mundo-en-hadoop"><img alt="🎮" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f3ae.svg" title=":video_game:" /> PRÁCTICA 1: HOLA MUNDO EN HADOOP</h2>
<p>El primer ejemplo que suele realizarse como Hola Mundo en Hadoop, es una aplicación que cuente el número de ocurrencias de cada palabra en un documento de texto.</p>
<p>En este caso, nosotros vamos a <strong>contar las palabras de El Quijote</strong>, el cual podemos descargar en formato de texto plano, desde el siguiente <a href="https://gist.githubusercontent.com/jsdario/6d6c69398cb0c73111e49f1218960f79/raw/8d4fc4548d437e2a7203a5aeeace5477f598827d/el_quijote.txt">enlace de GitHub</a> <img alt="📥" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4e5.svg" title=":inbox_tray:" />.</p>
<p>Si se ha descargado en nuestra carpeta de Descargas, accedemos a ella desde el terminal y lo copiamos en el directorio raíz del nodo Maestro de HDFS. Luego creamos una carpeta personal dentro de HDFS y ahí moveremos nuestro fichero de texto. Los comandos serían estos:</p>
<div class="language-text highlight"><pre><span></span><code>cd ~/Descargas

docker cp el_quijote.txt namenode:/

docker exec -it namenode bash

hdfs dfs -mkdir /user/
hdfs dfs -mkdir /user/profe/

hdfs dfs -put el_quijote.txt /user/profe/

hdfs dfs -ls /user/profe/
</code></pre></div>
<p>Una vez tenemos el documento en nuestro sistema de ficheros HDFS, podemos procesar su información con Mapreduce. Para ello, Hadoop tiene una serie de ejemplos ya implementados para demostrar el uso de MapReduce.</p>
<p>Estos se encuentran en la carpeta <strong>$HADOOP_HOME/share/hadoop/mapreduce</strong>. Así pues, podemos ejecutar el programa <code>wordcount</code> con el siguiente comando (debemos lanzarlo dentro del nodo Maestro):</p>
<div class="language-text highlight"><pre><span></span><code>hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar \
wordcount /user/profe/el_quijote.txt /user/profe/salidaQuijote
</code></pre></div>
<h3 id="desarrollando-nuestros-scripts-mapreduce">DESARROLLANDO NUESTROS SCRIPTS MAPREDUCE</h3>
<p>La API de MapReduce está escrita en Java, pero mediante la utilidad Hadoop Streaming podemos usar MapReduce con cualquier lenguaje de programación compatible con sistemas Unix. Para entender mejor como funciona, vamos a recrear el ejemplo anterior usando Python.</p>
<p>Auque dependiendo del tipo de tarea que necesitemos llevar a cabo, el código de los scripts va a variar, siempre vamos a diferenciar dos grandes fases: el mapeo de datos y la reducción o resumen.</p>
<p>Para poder ejecutar los scripts, en nuestro caso, lo primero es instalar Python. En caso de haber levantado un clúster para desarrollo con Docker, como hemos visto más arriba, deberemos <strong>actualizar los origenes del repositorio</strong>, ya que usan una imágen Debian bastante antigua:</p>
<div class="language-text highlight"><pre><span></span><code>cd ~/Descargas
docker cp nodemanager:/etc/apt/sources.list ./
sudo nano sources.list

# Comentamos todas las líneas que tuviera el fichero y pegamos las siguientes 3 líneas al final:
deb http://archive.debian.org/debian stretch main
deb http://archive.debian.org/debian-security stretch/updates main
deb http://archive.debian.org/debian stretch-updates main

docker cp sources.list nodemanager:/etc/apt/
</code></pre></div>
<p>Con esto ya podremos instalar paquetes en el contendor donde lo hayamos realizado, en este caso nos interesa el <strong>nodemanager</strong>:</p>
<div class="language-text highlight"><pre><span></span><code>apt-get update

apt-get install nano

apt-get install python3
</code></pre></div>
<p>Una vez tenemos Python instalado, ahora sí, vamos a <strong>crear nuestros scripts</strong>. Los cuales se lanzan <strong>desde el Nodemanager</strong> (YARN slave):</p>
<h4 id="mapeo"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M2.672 23.969c-.352-.089-.534-.234-1.471-1.168C.085 21.688.014 21.579.018 20.999c0-.645-.196-.414 3.368-3.986 3.6-3.608 3.415-3.451 4.064-3.449.302 0 .378.016.62.14l.277.14 1.744-1.744-.218-.343c-.425-.662-.825-1.629-1.006-2.429a7.66 7.66 0 0 1 1.479-6.44c2.49-3.12 6.959-3.812 10.26-1.588 1.812 1.218 2.99 3.099 3.328 5.314.07.467.07 1.579 0 2.074a7.55 7.55 0 0 1-2.205 4.402 6.7 6.7 0 0 1-1.943 1.401c-.959.483-1.775.71-2.881.803-1.573.131-3.32-.305-4.656-1.163l-.343-.218-1.744 1.744.14.28c.125.241.14.316.14.617.003.651.156.467-3.426 4.049-2.761 2.756-3.186 3.164-3.398 3.261-.271.125-.69.171-.945.106zM17.485 13.95a6.43 6.43 0 0 0 4.603-3.51c1.391-2.899.455-6.306-2.227-8.108-.638-.43-1.529-.794-2.367-.962-.581-.117-1.809-.104-2.414.025a6.6 6.6 0 0 0-2.452 1.064c-.444.315-1.177 1.048-1.487 1.487a6.384 6.384 0 0 0 .38 7.907 6.4 6.4 0 0 0 3.901 2.136c.509.078 1.542.058 2.065-.037zm-3.738 7.376a81 81 0 0 1-2.196-.651c-.025-.028 1.207-4.396 1.257-4.449.023-.026 4.242 1.152 4.414 1.236.062.026-.003.288-.525 2.102a399 399 0 0 0-.635 2.236c-.025.087-.069.156-.097.156-.028-.003-1.028-.287-2.219-.631zm2.912.524c0-.053 1.227-4.333 1.246-4.347.047-.034 4.324-1.23 4.341-1.211.019.019-1.199 4.337-1.23 4.36-.02.019-4.126 1.191-4.259 1.218-.054.011-.098 0-.098-.019zm-7.105-1.911c.846-.852 1.599-1.627 1.674-1.728.171-.218.405-.732.472-1.015.026-.118.053-.352.058-.522l.011-.307.182-.051c.103-.028.193-.044.202-.034.023.025-1.207 4.321-1.246 4.36-.02.016-.677.213-1.464.436l-1.425.405 1.537-1.542zm8.289-3.06a1.4 1.4 0 0 1-.059-.187l-.044-.156.156-.028c1.339-.227 2.776-.856 3.908-1.713.16-.125.252-.171.265-.134.054.165.272.95.265.959-.034.034-4.48 1.282-4.492 1.261zm-15.083-1.3c-.05-.039-1.179-3.866-1.264-4.29-.016-.084.146-.044 2.174.536 2.121.604 2.192.629 2.222.74.028.098.011.129-.125.223-.084.059-.769.724-1.523 1.479a64 64 0 0 1-1.39 1.367c-.016 0-.056-.025-.093-.054zm.821-4.378c-1.188-.343-2.164-.623-2.167-.626-.016-.012 1.261-4.433 1.285-4.46.022-.022 4.422 1.211 4.469 1.252.009.009-.269 1.017-.618 2.239-.576 2.02-.643 2.224-.723 2.22-.05-.003-1.059-.285-2.247-.626zm2.959.538c.012-.031.212-.723.444-1.534l.42-1.476.056.321c.093.556.265 1.188.464 1.741.106.296.187.539.181.545-.008.006-.332.101-.719.212-.389.109-.741.21-.786.224q-.085.025-.059-.034zM4.905 6.112c-1.187-.339-2.167-.635-2.18-.654-.04-.062-1.246-4.321-1.23-4.338.026-.025 4.31 1.204 4.351 1.246.047.051 1.28 4.379 1.246 4.376L4.91 6.113zm2.148-1.713-.519-1.806-.078-.28 1.693-.483c.934-.265 1.724-.495 1.76-.508.034-.016-.083.14-.26.336A8.7 8.7 0 0 0 7.69 5.23a4 4 0 0 0-.132.561c0 .293-.115-.025-.505-1.39z"/></svg></span> Mapeo</h4>
<p>Para crear el mapeador en este ejemplo de contador de palabras, vamos a hacer que el programa recorra línea a línea el documento recibido y genere una salida donde cada palabra se muestre en una nueva linea. De modo que cada línea sea una <em>tupla</em> compuesta por la palabra, un tabulador y el número 1 (indicando que hay una ocurrencia).</p>
<div class="language-py highlight"><span class="filename">mapper.py</span><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="ch">#!/usr/bin/python3</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="c1"># -*-coding:utf-8 -*</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="k">for</span> <span class="n">linea</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="c1"># eliminamos los espacios de delante y de detrás</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">linea</span> <span class="o">=</span> <span class="n">linea</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="c1"># dividimos la línea en palabras</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">palabras</span> <span class="o">=</span> <span class="n">linea</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="c1"># creamos tuplas de (palabra, 1)</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="k">for</span> <span class="n">palabra</span> <span class="ow">in</span> <span class="n">palabras</span><span class="p">:</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="se">\t</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">palabra</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></code></pre></div>
<p>Si queremos probar su funcionamiento localmente, podemos hacerlo con:</p>
<div class="language-text highlight"><pre><span></span><code>cat el_quijote.txt | python3 mapper.py
</code></pre></div>
<h4 id="reduccion"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M1.88.46.46 1.88 5.59 7H2v2h7V2H7v3.59M11 7v2h10v6h2V9a2 2 0 0 0-2-2M7 11v10a2 2 0 0 0 2 2h6v-2H9V11m6.88 3.46-1.42 1.42L19.6 21H17v2h6v-6h-2v2.59"/></svg></span> Reducción</h4>
<p>A continuación, en el reducer vamos a recibir la salida del mapper y desglosamos la cadena, separando la palabra del contador.</p>
<p>Para llevar la cuenta de las palabras, vamos a meterlas dentro de un diccionario, donde cada palabra será una clave y los valores serán los contadores de cada palabra, los cuales se irán incrementando con cada ocurrencia encontrada.</p>
<div class="language-py highlight"><span class="filename">reducer.py</span><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="ch">#!/usr/bin/python3</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="c1"># -*-coding:utf-8 -*</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="c1"># inicializamos el diccionario</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="n">dictPalabras</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="k">for</span> <span class="n">linea</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>    <span class="c1"># quitamos espacios de sobra</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>    <span class="n">linea</span> <span class="o">=</span> <span class="n">linea</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>    <span class="c1"># parseamos la entrada de mapper.py</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>    <span class="n">palabra</span><span class="p">,</span> <span class="n">cuenta</span> <span class="o">=</span> <span class="n">linea</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>    <span class="c1"># convertimos cuenta de string a int</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>        <span class="n">cuenta</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">cuenta</span><span class="p">)</span>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>        <span class="c1"># cuenta no era un numero, descartamos la linea</span>
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>        <span class="k">continue</span>
</span><span id="__span-1-18"><a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="__span-1-19"><a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>        <span class="n">dictPalabras</span><span class="p">[</span><span class="n">palabra</span><span class="p">]</span> <span class="o">+=</span> <span class="n">cuenta</span>
</span><span id="__span-1-20"><a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>    <span class="k">except</span><span class="p">:</span>
</span><span id="__span-1-21"><a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a>        <span class="n">dictPalabras</span><span class="p">[</span><span class="n">palabra</span><span class="p">]</span> <span class="o">=</span> <span class="n">cuenta</span>
</span><span id="__span-1-22"><a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a>
</span><span id="__span-1-23"><a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a><span class="k">for</span> <span class="n">palabra</span> <span class="ow">in</span> <span class="n">dictPalabras</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="__span-1-24"><a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="se">\t</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">palabra</span><span class="p">,</span> <span class="n">dictPalabras</span><span class="p">[</span><span class="n">palabra</span><span class="p">]))</span>
</span></code></pre></div>
<p>Para probar el funcionamiento del proceso completo (<em>map + reduce</em>), podemos ejecutar lo siguiente:</p>
<div class="language-text highlight"><pre><span></span><code>cat el_quijote.txt | python3 mapper.py | python3 reducer.py &gt; salida.tsv
</code></pre></div>
<h4 id="hadoop-streaming"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 13H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25v-8.5C0 1.784.784 1 1.75 1M1.5 2.75v8.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.75.75 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25m5.28 1.72a.75.75 0 0 1 0 1.06L5.31 7l1.47 1.47a.75.75 0 0 1-.018 1.042.75.75 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.75.75 0 0 1 1.06 0m2.44 0a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.75.75 0 0 1-1.042-.018.75.75 0 0 1-.018-1.042L10.69 7 9.22 5.53a.75.75 0 0 1 0-1.06"/></svg></span> Hadoop Streaming</h4>
<p>Ahora pasaremos a ejecutar las aplicaciones anteriores dentro de Hadoop, para ello usaremos <em>Hadoop Streaming</em>. Que, como ya mencionamos, nos permite ejecutar trabajos (jobs) Map/Reduce con scripts codificados en cualquier lenguaje de programación que pueda leer de la entrada estándar (stdin) y escribir a la salida estándar (stdout).</p>
<p>En primer lugar, daremos permisos de ejecución a los scripts creados por el usuario:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="w">     </span>chmod<span class="w"> </span>+x<span class="w"> </span>mapper.py
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="w">     </span>chmod<span class="w"> </span>+x<span class="w"> </span>reducer.py
</span></code></pre></div>
<div class="admonition inline end bug">
<p class="admonition-title">IMPORTANTE:</p>
<p>El directorio de salida que especifiquemos, no debe existir previamente. De lo contrario, el comando fallará en su ejecución.</p>
</div>
<p>El comando utilizado ejecutar un job con Hadoop Streaming es <code>mapred streaming</code> y aunque tiene muchas opciones, las principales que se suelen usar son:</p>
<div class="language-text highlight"><pre><span></span><code>mapred streaming \
    -input &lt;directorio_entrada_HDFS&gt; \
    -output &lt;directorio_salida_HDFS&gt; \
    -mapper &lt;ruta_script_Mapper&gt; \
    -reducer &lt;ruta_script_Reducer&gt;
</code></pre></div>
<p>Como en nuestro caso, estamos ejecutando scripts locales al nodo, que no están en el sistema de ficheros del clúster, usaremos también la opción <code>-files</code>, para cargalos en los nodos Hadoop y nos podría quedar algo parecido al siguiente ejemplo:</p>
<div class="language-text highlight"><pre><span></span><code>mapred streaming -files mapper.py,reducer.py \
-input /user/profe/el_quijote.txt \
-output /user/profe/salidaPY \
-mapper ./mapper.py -reducer ./reducer.py
</code></pre></div>
<p><em><small><a href="https://aitor-medrano.github.io/iabd/hadoop/hadoop.html">Fuente: Aitor Medrano</a></small></em></p>
<h2 id="practica-2-trabajando-con-hdfs"><img alt="🎮" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f3ae.svg" title=":video_game:" /> PRÁCTICA 2: TRABAJANDO CON HDFS</h2>
<p><a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html">Guía oficial comandos HDFS</a></p>
<p><a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html">Guía oficial shell FS Hadoop</a></p>
<h3 id="_1"></h3>
<p><em><small><a href="https://aitor-medrano.github.io/iabd/hadoop/hdfs.html">Fuente: Aitor Medrano</a></small></em></p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Licencia CC BY-NC-SA 4.0 | Lorenzo LV - 2025
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
    <a href="https://github.com/ProfeAzarquiel" target="_blank" rel="noopener" title="ProfeAzarquiel on GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["content.code.copy", "content.tabs.link", "navigation.indexes"], "search": "../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
    
  </body>
</html>