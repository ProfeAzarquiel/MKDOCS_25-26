{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"MATERIALES FP INFORM\u00c1TICA","text":"<p>P\u00c1GINA EN CONSTRUCCI\u00d3N</p> <p>Esta web se encuentra actualmente en desarrollo, por lo que es muy posible que encuentres secciones en blanco o apartados incompletos.</p> <p>Los contenidos se actualizan casi a diario, para intentar que los materiales sean lo m\u00e1s completos posibles.</p> <p>\u00cdNDICE DE CONTENIDOS:</p> <ol> <li>COMPUTACI\u00d3N EN LA NUBE </li> <li>BIGDATA APLICADO </li> <li>DISE\u00d1O WEB </li> <li>PYTHON </li> </ol> <p>MATERIALES FORMACI\u00d3N PROFESIONAL INFORM\u00c1TICA by Lorenzo Le\u00f3n Valor in collaboration with Jos\u00e9 Enrique Ati\u00e9nzar, is licensed under CC BY-NC-SA 4.0</p> <p>Realizado con Material for MkDocs</p>"},{"location":"BIGDATA/indexb/","title":"BIGDATA APLICADO","text":"<p>\u00cdNDICE DE CONTENIDOS:</p> <ol> <li>Libros y Herramientas \u00datiles</li> <li>Introducci\u00f3n a BigData</li> <li>Ingesta de Datos con Nifi</li> <li>Ecosistema Hadoop</li> </ol> <p>MATERIALES FORMACI\u00d3N PROFESIONAL INFORM\u00c1TICA by Lorenzo Le\u00f3n Valor is licensed under CC BY-NC-SA 4.0</p>"},{"location":"BIGDATA/ud0/","title":"LIBROS Y HERRAMIENTAS \u00daTILES PARA EL DESARROLLO DEL M\u00d3DULO","text":""},{"location":"BIGDATA/ud0/#libros-de-referencia","title":"LIBROS DE REFERENCIA","text":""},{"location":"BIGDATA/ud0/#herramientas-web-utiles","title":"HERRAMIENTAS WEB \u00daTILES","text":""},{"location":"BIGDATA/ud1/","title":"INTRODUCCI\u00d3N AL ECOSISTEMA BIGDATA","text":""},{"location":"BIGDATA/ud1/#sistemas-de-almacenamiento-y-herramientas-del-centro-de-datos","title":"Sistemas de almacenamiento y herramientas del centro de datos","text":""},{"location":"BIGDATA/ud1/#almacenamiento-de-datos-masivo","title":"Almacenamiento de datos masivo","text":""},{"location":"BIGDATA/ud1/#procesamiento-de-datos","title":"Procesamiento de datos","text":""},{"location":"BIGDATA/ud1/#analitica-de-big-data-en-los-ecosistemas-de-almacenamiento","title":"Anal\u00edtica de Big Data en los ecosistemas de almacenamiento","text":""},{"location":"BIGDATA/ud1/#big-data-y-cloud","title":"Big Data y Cloud","text":""},{"location":"BIGDATA/ud1/#gestion-de-sistemas-de-almacenamiento-y-ecosistemas-big-data","title":"Gesti\u00f3n de sistemas de almacenamiento y ecosistemas Big Data","text":""},{"location":"BIGDATA/ud1/#computacion-distribuida-computacion-paralela","title":"Computaci\u00f3n distribuida. Computaci\u00f3n paralela","text":""},{"location":"BIGDATA/ud1/#sistemas-de-almacenamiento-distribuidos-tolerancia-a-fallos","title":"Sistemas de almacenamiento distribuidos. Tolerancia a fallos","text":""},{"location":"BIGDATA/ud1/#herramientas","title":"Herramientas","text":""},{"location":"BIGDATA/ud1/#generacion-de-mecanismos-de-integridad-de-los-datos-y-comprobacion-de-mantenimiento-de-sistemas-de-ficheros","title":"Generaci\u00f3n de mecanismos de Integridad de los datos y Comprobaci\u00f3n de mantenimiento de sistemas de ficheros","text":""},{"location":"BIGDATA/ud1/#calidad-de-los-datos","title":"Calidad de los datos","text":""},{"location":"BIGDATA/ud1/#comprobacion-de-la-integridad-de-datos-de-los-sistemas-de-ficheros-distribuidos-sumas-de-verificacion","title":"Comprobaci\u00f3n de la integridad de datos de los sistemas de ficheros distribuidos. Sumas de verificaci\u00f3n","text":""},{"location":"BIGDATA/ud1/#movimiento-de-datos-entre-clusters-actualizacion-y-migracion-metadatos","title":"Movimiento de datos entre clusters. Actualizaci\u00f3n y migraci\u00f3n. Metadatos","text":""},{"location":"BIGDATA/ud1/#monitorizacion-optimizacion-y-solucion-de-problemas","title":"Monitorizaci\u00f3n, optimizaci\u00f3n y soluci\u00f3n de problemas","text":""},{"location":"BIGDATA/ud1/#herramientas-de-monitorizacion","title":"Herramientas de monitorizaci\u00f3n","text":""},{"location":"BIGDATA/ud1/#analisis-de-los-historicos","title":"An\u00e1lisis de los hist\u00f3ricos","text":""},{"location":"BIGDATA/ud1/#monitorizacion-del-cluster","title":"Monitorizaci\u00f3n del cl\u00faster","text":""},{"location":"BIGDATA/ud1/#validacion-de-tecnicas-big-data-en-la-toma-de-decisiones-en-la-inteligencia-de-negocio","title":"Validaci\u00f3n de t\u00e9cnicas Big Data en la toma de decisiones en la Inteligencia de Negocio","text":""},{"location":"BIGDATA/ud1/#modelos-de-inteligencia-de-negocios","title":"Modelos de Inteligencia de negocios","text":""},{"location":"BIGDATA/ud1/#proceso-del-modelo-kdd-knowledge-discovery-in-databases","title":"Proceso del modelo KDD (Knowledge Discovery in Databases)","text":""},{"location":"BIGDATA/ud1/#etapas","title":"Etapas","text":""},{"location":"BIGDATA/ud1/#seleccion","title":"Selecci\u00f3n","text":""},{"location":"BIGDATA/ud1/#limpieza","title":"Limpieza","text":""},{"location":"BIGDATA/ud1/#transformacion-de-datos","title":"Transformaci\u00f3n de datos","text":""},{"location":"BIGDATA/ud1/#mineria-de-datos","title":"Miner\u00eda de datos","text":""},{"location":"BIGDATA/ud1/#interpretacion","title":"Interpretaci\u00f3n","text":""},{"location":"BIGDATA/ud1/#evaluacion-de-datos","title":"Evaluaci\u00f3n de datos","text":""},{"location":"BIGDATA/ud1/#implantacion-de-modelos-de-inteligencia-de-negocios-bi","title":"Implantaci\u00f3n de modelos de inteligencia de negocios BI","text":""},{"location":"BIGDATA/ud1/#tecnicas-de-validacion-de-modelos-bi","title":"T\u00e9cnicas de validaci\u00f3n de modelos BI","text":""},{"location":"BIGDATA/ud2/","title":"INGESTA DE DATOS CON APACHE/NIFI","text":""},{"location":"BIGDATA/ud3/","title":"APACHE HADOOP","text":"<p>Hadoop es un proyecto open source que aglutina una serie de herramientas para el procesamiento distribuido de grandes conjuntos de datos a trav\u00e9s de cl\u00fasters de ordenadores utilizando modelos de programaci\u00f3n sencillos.</p> Logo Apache Hadoop"},{"location":"BIGDATA/ud3/#arquitectura-basica","title":"ARQUITECTURA B\u00c1SICA","text":"<ul> <li>COMMON UTILITIES: conjunto de librerias y ficheros necesarios para ejecutar Haddop.</li> <li>YARN: gestor de recursos, se encarga de repartir los recursos disponibles en cada nodo entre las distitnas aplicaciones.</li> <li>HDFS: sistema de archivos distribuidos instalado en los distintos nodos del cluster y va almacenando mediante replicaci\u00f3n los datos.</li> <li>MapReduce: son los procesos implementados en c\u00f3digo por el usuario, para procesar los datos.</li> </ul> <p>Si queremos empezar a utilizar Hadoop y todo su ecosistema, disponemos de diversas distribuciones con toda la arquitectura, herramientas y configuraci\u00f3n ya preparadas. Las m\u00e1s rese\u00f1ables son:</p> <ul> <li>EMR de AWS (Amazon Elastic MapReduce)</li> <li>CDP de Cloudera: es la evoluci\u00f3n de CDH y HDP (antiguas distribuciones de c\u00f3digo abierto de Apache Hadoop y otros proyectos relacionados, actualmente sin soporte). Cloudera ofrecia estas distribuciones de forma gratuita, cosa que ya no sucede con CDP, pero a\u00fan se puede descargar la MV de HDP en el siguiente enlace.</li> <li>Azure HDInsight de Microsoft.</li> <li>DataProc de Google.</li> </ul> <p>Nosotros vamos a usar una <code>Apache Ambari</code>, proyecto dedicado a simplificar la administraci\u00f3n, aprovisionamiento, la gesti\u00f3n y la monitorizaci\u00f3n de cl\u00fasteres Apache Hadoop; proporcionando una interfaz web de administraci\u00f3n intuitiva y f\u00e1cil de usar.</p> <p>No todo el monte es Or\u00e9gano </p> <p>Hadoop facilita el trabajo con grandes vol\u00famenes de datos, pero montar un cl\u00faster funcional no es una cosa trivial. Existen gestores de cl\u00fasters que hacen las cosas un poco m\u00e1s sencillas (como Apache Ambari o Apache Mesos), aunque la tendencia es utilizar una soluci\u00f3n cloud que nos evita toda la instalaci\u00f3n y configuraci\u00f3n.</p>"},{"location":"BIGDATA/ud3/#hdfs","title":"HDFS","text":"<p>Es la capa de almacenamiento de Hadoop o lo que es lo mismo, un sistema de ficheros distribuido, con gran tolerancia a fallos, facil de escalar de forma incremental y capaz de almacenar grandes vol\u00famenes de datos.</p> <p>Su funcionamiento se basa en repartir los datos entre todos los nodos del cl\u00faster, dividiendo los ficheros en bloques y almacenando copias duplicadas en diferentes nodos. Por defecto cada bloque se replica en 3 nodos distintos (esto se conoce como factor de replicaci\u00f3n).</p> <p>Est\u00e1 planteado para escribir los datos una vez y leerlos muchas veces, Write Once, Read Many (WORM). Adem\u00e1s, una vez escritos, los datos son inmutables; es decir, cada fichero de HDFS solo permite a\u00f1adir contenido (append-only) o eliminar el fichero completo.</p> <p>Modificaci\u00f3n de datos en HDFS</p> <p>Tanto HBase como Hive ofrecen una capa por encima de HDFS para dar soporte a la modificaci\u00f3n de los datos, como en cualquier base de datos.</p>"},{"location":"BIGDATA/ud3/#tipos-de-nodos","title":"Tipos de Nodos","text":"<p>En HDFS vamos a distinguir 2 tipos de m\u00e1quinas o roles:</p> <ul> <li> <p>Namenode: act\u00faa como m\u00e1ster y almacena todos los metadatos necesarios para construir el sistema de ficheros a partir de sus bloques. Tiene control sobre d\u00f3nde est\u00e1n todos los bloques.</p> </li> <li> <p>Datanode: son los nodos esclavo, se limitan a almacenar los bloques que componen cada fichero.</p> </li> </ul>"},{"location":"BIGDATA/ud3/#los-bloques","title":"Los Bloques","text":"<p>Un bloque es la cantidad m\u00ednima de datos que puede ser le\u00edda o escrita en HDFS, su tama\u00f1o predeterminado son 128 MB.</p> <p>Todos los ficheros en HDFS estan divididos en bloques, por lo que si subimos un fichero de 600MB, se dividir\u00e1 en 5 bloques de 128MB, que se distribuir\u00e1n por todos los nodos de datos del cl\u00faster.</p> <p>Adem\u00e1s, a trav\u00e9s del factor de replicaci\u00f3n (por defecto 3), cada bloque se almacena varias veces en diferentes nodos. As\u00ed que finalmente, nuestro archivo de 600MB estar\u00e1 repartido en 15 bloques entre todos los nodos del cl\u00faster.</p> Divisi\u00f3n y replicaci\u00f3n HDFS"},{"location":"BIGDATA/ud3/#yarn-yet-another-resource-negotiator","title":"YARN (Yet Another Resource Negotiator)","text":"<p>Este framework proporciona un planificador de recursos desvinculado de los trabajos que se encuentran en ejecuci\u00f3n en el cl\u00faster, ya que separa la gesti\u00f3n de recursos y la planificaci\u00f3n y monitorizaci\u00f3n de trabajos. Lo que hace posible tener un gestor global (Resource Manager) por cluster y un Application Master por aplicaci\u00f3n (considerando aplicaci\u00f3n tanto un \u00fanico job, como un conjunto de jobs* c\u00edclicos).</p> <p>Se divide en tres componentes principales: un Resource Manager, m\u00faltiples Node Manager y varios ApplicationMaster.</p> <p>El Resource Manager y el Node Manager componen el framework de computaci\u00f3n de datos. En concreto, el ResourceManager controla el arranque de la aplicaci\u00f3n, siendo la autoridad que orquesta los recursos entre todas las aplicaciones del sistema. A su vez, tendremos tantos NodeManager como datanodes tenga nuestro cl\u00faster, siendo responsables de gestionar y monitorizar los recursos de cada nodo (CPU, memoria, disco y red) y reportar estos datos al Resource Manager.</p> <p>El Application Master es una librer\u00eda espec\u00edfica encargada de negociar los recursos con el ResourceManager y de trabajar con los Node Manager para ejecutar y monitorizar las tareas.</p> <p>Finalmente, en nuestro cl\u00faster, tendremos corriendo un Job History Server encargado de archivar los fichero de log de los jobs. Aunque es un proceso opcional, se recomienda su uso para monitorizar los jobs ejecutados.</p> Arquitectura YARN"},{"location":"BIGDATA/ud3/#map-reduce","title":"MAP-REDUCE","text":"<p>Hadoop MapReduce es un paradigma de procesamiento de datos caracterizado por dividirse en dos fases o pasos diferenciados: Map y Reduce. Estos subprocesos asociados a la tarea se ejecutan de manera distribuida, en diferentes nodos de procesamiento o esclavos. Para controlar y gestionar su ejecuci\u00f3n, existe un proceso Master o Job Tracker. Tambi\u00e9n es el encargado de aceptar los nuevos trabajos enviados al sistema por los clientes. Los resultados del procesamiento se pueden almacenar en el mismo sistema de almacenamiento o bien en una base de datos o sistema externo.</p>"},{"location":"BIGDATA/ud3/#fases-de-hadoop-mapreduce","title":"Fases de Hadoop MapReduce","text":"<p>Map: se ejecuta en subtareas llamadas mappers. Estos componentes son los responsables de generar pares clave-valor filtrando, agrupando, ordenando o transformando los datos originales. Los pares de datos intermedios, no se almacenan en HDFS.</p> <p>Shuffle: puede no ser necesaria. Es el paso intermedio entre Map y reduce que ayuda a recoger los datos y ordenarlos de manera conveniente para el procesamiento. Con esta fase, se pretende agregar las ocurrencias repetidas en cada uno de los mappers.</p> <p>Reduce: gestiona la agregaci\u00f3n de los valores producidos por todos los mappers del sistema (o por la fase shuffle) de tipo clave-valor en funci\u00f3n de su clave. Por \u00faltimo, cada reducer genera su fichero de salida de forma independiente, generalmente escrito en HDFS.</p> Fases MapReduce"},{"location":"BIGDATA/ud3/#limitaciones","title":"Limitaciones","text":"<p>MapReduce es la implementaci\u00f3n b\u00e1sica de un framework de procesamiento en paralelo para cargas big data, por lo que al final tiene ciertas limitaciones como, por ejemplo, hasta que la fase map completa su procesamiento, los reducers no empiezan a ejecutarse; o que no se puede controlar su orden de ejecuci\u00f3n.</p> <p>Es por ello, que existen alternativas como Apache Spark, Apache Hive o Pig; las cuales mantienen los principales puntos de MapReduce, pero son capaces de usar HDFS de manera m\u00e1s eficiente. La que resalta m\u00e1s entre el resto es SPARK, la cual veremos m\u00e1s adelante.</p> <p>Fuente 1: Aitor Medrano, Fuente 2: Oscar Fern\u00e1ndez</p>"},{"location":"BIGDATA/ud3/#despliegue-cluster-hadoop-con-ambari-y-docker","title":"DESPLIEGUE CL\u00daSTER HADOOP CON AMBARI Y DOCKER","text":"Logo Apache Ambari"},{"location":"BIGDATA/ud3/#escenario-e-imagen-empleada","title":"ESCENARIO E IMAGEN EMPLEADA","text":"<p>Partimos de una m\u00e1quina con Ubuntu Desktop 25.10, en la que tenemos instalado Docker 28.5.1. En ella, vamos a desplegar un entorno con cuatro contenedores, consistente en:</p> <ul> <li>Un contenedor ( bigtop-hostname0) para el servidor Ambari.</li> <li>Tres contenedores ( bigtop-hostname1, bigtop-hostname2, bigtop-hostname3) para agentes de Ambari.</li> <li>Un volumen compartido para el repositorio Ambari.</li> </ul> <p>La imagen que usaremos <code>bigtop/puppet:trunk-rockylinux-8imagen</code>, forma parte del proyecto Apache BigTop y proporciona un marco de trabajo para la creaci\u00f3n y prueba de proyectos relacionados con Hadoop, ya que viene preconfigurada con muchas de las dependencias necesarias para los servicios de Ambari y Hadoop. Esta imagen incluye:</p> <ul> <li>Rocky Linux 8 como sistema operativo base</li> <li>Java y herramientas de desarrollo preinstaladas</li> <li>Puppet para la gesti\u00f3n de la configuraci\u00f3n</li> <li>Configuraciones de sistema optimizadas para los servicios del ecosistema Hadoop</li> </ul>"},{"location":"BIGDATA/ud3/#configuracion-del-entorno","title":"CONFIGURACI\u00d3N DEL ENTORNO","text":""},{"location":"BIGDATA/ud3/#atajo-util-para-docker","title":"ATAJO \u00daTIL PARA DOCKER","text":"<p>Este es un paso opcional, pero que puede ahorrarnos mucho tiempo en el futuro. Vamos a crear una funci\u00f3n para conectarnos m\u00e1s facilmente al terminal de consola de un contenedor:</p> <pre><code>sudo su -\n\nnano /etc/profile\n\n# A\u00f1adimos la siguiente funci\u00f3n al final del fichero\ncon() {\n    docker exec -it \"$1\" /bin/bash\n}\n\n# Aplicamos los cambios inmediatemente\nsource /etc/profile\n</code></pre> <p>Tras a\u00f1adir esta funci\u00f3n, podr\u00e1 acceder r\u00e1pidamente a cualquier contenedor utilizando:</p> <pre><code>con contenedor_linux\n</code></pre>"},{"location":"BIGDATA/ud3/#creacion-de-carpetas-y-fichero-hosts","title":"CREACI\u00d3N DE CARPETAS Y FICHERO HOSTS","text":"<p>Creamos una carpeta Ambari y dentro de ella, a\u00f1adiremos dos carpetas m\u00e1s:</p> <pre><code>mkdir -p Ambari\ncd Ambari\nmkdir -p ambari-repo\nmkdir -p conf\n</code></pre> <p>Por un lado, accedemos a la carpeta ambari-repo y descargamos los p\u00e1quetes RPM de Ambari y Bigtop:</p> <pre><code>cd ambari-repo/\n\n//PARA ROCKY LINUX 8 (que es el SO que vamos a usar para nuestros nodos)\nwget -r -np -nH --cut-dirs=4 --reject 'index.html*' https://www.apache-ambari.com/dist/ambari/3.0.0/rocky8/\nwget -r -np -nH --cut-dirs=4 --reject 'index.html*' https://www.apache-ambari.com/dist/bigtop/3.3.0/rocky8/\n</code></pre> <p>Por otro lado, accedemos a la carpeta conf y creamos el fichero hosts, con la siguiente informaci\u00f3n:</p> <pre><code>cd conf\n\ncat &gt; hosts &lt;&lt; EOF\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n\n# Container hostnames\n192.168.20.2  bigtop-hostname0.iabd.local\n192.168.20.3  bigtop-hostname1.iabd.local\n192.168.20.4  bigtop-hostname2.iabd.local\n192.168.20.5  bigtop-hostname3.iabd.local\nEOF\n</code></pre> <p>ATENCI\u00f3N:</p> <p>Los valores indicados m\u00e1s arriba para el fichero hosts, deben personalizarse seg\u00fan la instalaci\u00f3n de cada uno, estos est\u00e1n configurados para que coincidan con el docker-compose.yaml que vemos m\u00e1s abajo. Pero es muy recomendable confirmar bien estos datos, despues de levantar el escenario Docker Compose si queremos evitarnos problemas durante la instalaci\u00f3n de Hadoop. Por un lado, comprobar el direccionamiento que se le ha asignado a cada contenedor con <code>docker network inspect ambari_net</code>; y por otro lado, los hostnames deben ser los que les asignemos m\u00e1s adelante a cada nodo (ver apartado), seguidos de un nombre de dominio inventado (esto es necesario para que luego ambari los reconozca como hostnames v\u00e1lidos).</p>"},{"location":"BIGDATA/ud3/#el-fichero-docker-compose","title":"EL FICHERO DOCKER-COMPOSE","text":"<p>Utilizaremos el siguiente fichero <code>docker-compose.yaml</code> para desplegar nuestro escenario:</p> nano docker-compose.yaml <pre><code>services:\n    bigtop-hostname0:\n        container_name: ambari_server\n        hostname: bigtop-hostname0\n        command: /sbin/init\n        domainname: bigtop.apache.org\n        image: bigtop/puppet:trunk-rockylinux-8\n        mem_limit: 8g\n        mem_swappiness: 0\n        ports:\n            - \"8080:8080\"\n        privileged: true\n        networks:\n        red_cluster:\n            ipv4_address: 192.168.20.2\n        volumes:\n            - ./ambari-repo:/var/repo/ambari\n            - ./conf/hosts:/etc/hosts\n\n    bigtop-hostname1:\n        container_name: ambari_agent1\n        hostname: bigtop-hostname1\n        command: /sbin/init\n        domainname: bigtop.apache.org\n        image: bigtop/puppet:trunk-rockylinux-8\n        mem_limit: 8g\n        mem_swappiness: 0\n        privileged: true\n        networks:\n            red_cluster:\n                ipv4_address: 192.168.20.3\n        volumes:\n            - ./ambari-repo:/var/repo/ambari\n            - ./conf/hosts:/etc/hosts\n\n    bigtop-hostname2:\n        container_name: ambari_agent2\n        hostname: bigtop-hostname2\n        command: /sbin/init\n        domainname: bigtop.apache.org\n        image: bigtop/puppet:trunk-rockylinux-8\n        mem_limit: 8g\n        mem_swappiness: 0\n        privileged: true\n        networks:\n            red_cluster:\n                ipv4_address: 192.168.20.4\n        volumes:\n            - ./ambari-repo:/var/repo/ambari\n            - ./conf/hosts:/etc/hosts\n\n    bigtop-hostname3:\n        container_name: ambari_agent3\n        hostname: bigtop-hostname3\n        command: /sbin/init\n        domainname: bigtop.apache.org\n        image: bigtop/puppet:trunk-rockylinux-8\n        mem_limit: 8g\n        mem_swappiness: 0\n        privileged: true\n        networks:\n            red_cluster:\n                ipv4_address: 192.168.20.5\n        volumes:\n            - ./ambari-repo:/var/repo/ambari\n            - ./conf/hosts:/etc/hosts\n\nnetworks:\n    red_cluster:\n        name: ambari_net\n        driver: bridge\n        ipam:\n            driver: default\n            config:\n                - subnet: 192.168.20.0/24\n                gateway: 192.168.20.1\n</code></pre> <p>Arrancamos el escenario con el comando:</p> <pre><code>docker compose up -d\n</code></pre> <p>Y verificamos que se han creado nuestros contenedores y que hay conectividad entre ellos:</p> <pre><code>docker ps\n\ndocker exec -it ambari-bigtop-hostname0 ping -c 4 ambari-bigtop-hostname1\ndocker exec -it ambari-bigtop-hostname0 ping -c 4 ambari-bigtop-hostname2\ndocker exec -it ambari-bigtop-hostname0 ping -c 4 ambari-bigtop-hostname3\n</code></pre>"},{"location":"BIGDATA/ud3/#actualizacion-del-hostname-de-cada-nodo","title":"ACTUALIZACION DEL HOSTNAME DE CADA NODO","text":"<p>Nos conectamos a cada nodo de nuestro cluster y si vemos que el hostname de la m\u00e1quina no coincide con el que hemos configurado en el fichero hosts, lo actualizamos con el siguiente comando (es posible que haya que lanzarlo 2 veces):</p> <pre><code>con ambari_server\nhostnamectl set-hostname bigtop-server\n</code></pre>"},{"location":"BIGDATA/ud3/#conexion-ssh-entre-los-contenedores","title":"CONEXION SSH ENTRE LOS CONTENEDORES","text":"<p>Mediante la funci\u00f3n que creamos al prinicipio, vamos conectandonos al terminal de consola de cada uno de nuestros contenedores e instalamos OPENSSH:</p> <pre><code>con ambari_server\ndnf install -y sudo openssh-server openssh-clients which iproute net-tools less vim-enhanced\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\nsystemctl enable sshd\nsystemctl start sshd\nexit\n</code></pre> <p>Luego desde nuestra m\u00e1quina ubuntu copiamos la clave del SERVIDOR y luego la pegamos en cada uno de los AGENTES:</p> <pre><code>docker exec -i ambari-bigtop-hostname0 bash -c 'cat ~/.ssh/id_rsa.pub' &gt; id_rsa.pub\n\ncat id_rsa.pub | docker exec -i ambari-bigtop-hostname1 bash -c 'cat &gt;&gt; ~/.ssh/authorized_keys'\ncat id_rsa.pub | docker exec -i ambari-bigtop-hostname2 bash -c 'cat &gt;&gt; ~/.ssh/authorized_keys'\ncat id_rsa.pub | docker exec -i ambari-bigtop-hostname3 bash -c 'cat &gt;&gt; ~/.ssh/authorized_keys'\n\nrm id_rsa.pub\n</code></pre> <p>Finalmente nos volvemos a conectar al SERVIDOR y comprobamos la conectividad con los agentes:</p> <pre><code>con ambari_server\nssh -o StrictHostKeyChecking=no ambari-bigtop-hostname1 echo \"Connection successful\"\nssh -o StrictHostKeyChecking=no ambari-bigtop-hostname2 echo \"Connection successful\"\nssh -o StrictHostKeyChecking=no ambari-bigtop-hostname3 echo \"Connection successful\"\n</code></pre>"},{"location":"BIGDATA/ud3/#instalacion-de-software-externo-necesario","title":"INSTALACI\u00d3N DE SOFTWARE EXTERNO NECESARIO","text":"<p>Repetimos los siguientes pasos en todos los nodos del cluster:</p> <pre><code>con ambari_server\ndnf install -y initscripts wget curl tar unzip git\ndnf install -y dnf-plugins-core\ndnf config-manager --set-enabled powertools\ndnf update -y\ndnf install -y nano\ndnf install -y python3\n</code></pre> <p>Editar el siguiente fichero para que indique <code>enabled=1</code> y no tenga ninguna linea comentada, excepto las dos superiores:</p> <pre><code>nano /etc/yum.repos.d/Rocky-Devel.repo\ndnf repolist | grep devel\n</code></pre>"},{"location":"BIGDATA/ud3/#instalacion-de-ambari","title":"INSTALACI\u00d3N DE AMBARI","text":""},{"location":"BIGDATA/ud3/#acceso-al-repositorio-local","title":"ACCESO AL REPOSITORIO LOCAL","text":"<p>Luego configuramos el acceso de los paquetes de estos repositorios, en todos los nodos del Cluster:</p> <pre><code>con ambari_server\ndnf install -y createrepo\ncd /var/repo/ambari/\ncreaterepo .\n\ntee /etc/yum.repos.d/ambari.repo &lt;&lt; EOF\n[ambari]\nname=Ambari Repository\nbaseurl=file:///var/repo/ambari\ngpgcheck=0\nenabled=1\nEOF\n</code></pre>"},{"location":"BIGDATA/ud3/#instalacion-de-paquetes","title":"INSTALACI\u00d3N DE PAQUETES","text":"<p>Instalamos los siguientes paquetes en todos los nodos del cluster:</p> <pre><code>con ambari_server\n\nyum install -y iproute\nyum install -y python3-distro\nyum install -y java-17-openjdk-devel\nyum install -y java-1.8.0-openjdk-devel\nyum install -y chrony\nyum install -y ambari-agent\n\nyum remove -y rubygem-multi_json rubygem-semantic_puppet cpp-hocon rubygem-hocon rubygem-puppet-resource_api hiera leatherman ruby-facter rubygem-concurrent-ruby rubygem-deep_merge puppet rubygem-httpclient ruby-augeas facter yaml-cpp\n\ndnf clean all\ndnf makecache\n</code></pre> <p>Y adem\u00e1s de lo anterior, solo en el SERVIDOR, instalamos lo siguiente:</p> <pre><code>con ambari_server\n\nyum install -y python3-psycopg2\nyum install -y ambari-server\n</code></pre>"},{"location":"BIGDATA/ud3/#instalacion-y-configuracion-de-mysql","title":"INSTALACI\u00d3N Y CONFIGURACI\u00d3N DE MYSQL","text":"<p>Seguimos conectados al SERVIDOR y configuramos lo siguiente:</p> <pre><code>rpm -qa | grep mysql\nrpm -ev mysql-server --nodeps\nrpm -ev mysql-community-server --nodeps\n\nyum -y install https://dev.mysql.com/get/mysql80-community-release-el8-1.noarch.rpm\n\nyum -y install mysql-server\nsystemctl start mysqld.service\nsystemctl enable mysqld.service\n</code></pre> <p>Ahora configuramos en MySQL las BBDD y Usuarios que usaremos en el ecosistema Hadoop:</p> <pre><code>mysql\n\nCREATE USER 'ambari'@'localhost' IDENTIFIED BY 'ambari';\nGRANT ALL PRIVILEGES ON *.* TO 'ambari'@'localhost';\nCREATE USER 'ambari'@'%' IDENTIFIED BY 'ambari';\nGRANT ALL PRIVILEGES ON *.* TO 'ambari'@'%';\n\nCREATE DATABASE ambari CHARACTER SET utf8 COLLATE utf8_general_ci;\nCREATE DATABASE hive;\nCREATE DATABASE ranger;\nCREATE DATABASE rangerkms;\n\nCREATE USER 'hive'@'%' IDENTIFIED BY 'hive';\nGRANT ALL PRIVILEGES ON hive.* TO 'hive'@'%';\n\nCREATE USER 'ranger'@'%' IDENTIFIED BY 'ranger';\nGRANT ALL PRIVILEGES ON *.* TO 'ranger'@'%' WITH GRANT OPTION;\n\nCREATE USER 'rangerkms'@'%' IDENTIFIED BY 'rangerkms';\nGRANT ALL PRIVILEGES ON rangerkms.* TO 'rangerkms'@'%';\n\nFLUSH PRIVILEGES;\n\nexit\n\nmysql -uambari -pambari ambari &lt; /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql\n</code></pre>"},{"location":"BIGDATA/ud3/#arranque-de-los-serivicios-en-el-servidor","title":"ARRANQUE DE LOS SERIVICIOS EN EL SERVIDOR","text":"<p>Continuamos sin salir del SERVIDOR Ambari, y pasamos a arrancar los servicios JAVA, Amberi-Server y Ambari-Agent:</p> <pre><code>wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.28/mysql-connector-java-8.0.28.jar -O /usr/share/java/mysql-connector-java.jar\n\nambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar\n\necho \"server.jdbc.url=jdbc:mysql://localhost:3306/ambari?useSSL=true&amp;verifyServerCertificate=false&amp;enabledTLSProtocols=TLSv1.2\" &gt;&gt; /etc/ambari-server/conf/ambari.properties\n\nambari-server setup -s -j /usr/lib/jvm/java-1.8.0-openjdk --ambari-java-home /usr/lib/jvm/java-17-openjdk --database=mysql --databasehost=localhost --databaseport=3306 --databasename=ambari --databaseusername=ambari --databasepassword=ambari\n\nambari-server start\n\n# \u00a1OJO! En el siguiente comando estamos indicando el hostname del servidor, por lo que deber\u00e1 modificarse ese dato para que coincida con el de nuestro nodo servidor:\nsed -i \"s/hostname=.*/hostname=bigtop-hostname0.iabd.local/\" /etc/ambari-agent/conf/ambari-agent.ini\n\nsystemctl enable chronyd\nsystemctl start chronyd\nambari-agent start\n</code></pre>"},{"location":"BIGDATA/ud3/#arranque-del-servicio-en-los-agentes","title":"ARRANQUE DEL SERVICIO EN LOS AGENTES","text":"<p>Por \u00faltimo, vamos accediendo a los nodos Agente y ejecutamos lo siguiente:</p> <pre><code># \u00a1OJO! En el siguiente comando estamos indicando el hostname del servidor, por lo que deber\u00e1 modificarse ese dato para que coincida con el de nuestro nodo servidor:\nsed -i \"s/hostname=.*/hostname=bigtop-hostname0.iabd.local/\" /etc/ambari-agent/conf/ambari-agent.ini\n\nsystemctl enable chronyd\nsystemctl start chronyd\nambari-agent start\n</code></pre> <p>POSIBLE BUG</p> <p>Es posible que nos lance un error al arrancar los Agentes, debido a que el enlace al binario de Python no se crea autom\u00e1ticamente. En ese caso, ejecutando los siguientes comandos deber\u00eda solucionarse:</p> <pre><code>dnf install -y python3\nln -s /usr/bin/python3 /usr/bin/ambari-python-wrap\n\nyum reinstall -y ambari-agent\nambari-agent start\n</code></pre> <p>Si todo ha ido bien, ya tenemos nuestro cluster Ambari operativo, y podemos acceder a \u00e9l v\u00eda web, como veremos en el siguiente apartado.</p>"},{"location":"BIGDATA/ud3/#configuracion-de-hadoop-desde-ambari","title":"CONFIGURACI\u00d3N DE HADOOP DESDE AMBARI","text":""},{"location":"BIGDATA/ud3/#acceso-a-la-interfaz-grafica","title":"ACCESO A LA INTERFAZ GR\u00c1FICA","text":"<p>Una vez tenemos arrancados el servidor y los agentes Ambari, podemos ir a nuestro navegador y acceder a su interfaz gr\u00e1fica a trav\u00e9s de la direcci\u00f3n:</p> <pre><code>https://localhost:8080\n</code></pre> <p>CREDENCIALES</p> <p>Tanto el usuario como la contrase\u00f1a para acceder la primera vez es <code>admin</code>.</p>"},{"location":"BIGDATA/ud3/#instalacion-de-hadoop","title":"INSTALACION DE HADOOP","text":"<p>Cuando iniciemos sesi\u00f3n en Ambari, veremos que no hay nada configurado y la primera opci\u00f3n que nos muestra es la de crear nuestro cluster Hadoop usando un assitente de instalaci\u00f3n, para ello pulsamos en el bot\u00f3n:</p> <p>LAUNCH INSTALL WIZARD</p> <p>Comenzamos por poner un nombre a nuestro cluster y luego seleccionamos la versi\u00f3n de BIGTOP que queremos, nosotros elegimos la 3.3.0, ya que es la que hemos utilizado en nuestros nodos.</p> <p>M\u00e1s abajo, en esta misma p\u00e1gina debemos marcar la opci\u00f3n de Usar Repositorio Local e indicar que distribuci\u00f3n de SO tenemos, en nuestro caso Rocky Linux 8, esta basado en Red Hat 8. El resto de distribuciones las debemos borrar haciendo click en el bot\u00f3n <code>- Remove</code> que aparece en la parte izquierda de cada una de ellas.</p> <p>Por \u00faltimo, especificamos en el campo \"Base URL\" donde se encuentra nuestro repositorio local. Aqu\u00ed debemos indicar el valor que pusimos al configurar el Repositorio Local en los nodos:</p> <pre><code>file:///var/repo/ambari\n</code></pre> <p>NEXT</p> <p>En la siguiente p\u00e1gina, donde dice Target Hosts tenemos que indicar el hostname de cada nodo de nuestro cluster, separados por saltos de l\u00ednea.</p> <p>Luego en el apartado de Host Registration Information como nosotros ya hemos copiado manualmente la clave SSH del servidor en el fichero de autorizados de los agentes, simplemente marcamos la opci\u00f3n de <code>Perform Manual Registration on Hosts</code>.</p> <p>REGISTER AND CONFIRM </p> <p>Esperamos a que finalice el proceso de registro de los nodos y si todo va bien recibiremos un mensaje que dir\u00e1 <code>All hosts checks passed on 4 registered hosts</code>.</p> <p>NEXT </p> <p>Pasaremos a la siguiente ventana donde vamos a elegir los servicios que queremos instalar. En nuestro caso, como estamos creando un laboratorio de pr\u00e1cticas y nuestros recursos son limitados, seleccionaremos los m\u00e1s esenciales para empezar (siempre podemos instalar servicios m\u00e1s adelante, una vez que est\u00e9 funcionando nuestro cluster desde la secci\u00f3n <code>Stack an Versions</code>).</p> <p>Por lo tanto, solo mantendremos seleccionados HDFS, YARN, MapReduce2, ZooKeeper y Ambari Metrics. M\u00e1s adelante, por ejemplo tendremos que instalar HBase, ya que sin \u00e9l no funcionar\u00e1 Ambari Metrics.</p> <p>NEXT PROCEED ANYWAY</p> <p>Continuaremos con la opci\u00f3n de Asign Masters, esto es personalizable seg\u00fan las necesidades y recursos de cada cluster, pero un ejemplo para un laboratorio similar al nuestro, podr\u00eda ser el siguiente:</p> <p></p> <p>NEXT </p> <p>Al igual que pasaba en el paso anterior, la configuraci\u00f3n de Assign Slaves and Clients puede variar de un escenario a otro, en este caso podemos establecer algo como lo siguiente:</p> <p></p> <p>NEXT </p> <p>En la pesta\u00f1a Credentials nos pedir\u00e1 configurar usauraio y contrase\u00f1a para Grafana, podemos dejarlo como <code>admin / admin</code>.</p> <p>NEXT </p> <p>En las siguientes pesta\u00f1as Directories, Accounts y All Configurations; podremos hacer cambios m\u00e1s adelante si fuese necesario, pero por el momento vamos a dejarlos con sus valores por defecto, as\u00ed que solo pulsamos en siguiente para avanzar.</p> <p>DEPLOY </p> <p>Comenzar\u00e1 el despliegue de los servicios en los nodos de nuestro cluster, esto puede llevar un tiempo seg\u00fan las caracteristicas de nuestra m\u00e1quina</p> <p>Adem\u00e1s, el servicio Timeline Service V2 va a fallar, pero no es un problema, as\u00ed que vamos a ignorarlo por el momento. El resto de servicios, deber\u00edan instalarse con \u00e9xito, si no es as\u00ed, podemos pulsar en el bot\u00f3n <code>RETRY</code>, para volver a intentarlo. Si todo va bien, deber\u00eda finalizar el despliegue con 2 o 3 warnings, pero sin errores.</p> <p>FALTA DE RECURSOS</p> <p>Si por alg\u00fan motivo, como recursos insuficientes el despliegue se queda congelado y no responde; podemos conectarnos a la consola de nuestro nodo SERVIDOR y ejecutar el siguiente comando:     ambari-server restart</p> <p>NEXT COMPLETE </p> <p>Dejaremos unos segundos (o minutos) a que los servicios terminen de arrancar y podremos conectarnos a nuestro nodo SERVIDOR y comprobar que efectivamente tenemos habilitado el sistema de archivos de Hadoop:</p> <pre><code>con ambari_server\nhadoop fs -ls /\n</code></pre> <p>Fuente 1: Ambari Docker Environmet Setup , Fuente 2: Ambari Installation Guide , Fuente 3: Edward Viaene</p>"},{"location":"BIGDATA/ud3/#despliegue-cluster-hadoop-sobre-docker","title":"DESPLIEGUE CL\u00daSTER HADOOP SOBRE DOCKER","text":"Hadoop on Docker <p>El despliegue anterior nos servir\u00eda para un entorno de producci\u00f3n (sustituyendo los nodos virtuales por m\u00e1quinas f\u00edsicas), pero si queremos desplegar Hadoop para un entorno de desarrollo o laboratorio pr\u00e1ctico, existen im\u00e1genes de docker ya preparadas para realizar esta tarea de una forma m\u00e1s r\u00e1pida y menos compleja.</p> <p>Existen varios repositorios Github donde podemos encontrar los archivos de configuraci\u00f3n necesarios para llevar a cabo esta seugnda opci\u00f3n, pero uno de los m\u00e1s completos y estables es el de Big Data Europe. Que podemos descargar en el siguiente archivo comprimido .</p> Logo Big Data Europe <p>POSIBLE ERROR:</p> <p>En ocasiones, uno de los contenedores se queda reseteando por falta de recursos. As\u00ed que en caso de que solo veamos 4 contenedores en ejecuci\u00f3n, deberemos editar el fichero <code>docker-compose.yml</code> y a\u00f1adir las siguientes l\u00edneas al final de la descripci\u00f3n de cada servicio:     ulimits:         nofile:             soft: 65536             hard: 65536</p> <p>Descomprimimos el archivo y se nos crear\u00e1 la carpeta \"docker-hadoop\". Abrimos un terminal en esta carpeta y ejecutamos el comando para hacer el despliegue mediante docker:</p> <pre><code>cd docker-hadoop\ndocker compose up -d\n</code></pre> <p>Una vez acabe de ejecutarse, podemos ver la red que ha creado para los contenedores con el comando:</p> <pre><code>docker network ls\n</code></pre> <p>Copiamos el nombre de la red y lo usaremos en el siguiente comando, para ver los nombres de los contenedores que se han creado y sus direcciones IP asignadas (debes sustituir dentro del comando el nombre de tu red):</p> <pre><code>docker network inspect &lt;nombre_de_la_red&gt; --format '{{range .Containers}}{{.Name}}: {{.IPv4Address}}{{println}}{{end}}'\n</code></pre> <p>Ahora, seg\u00fan lo que nos muestre el comando anterior, debemos a\u00f1adir las direcciones IP (sin m\u00e1scaras de red) con sus respectivos hostname al final del fichero <code>/etc/hosts</code>. Para que podamos acceder a los diferentes recursos del cl\u00faster a trav\u00e9s de nuestro navegador, usando sus nombres:</p> <ul> <li>HDFS Master: http://namenode:9870</li> <li>HDFS Slave: http://datanode:9864</li> <li>Map Reduce: http://historyserver:8188</li> <li>YARN Slave: http://nodemanager:8042</li> <li>YARN Master: http://resourcemanager:8088</li> </ul> <p>Adem\u00e1s de esas, hay que a\u00f1adir dos traducciones m\u00e1s a <code>/etc/hosts</code>, que podemos ver en la interfaz gr\u00e1fica de los servicios:</p> Captura Datanode Captura Nodemanager <p>Y con esto tendr\u00edamos nuestro cl\u00faster Hadoop listo. Que aunque sea un cl\u00faster simulado, pues los nodos corren como servicios dentro de una \u00fanica m\u00e1quina f\u00edsica, est\u00f3s se configuran para actuar como nodos de un cl\u00faster distribuido, permitiendo ejecutar aplicaciones MapReduce y usar HDFS.</p> <p>Fuente 1: Escuela de Inform\u00e1tica, Fuente 2: Tutorials Point</p>"},{"location":"BIGDATA/ud3/#practica-1-hola-mundo-en-hadoop","title":"PR\u00c1CTICA 1: HOLA MUNDO EN HADOOP","text":"<p>El primer ejemplo que suele realizarse como Hola Mundo en Hadoop, es una aplicaci\u00f3n que cuente el n\u00famero de ocurrencias de cada palabra en un documento de texto.</p> <p>En este caso, nosotros vamos a contar las palabras de El Quijote, el cual podemos descargar en formato de texto plano, desde el siguiente enlace de GitHub .</p> <p>Si se ha descargado en nuestra carpeta de Descargas, accedemos a ella desde el terminal y lo copiamos en el directorio ra\u00edz del nodo Maestro de HDFS. Luego creamos una carpeta personal dentro de HDFS y ah\u00ed moveremos nuestro fichero de texto. Los comandos ser\u00edan estos:</p> <pre><code>cd ~/Descargas\n\ndocker cp el_quijote.txt namenode:/\n\ndocker exec -it namenode bash\n\nhdfs dfs -mkdir /user/\nhdfs dfs -mkdir /user/profe/\n\nhdfs dfs -put el_quijote.txt /user/profe/\n\nhdfs dfs -ls /user/profe/\n</code></pre> <p>Una vez tenemos el documento en nuestro sistema de ficheros HDFS, podemos procesar su informaci\u00f3n con Mapreduce. Para ello, Hadoop tiene una serie de ejemplos ya implementados para demostrar el uso de MapReduce.</p> <p>Estos se encuentran en la carpeta $HADOOP_HOME/share/hadoop/mapreduce. As\u00ed pues, podemos ejecutar el programa <code>wordcount</code> con el siguiente comando (debemos lanzarlo dentro del nodo Maestro):</p> <pre><code>hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar \\\nwordcount /user/profe/el_quijote.txt /user/profe/salidaQuijote\n</code></pre>"},{"location":"BIGDATA/ud3/#desarrollando-nuestros-scripts-mapreduce","title":"DESARROLLANDO NUESTROS SCRIPTS MAPREDUCE","text":"<p>La API de MapReduce est\u00e1 escrita en Java, pero mediante la utilidad Hadoop Streaming podemos usar MapReduce con cualquier lenguaje de programaci\u00f3n compatible con sistemas Unix. Para entender mejor como funciona, vamos a recrear el ejemplo anterior usando Python.</p> <p>Auque dependiendo del tipo de tarea que necesitemos llevar a cabo, el c\u00f3digo de los scripts va a variar, siempre vamos a diferenciar dos grandes fases: el mapeo de datos y la reducci\u00f3n o resumen.</p> <p>Para poder ejecutar los scripts, en nuestro caso, lo primero es instalar Python. En caso de haber levantado un cl\u00faster para desarrollo con Docker, como hemos visto m\u00e1s arriba, deberemos actualizar los origenes del repositorio, ya que usan una im\u00e1gen Debian bastante antigua:</p> <pre><code>cd ~/Descargas\ndocker cp nodemanager:/etc/apt/sources.list ./\nsudo nano sources.list\n\n# Comentamos todas las l\u00edneas que tuviera el fichero y pegamos las siguientes 3 l\u00edneas al final:\ndeb http://archive.debian.org/debian stretch main\ndeb http://archive.debian.org/debian-security stretch/updates main\ndeb http://archive.debian.org/debian stretch-updates main\n\ndocker cp sources.list nodemanager:/etc/apt/\n</code></pre> <p>Con esto ya podremos instalar paquetes en el contendor donde lo hayamos realizado, en este caso nos interesa el nodemanager:</p> <pre><code>apt-get update\n\napt-get install nano\n\napt-get install python3\n</code></pre> <p>Una vez tenemos Python instalado, ahora s\u00ed, vamos a crear nuestros scripts. Los cuales se lanzan desde el Nodemanager (YARN slave):</p>"},{"location":"BIGDATA/ud3/#mapeo","title":"Mapeo","text":"<p>Para crear el mapeador en este ejemplo de contador de palabras, vamos a hacer que el programa recorra l\u00ednea a l\u00ednea el documento recibido y genere una salida donde cada palabra se muestre en una nueva linea. De modo que cada l\u00ednea sea una tupla compuesta por la palabra, un tabulador y el n\u00famero 1 (indicando que hay una ocurrencia).</p> mapper.py<pre><code>#!/usr/bin/python3\n# -*-coding:utf-8 -*\nimport sys\nfor linea in sys.stdin:\n    # eliminamos los espacios de delante y de detr\u00e1s\n    linea = linea.strip()\n    # dividimos la l\u00ednea en palabras\n    palabras = linea.split()\n    # creamos tuplas de (palabra, 1)\n    for palabra in palabras:\n        print(\"%s\\t%d\" % (palabra, 1))\n</code></pre> <p>Si queremos probar su funcionamiento localmente, podemos hacerlo con:</p> <pre><code>cat el_quijote.txt | python3 mapper.py\n</code></pre>"},{"location":"BIGDATA/ud3/#reduccion","title":"Reducci\u00f3n","text":"<p>A continuaci\u00f3n, en el reducer vamos a recibir la salida del mapper y desglosamos la cadena, separando la palabra del contador.</p> <p>Para llevar la cuenta de las palabras, vamos a meterlas dentro de un diccionario, donde cada palabra ser\u00e1 una clave y los valores ser\u00e1n los contadores de cada palabra, los cuales se ir\u00e1n incrementando con cada ocurrencia encontrada.</p> reducer.py<pre><code>#!/usr/bin/python3\n# -*-coding:utf-8 -*\nimport sys\n# inicializamos el diccionario\ndictPalabras = {}\n\nfor linea in sys.stdin:\n    # quitamos espacios de sobra\n    linea = linea.strip()\n    # parseamos la entrada de mapper.py\n    palabra, cuenta = linea.split('\\t', 1)\n    # convertimos cuenta de string a int\n    try:\n        cuenta = int(cuenta)\n    except ValueError:\n        # cuenta no era un numero, descartamos la linea\n        continue\n    try:\n        dictPalabras[palabra] += cuenta\n    except:\n        dictPalabras[palabra] = cuenta\n\nfor palabra in dictPalabras.keys():\n    print(\"%s\\t%d\" % (palabra, dictPalabras[palabra]))\n</code></pre> <p>Para probar el funcionamiento del proceso completo (map + reduce), podemos ejecutar lo siguiente:</p> <pre><code>cat el_quijote.txt | python3 mapper.py | python3 reducer.py &gt; salida.tsv\n</code></pre>"},{"location":"BIGDATA/ud3/#hadoop-streaming","title":"Hadoop Streaming","text":"<p>Ahora pasaremos a ejecutar las aplicaciones anteriores dentro de Hadoop, para ello usaremos Hadoop Streaming. Que, como ya mencionamos, nos permite ejecutar trabajos (jobs) Map/Reduce con scripts codificados en cualquier lenguaje de programaci\u00f3n que pueda leer de la entrada est\u00e1ndar (stdin) y escribir a la salida est\u00e1ndar (stdout).</p> <p>En primer lugar, daremos permisos de ejecuci\u00f3n a los scripts creados por el usuario:</p> <pre><code>     chmod +x mapper.py\n     chmod +x reducer.py\n</code></pre> <p>IMPORTANTE:</p> <p>El directorio de salida que especifiquemos, no debe existir previamente. De lo contrario, el comando fallar\u00e1 en su ejecuci\u00f3n.</p> <p>El comando utilizado ejecutar un job con Hadoop Streaming es <code>mapred streaming</code> y aunque tiene muchas opciones, las principales que se suelen usar son:</p> <pre><code>mapred streaming \\\n    -input &lt;directorio_entrada_HDFS&gt; \\\n    -output &lt;directorio_salida_HDFS&gt; \\\n    -mapper &lt;ruta_script_Mapper&gt; \\\n    -reducer &lt;ruta_script_Reducer&gt;\n</code></pre> <p>Como en nuestro caso, estamos ejecutando scripts locales al nodo, que no est\u00e1n en el sistema de ficheros del cl\u00faster, usaremos tambi\u00e9n la opci\u00f3n <code>-files</code>, para cargalos en los nodos Hadoop y nos podr\u00eda quedar algo parecido al siguiente ejemplo:</p> <pre><code>mapred streaming -files mapper.py,reducer.py \\\n-input /user/profe/el_quijote.txt \\\n-output /user/profe/salidaPY \\\n-mapper ./mapper.py -reducer ./reducer.py\n</code></pre> <p>Fuente: Aitor Medrano</p>"},{"location":"BIGDATA/ud3/#practica-2-trabajando-con-hdfs","title":"PR\u00c1CTICA 2: TRABAJANDO CON HDFS","text":"<p>Gu\u00eda oficial comandos HDFS</p> <p>Gu\u00eda oficial shell FS Hadoop</p>"},{"location":"BIGDATA/ud3/#_1","title":"UD3. Ecosistema Hadoop","text":"<p>Fuente: Aitor Medrano</p>"},{"location":"BIGDATA/ud4/","title":"APACHE SPARK","text":"Logo Apache Spark"},{"location":"CLOUD/indexc/","title":"COMPUTACI\u00d3N EN LA NUBE Y VIRTUALIZACI\u00d3N","text":"<p>\u00cdNDICE DE CONTENIDOS:</p> <ol> <li>Libros y Herramientas \u00datiles</li> <li>Elementos clave de una Infraestructura de Red</li> <li>Cloud Computing</li> <li>Virtualizaci\u00f3n</li> <li>Introducci\u00f3n a Docker</li> <li>Introducci\u00f3n a Kubernetes</li> </ol> <p>MATERIALES FORMACI\u00d3N PROFESIONAL INFORM\u00c1TICA by Lorenzo Le\u00f3n Valor is licensed under CC BY-NC-SA 4.0</p>"},{"location":"CLOUD/ud0/","title":"LIBROS Y HERRAMIENTAS \u00daTILES PARA EL DESARROLLO DEL M\u00d3DULO","text":""},{"location":"CLOUD/ud0/#libros-de-referencia","title":"LIBROS DE REFERENCIA","text":""},{"location":"CLOUD/ud0/#herramientas-web-utiles","title":"HERRAMIENTAS WEB \u00daTILES","text":""},{"location":"CLOUD/ud1/","title":"UNIDAD 1: ELEMENTOS CLAVE DE UNA INFRAESTRUCTURA DE RED","text":""},{"location":"CLOUD/ud1/#el-protocolo-ip","title":"EL PROTOCOLO IP","text":""},{"location":"CLOUD/ud1/#que-es","title":"\u00bfQUE ES?","text":"<ul> <li> <p>El protocolo IP (Internet Protocol) es uno de los m\u00e1s utilizados y m\u00e1s importantes de los que operan en la capa 3 del modelo OSI. Ya que permite la comunicaci\u00f3n entre dispositivos conectados a redes distintas. Para ello, se le asigna una numeraci\u00f3n a cada equipo, que lo identifica de forma \u00faniva dentro de la misma red, conocida como direcci\u00f3n IP.</p> </li> <li> <p>Una direcci\u00f3n IP consiste en un numero binario de 32 bits, divido en grupos de 4 octetos (8 bits; lo que implica que cada octeto podr\u00e1 tomar valores de 0 hasta 255 como m\u00e1ximo), separados por puntos. La forma m\u00e1s com\u00fan de representarla es en formato decimal, como por ejemplo 192.168.200.255</p> </li> </ul>"},{"location":"CLOUD/ud1/#clases-de-direcciones-ip","title":"CLASES DE DIRECCIONES IP","text":"<ul> <li>Seg\u00fan su numeraci\u00f3n, distinguiremos 5 clases diferentes de direcciones IP: </li> </ul>"},{"location":"CLOUD/ud1/#direccionamiento-privado","title":"DIRECCIONAMIENTO PRIVADO","text":"<ul> <li>No obstante, dentro de cada clase existen rangos privados de direccionamiento. Estos rangos son los que usaremos cuando estemos configurando los dispositivos englobados en una misma red LAN y cuyas direcciones no deban ser visibles desde internet. Son los siguientes:</li> </ul>"},{"location":"CLOUD/ud1/#direccionamiento-reservado","title":"DIRECCIONAMIENTO RESERVADO","text":"<ul> <li> <p>Adem\u00e1s, tambi\u00e9n existen ciertos rangos de direcciones reservadas, que no deben usarse excepto para el uso que tienen asignados, como pueden ser el 127.0.0.0/8 que se utiliza para direcciones de Loopback, o el 0.0.0.0/0 que se utiliza como Ruta por Defecto.</p> </li> <li> <p>Al resto de direccionamiento que no se incluye en los rangos privados y reservados, lo llamaremos direcciones p\u00fablicas, que son las que se usan en Internet.</p> </li> </ul>"},{"location":"CLOUD/ud1/#estructura-de-una-direccion-ip","title":"ESTRUCTURA DE UNA DIRECCI\u00d3N IP","text":"<ul> <li>En una direcci\u00f3n IP vamos a diferenciar 2 partes, la izquierda o identificador de red, y la derecha o identificador de host. Como se ha visto en la tabla anterior, dependiendo de la clase a la que pertenezca una direcci\u00f3n IP, su red tendr\u00e1 un tama\u00f1o por defecto para cada una de esas partes, que ser\u00eda el siguiente:</li> </ul>"},{"location":"CLOUD/ud1/#la-mascara-de-red","title":"LA M\u00c1SCARA DE RED","text":"<ul> <li>Para indicarnos la cantidad de bits pertenece a cada una de estas partes, tenemos la m\u00e1scara de red. Se trata de un indicador n\u00famerico con el mismo tama\u00f1o y distribuci\u00f3n de bits que una direcci\u00f3n IP, y que suele indicarse a continuaci\u00f3n de esta.</li> <li>Podemos expresarla tanto en formato decimal (similar a una IP) o en formato abreviado o CIDR (Classles Inter-Domain Routing), con un /N, siendo N el n\u00famero de bits usados para el identificador de red. Lo vemos en el siguiente ejemplo:</li> </ul>"},{"location":"CLOUD/ud1/#los-puertos-logicos","title":"LOS PUERTOS L\u00d3GICOS","text":""},{"location":"CLOUD/ud1/#que-son","title":"\u00bfQUE SON?","text":"<ul> <li>Son como interfaces virtuales que permiten la comunicaci\u00f3n entre diferentes aplicaciones o servicios en una misma computadora o entre distintas computadoras a trav\u00e9s de la red. Son identificadores n\u00famericos de 16 bits, a trav\u00e9s de los cuales podemos conocer que servicio o protocolo se est\u00e1 usando.</li> </ul>"},{"location":"CLOUD/ud1/#tipos-de-puertos-logicos","title":"TIPOS DE PUERTOS L\u00d3GICOS","text":"<ul> <li>Tanto en TCP como en UDP tenemos un total de 65535 puertos disponibles, tenemos una clasificaci\u00f3n dependiendo del n\u00famero de puerto a utilizar, que es la siguiente:</li> <li>Puertos conocidos: los puertos conocidos (well-known en ingl\u00e9s) van desde el puerto 0 hasta al 1023, est\u00e1n registrados y asignados por la Autoridad de N\u00fameros Asignados de Internet (IANA), a los servicios y protocolos de red m\u00e1s comunes.</li> <li>Puertos registrados: los puertos registrados van desde el puerto 1024 hasta al 49151. La principal diferencia de estos puertos, es que las diferentes organizaciones pueden hacer solicitudes a la IANA para que se le otorgue un determinado puerto por defecto, y se le asignar\u00e1 para su uso con una aplicaci\u00f3n en concreto.</li> <li>Puertos din\u00e1micos: estos puertos van desde el 49152 hasta el 65535, este rango de puertos se utiliza por los programas del cliente y est\u00e1n constantemente reutiliz\u00e1ndose. Este rango de puertos normalmente se utiliza cuando est\u00e1 transmitiendo a un puerto conocido o reservado desde otro dispositivo, como en el caso de web o FTP. Por ejemplo, cuando nosotros visitamos una web, el puerto de destino siempre ser\u00e1 el 80 (HTTP) o el 443 (HTTPS), pero como puerto origen se usar\u00e1 uno din\u00e1mico.</li> </ul>"},{"location":"CLOUD/ud1/#puertos-mas-usados","title":"PUERTOS M\u00c1S USADOS","text":""},{"location":"CLOUD/ud1/#principales-protocolos-de-red","title":"PRINCIPALES PROTOCOLOS DE RED","text":"<p>-</p>"},{"location":"CLOUD/ud1/#arp","title":"ARP","text":"<ul> <li>Es un protocolo de capa 2. Se encarga de asociar la direcci\u00f3n MAC de cada maquina, a su direcci\u00f3n IP. ADDRESS RESOLUTION PROTOCOL</li> </ul> <p>PROTOCOLO DE RESOLUCI\u00d3N DE DIRECCIONES</p> <ul> <li>Cuando un equipo intenta comunicarse por primera vez con otra maquina de su red, se enviar\u00e1 previamente una \"petici\u00f3n ARP\", en forma de mensaje de broadcast a todos los equipos de la red.</li> <li>De modo que solo responder\u00e1 el equipo que tenga la MAC con la que queramos comunicarnos.</li> <li>As\u00ed, cada equipo de la red ir\u00e1 generando lo que llamamos su \"Tabla ARP\", en la que iran quedando registradas las direcciones MAC de cada m\u00e1quina, asociada con su direcci\u00f3n IP correspondiente.</li> </ul>"},{"location":"CLOUD/ud1/#icmp","title":"ICMP","text":"<p>Es un protocolo de capa 3. Nos sirve para comprobar si tenemos conectividad con otro dispositivos de nuestra red o de otra distinta. Esto lo hace generando paquetes IP de un tama\u00f1o concreto y envi\u00e1ndolos a otra m\u00e1quina de la red para ver si responde.</p> <ul> <li>Herramientas como ping y traceroute utilizan ICMP para probar la disponibilidad de un destino, medir tiempos de respuesta o mostrar la ruta que siguen los paquetes.</li> </ul>"},{"location":"CLOUD/ud1/#dns","title":"DNS","text":"<ul> <li>Se considera un servicio de capa 7. Es un servicio o funcionalidad, que nos permite acceder o comunicarnos con otros equipos o recursos de una red, utilizando su nombre de dominio e incluso un alias.</li> <li>Evitando as\u00ed tener que recordar la direcci\u00f3n IP de cada maquina, que ser\u00eda mucho m\u00e1s complejo.</li> <li>Para ello, tendremos configurado en nuestra red uno o m\u00e1s servidores DNS, a los cuales les enviaremos peticiones cada vez que nos comunicamos con otro equipo a trav\u00e9s de su nombre de dominio; y estos realizaran la traducci\u00f3n de ese nombre o alias, a la direcci\u00f3n IP que le corresponde.</li> <li>Este servicio funciona de manera totalmente transparente para el usuario.</li> </ul> Funcionamiento DNS"},{"location":"CLOUD/ud1/#nat","title":"NAT","text":"<ul> <li>Mecanismo mediante el cual podemos traducir una o varias direcciones IP privadas (locales), en una o varios IP p\u00fablicas (globales) y viceversa. De esta forma, los equipos de una red local pueden acceder a internet sin que sus direcciones IP privadas sean visibles fuera de su red local.</li> <li>A parte de esta, la principal funci\u00f3n de NAT es la de conservar el espacio global IPv4 y evitar su agotamiento. Ya qu\u00e9 gracias a \u00e9l, podemos conseguir que utilizando una sola IP p\u00fablica, salgan internet todos los equipos de una red local. Distinguimos 3 tipos de NAT:</li> </ul> <ul> <li>NAT Est\u00e1tico: asigna de forma manual una direcci\u00f3n IP p\u00fablica a una direcci\u00f3n privada. Mapeo \u201cuno a uno\u201d permanente.</li> <li>NAT Din\u00e1mico: consiste en asignar un grupo de direcciones p\u00fablicas a una red local, de modo que los dispositivos podr\u00e1n ir utilizando din\u00e1micamente esas direcciones p\u00fablicas para salir a internet y dejarlas libres cuando terminen. Mapeo \u201cuno a uno\u201d temporal.</li> <li>NAT con Sobrecarga: tambi\u00e9n conocido como PAT (Port Address Translation), permite asignar una IP p\u00fablica a toda una red y que los dispositivos la utilicen de forma simultanea para salir a internet. Realiz\u00e1ndose la diferenciaci\u00f3n entre equipos por puertos. Mapeo \u201cuno a varios\u201d.</li> </ul> <p>Aclaraci\u00f3n</p> <ul> <li>Direcci\u00f3n local interna: la direcci\u00f3n de origen vista desde el interior de la red.</li> <li>Direcci\u00f3n global interna: la direcci\u00f3n de origen vista desde la red externa.</li> <li>Direcci\u00f3n global externa: la direcci\u00f3n del destino vista desde la red externa.</li> <li>Direcci\u00f3n local externa: la direcci\u00f3n del destino vista desde la red interna.</li> </ul>"},{"location":"CLOUD/ud1/#dhcp","title":"DHCP","text":"<ul> <li>Es un protocolo de capa 7. Nos permite configurar varios par\u00e1metros de conectividad (direcci\u00f3n IP, M\u00e1scara, Puerta de Enlace, Servidores DNS...) de manera autom\u00e1tica, en las diferentes m\u00e1quinas conectadas a una red.</li> <li>Para ello, debemos configurar previamente uno de los equipos de red, para que ejecute dicho servicio, es decir, har\u00e1 la funci\u00f3n de servidor. De modo que cada vez que un equipo se conecte a dicha red, solamente tengamos que activar en \u00e9l, la funcionalidad DHCP (Cliente, que generalmente viene habilitada por defecto) y realizar\u00e1 la petici\u00f3n de forma autom\u00e1tica, obteniendo as\u00ed su configuraci\u00f3n de red, sin necesidad de hacerlo manualmente equipo por equipo.</li> </ul>"},{"location":"CLOUD/ud1/#redes-en-linux","title":"REDES EN LINUX","text":""},{"location":"CLOUD/ud1/#modificar-direccionamiento-de-una-interfaz-de-red","title":"MODIFICAR DIRECCIONAMIENTO DE UNA INTERFAZ DE RED","text":"<p>-----NETPLAN GENERADO POR DEFECTO-----------------</p> <p>network:     ethernets:       ens18:         dhcp4: true         dhcp6: true         match:           macaddress: bc:24:11:39:b5:42         set-name: ens18     version: 2</p> <p>-----NETPLAN MODIFICADO PARA IP EST\u00c1TICA----------</p> <p>network:     ethernets:       ens18:         dhcp4: false         addresses:             - 172.21.184.38/16         routes:           - to: default             via: 172.21.0.254         nameservers:           addresses: [8.8.8.8, 1.1.1.1]         dhcp6: false         match:           macaddress: bc:24:11:39:b5:42         set-name: ens18     version: 2</p> <p>------ APLICAR LOS CAMBIOS REALIZADOS ---------   sudo netplan apply</p>"},{"location":"CLOUD/ud2/","title":"UNIDAD 2: CLOUD COMPUTING","text":""},{"location":"CLOUD/ud2/#que-es-la-computacion-en-la-nube","title":"\u00bfQUE ES LA COMPUTACI\u00d3N EN LA NUBE?","text":""},{"location":"CLOUD/ud2/#concepto","title":"Concepto","text":""},{"location":"CLOUD/ud2/#breve-historia","title":"Breve Historia","text":""},{"location":"CLOUD/ud2/#caracteristicas-de-los-serivicios-en-la-nube","title":"CARACTER\u00cdSTICAS DE LOS SERIVICIOS EN LA NUBE","text":""},{"location":"CLOUD/ud2/#caracteristicas-principales","title":"Caracter\u00edsticas Principales","text":""},{"location":"CLOUD/ud2/#estructura-general-arquitectura-en-la-nube","title":"Estructura general arquitectura en la nube","text":""},{"location":"CLOUD/ud2/#frontend","title":"FrontEnd","text":""},{"location":"CLOUD/ud2/#backend","title":"BackEnd","text":""},{"location":"CLOUD/ud2/#middleware","title":"Middleware","text":""},{"location":"CLOUD/ud2/#modelos-de-implementacion-en-la-nube","title":"MODELOS DE IMPLEMENTACI\u00d3N EN LA NUBE","text":""},{"location":"CLOUD/ud2/#nube-publica","title":"NUBE P\u00daBLICA","text":"<ul> <li> <p>VENTAJAS:</p> </li> <li> <p>INCONVENIENTES:</p> </li> </ul>"},{"location":"CLOUD/ud2/#nube-privada","title":"NUBE PRIVADA","text":"<ul> <li> <p>VENTAJAS:</p> </li> <li> <p>INCONVENIENTES:</p> </li> </ul>"},{"location":"CLOUD/ud2/#nube-hibrida","title":"NUBE H\u00cdBRIDA","text":"<ul> <li> <p>VENTAJAS:</p> </li> <li> <p>INCONVENIENTES:</p> </li> </ul>"},{"location":"CLOUD/ud2/#multinube","title":"MULTINUBE","text":"<ul> <li> <p>VENTAJAS:</p> </li> <li> <p>INCONVENIENTES:</p> </li> </ul>"},{"location":"CLOUD/ud2/#opciones-de-contratacion","title":"OPCIONES DE CONTRATACI\u00d3N","text":""},{"location":"CLOUD/ud2/#saas-software-as-a-service","title":"SAAS (Software as a Service)","text":""},{"location":"CLOUD/ud2/#paas-platform-as-a-service","title":"PAAS (Platform as a Service)","text":""},{"location":"CLOUD/ud2/#iaas-infraestructure-as-a-service","title":"IAAS (Infraestructure as a Service)","text":""},{"location":"CLOUD/ud2/#seguridad-en-la-nube","title":"SEGURIDAD EN LA NUBE","text":""},{"location":"CLOUD/ud2/#amenazas","title":"Amenazas","text":""},{"location":"CLOUD/ud2/#riesgos","title":"Riesgos","text":""},{"location":"CLOUD/ud2/#principales-proveedores-y-servicios","title":"PRINCIPALES PROVEEDORES Y SERVICIOS","text":""},{"location":"CLOUD/ud2/#cuota-de-mercado-por-proveedor","title":"Cuota de Mercado por Proveedor","text":""},{"location":"CLOUD/ud2/#amazon-web-services-aws","title":"Amazon Web Services (AWS)","text":""},{"location":"CLOUD/ud2/#microsoft-azure","title":"Microsoft Azure","text":""},{"location":"CLOUD/ud2/#google-cloud","title":"Google Cloud","text":""},{"location":"CLOUD/ud2/#oracle-cloud","title":"Oracle Cloud","text":""},{"location":"CLOUD/ud2/#clouding","title":"Clouding","text":""},{"location":"CLOUD/ud2/#equivalencia-entre-servicios","title":"Equivalencia entre servicios","text":""},{"location":"CLOUD/ud2/#perfil-devops","title":"PERFIL DEVOPS","text":"<p>DevOps es una metodolog\u00eda de desarrollo basada en una serie de pr\u00e1cticas dirigidas a integrar las \u00e1reas de Desarrollo y Operaciones, haciendo \u00e9nfasis en la comunicaci\u00f3n, colaboraci\u00f3n e integraci\u00f3n continua; para asegurar la calidad y automatizar el despliegue de soluciones software.</p> <p>Es la metodolog\u00eda en la que est\u00e1n enfocadas la gran mayor\u00eda de empresas tecnol\u00f3gicas en la actualidad y por ello, uno de los perfiles m\u00e1s demandado en este campo es el de especialista o ingeniero DevOps. Las habilidades requeridas para dicho puesto, son las siguientes (controlando 4 o 5 de ellas, ya entraremos en las b\u00fasquedas de diferentes empresas):</p> <ul> <li>Linux principalmente y en bastante menor medida Windows.</li> <li>AWS (Amazon Web Services)</li> <li>Scripting (Bash, Python, PHP).</li> <li>Herramientas de Configuraci\u00f3n distribuida (Puppet, Ansible, Chef, Terraform, OpenStack).</li> <li>Administraci\u00f3n de servidores web (Apache HTTP, Nginx).</li> <li>Administraci\u00f3n y configuraci\u00f3n de sistemas de monitoreo (New Relic, Nagios, Grafana, Prometheus, Kibana).</li> <li>Administraci\u00f3n y configuraci\u00f3n de bases de datos (MySQL, MariaDB, PostgreSQL, MongoDB)</li> <li>Conocimientos de Networking y herramientas (Balanceo, DNS, TCP, UDP, HTTP, telnet, dig, traceroute, iptables)</li> <li>Administraci\u00f3n y configuraci\u00f3n de sistemas de cach\u00e9 (memcache, redis)</li> <li>Conocimientos de Virtualizaci\u00f3n y Contenedores (VMWare, Proxmox, Vagrant, Docker, Kubernetes)</li> </ul> <p>Si englobamos estas habilidades en categor\u00edas, nos quedar\u00eda algo as\u00ed:</p> <ul> <li>Desarrollo (Habilidades para desarrollar software, haber trabajado como developer)</li> <li>Delivering (conocimientos de herramientas para distribuci\u00f3n de deployments)</li> <li>S.O Architect (Arquitectura de S.O, especialmente Linux)</li> <li>Webservers (Administraci\u00f3n y configuraci\u00f3n de  webservers Apache HTTP y/o Ngnix)</li> <li>Troubleshooting (Habilidades para resoluci\u00f3n de problemas de desarrollo e infraestructura)</li> <li>Virtualization (Conocimientos y conceptos de virtualizaci\u00f3n )</li> <li>Cloud (Conocimientos de Cloud, Webservices, APIs, REST, SOAP)</li> <li>Database (Administraci\u00f3n y configuraci\u00f3n de BBDD relacionales, no relacionales y cach\u00e9)</li> </ul> <p></p>"},{"location":"CLOUD/ud3/","title":"UNIDAD 3: VIRTUALIZACI\u00d3N","text":""},{"location":"CLOUD/ud3/#que-es-la-virtualizacion","title":"\u00bfQUE ES LA VIRTUALIZACI\u00d3N?","text":""},{"location":"CLOUD/ud3/#tipos-de-virtualizacion","title":"TIPOS DE VIRTUALIZACI\u00d3N","text":""},{"location":"CLOUD/ud3/#metodos-de-implementacion","title":"M\u00c9TODOS DE IMPLEMENTACI\u00d3N","text":""},{"location":"CLOUD/ud3/#categorias-de-virtualizacion","title":"CATEGOR\u00cdAS DE VIRTUALIZACI\u00d3N","text":""},{"location":"CLOUD/ud3/#beneficios-de-la-virtualizacion","title":"BENEFICIOS DE LA VIRTUALIZACI\u00d3N","text":""},{"location":"CLOUD/ud3/#limitaciones","title":"LIMITACIONES","text":""},{"location":"CLOUD/ud3/#tecnologias-especificas-de-virtualizacion","title":"TECNOLOG\u00cdAS ESPEC\u00cdFICAS DE VIRTUALIZACI\u00d3N","text":""},{"location":"CLOUD/ud3/#virtualizacion-con-proxmox","title":"VIRTUALIZACI\u00d3N CON PROXMOX","text":""},{"location":"CLOUD/ud3/#crear-plantilla-mv-ubuntu","title":"CREAR PLANTILLA MV UBUNTU","text":"<p>Abrimos la consola del nodo Proxmox sobre el que vayamos a trabjar y creamos una m\u00e1qina virtual con el siguiente comando:</p> <pre><code>qm create 900 --name plantilla-ubuntu-2204 \\\n--ostype=l26 \\\n--scsihw virtio-scsi-single --agent enabled=1 \\\n--cpu x86-64-v2-AES \\\n--memory 2048 \\\n--net0 virtio,bridge=vmbr0,firewall=1 \\\n-ide2 none,media=cdrom\n</code></pre> <p>A\u00f1adimos una unidad cloud-init que servir\u00e1 para configurar varios parametros de la m\u00e1quina la primera vez que se arranque:</p> <pre><code>qm set 900 --ide0 local-lvm:cloudinit\n</code></pre> <p>Luego establecemos los valores para los par\u00e1metros del cloud-init:</p> <pre><code>qm set 900 --ciuser profe \\\n--cipassword profe \\\n--sshkey ~/.ssh/id_rsa.pub \\\n--ipconfig0 ip=dhcp\n</code></pre> <p>Regeneramos la imagen de la m\u00e1quina incluyendo el cloud-init:</p> <ol> <li> <p>En el panel izquierdo, seleccionar nuestra m\u00e1quina virtual: <code>900</code>.</p> </li> <li> <p>Dentro de ella, selecci\u00f3nar la opci\u00f3n <code>Cloud-Init</code>.</p> </li> <li> <p>Pulsar el bot\u00f3n <code>Regenerate image</code>.</p> </li> </ol> <p>Volvemos a la consola de nuestro nodo y a\u00f1adimos un interfaz serial para nuestra m\u00e1quina virtual:</p> <pre><code>qm set 900 --serial0 socket --vga serial0\n</code></pre> <p>Descargamos la imagen cloud de Ubuntu:</p> <pre><code>wget https://cloud-images.ubuntu.com/minimal/releases/jammy/release/ubuntu-22.04-minimal-cloudimg-amd64.img\n</code></pre> <p>Cambiamos el tama\u00f1o de la imagen descargada:</p> <pre><code>qemu-img resize ubuntu-22.04-minimal-cloudimg-amd64.img 16G\n</code></pre> <p>Importamos la imagen ubuntu al disco local definido en nuestro Datacenter PROXMOX:</p> <pre><code>qm importdisk 900 ubuntu-22.04-minimal-cloudimg-amd64.img local-lvm\n</code></pre> <p>Ahora configuramos el disco scsi0 de nuestra m\u00e1quina virtual, con el disco que nos ha generado el comando anterior:</p> <pre><code>qm set 900 --scsi0 local-lvm:vm-900-disk-0,discard=on,iothread=1,ssd=1\n</code></pre> <p>Cambiamos el orden de arranque de la m\u00e1quina:</p> <ol> <li> <p>Seleccionar la m\u00e1quina virtual: 900</p> </li> <li> <p>Seleccionar la opci\u00f3n Opciones</p> </li> <li> <p>Seleciconar el elemento Orden de arranque y pulsar el bot\u00f3n Editar:</p> <ul> <li> <p>Activar el disco scsi0</p> </li> <li> <p>Arrastrarlo a la segunda posici\u00f3n (dejando el CDROM como primera opci\u00f3n por si alg\u00fan d\u00eda se necesita iniciar mediante una ISO)</p> </li> </ul> </li> </ol> <p>Volvemos a la consola de nuestro nodo Proxmox y convertimos la m\u00e1quina en plantilla:</p> <pre><code>qm template 900\n</code></pre>"},{"location":"CLOUD/ud3/#clonacion-de-la-plantilla","title":"CLONACI\u00d3N DE LA PLANTILLA","text":"<p>Para clonar nuestra plantilla, desde el shell del nodo Proxmox, ejecutamos:</p> <pre><code>qm clone 900 101 --name ubuntu-clon1 --full 1 --storage NASinformatica\n</code></pre> <p>Modificando el valor 101 por el ID que queramos darle a la m\u00e1quina clonada, tambien el nombre que se le quiera dar a la m\u00e1quina; y por \u00faltimo indicando en donde queremos que se almacene su imagen (en este ejemplo usamos un NAS que tenemos conectado a Proxmox).</p>"},{"location":"CLOUD/ud3/#primer-inicio-de-la-maquina","title":"PRIMER INICIO DE LA M\u00c1QUINA","text":"<p>Antes de arrancar la m\u00e1quina clonada, personalizamos los valores de username, password y direccionamiento IP:</p> <pre><code>qm set 101 --ciuser clon1 --cipassword clon1\nqm set 101 --ipconfig0 ip=172.21.184.41/16,gw=172.21.0.254\n</code></pre> <p>Si queremos asignar los clones a grupos de usuarios para que solo sean visibles por ellos, podemos hacerlo con el comando:</p> <pre><code>pveum acl mod /vms/101 --group Grupo1_ASIR --role \"PVEVMAdmin\"\n</code></pre> <p>Es un ubuntu minimal, por lo que trae lo justo. Deberemos ir instalandole las herramientas que necesitemos:</p> <pre><code>apt install nano\napt install openvswitch-switch\n</code></pre> <p>Adem\u00e1s, para utilizar el DNS local a\u00f1adiendo entradas en el fichero <code>/etc/hosts</code> y que no perdamos los datos, debemos editar el siguiente fichero y comentamos la l\u00ednea que dice - update_etc_hosts:</p> <pre><code>sudo nano /etc/cloud/cloud.cfg\n</code></pre> <p>Fuente1: Manel Rodero Fuente2: Proxmox Wiki</p>"},{"location":"CLOUD/ud4/","title":"UNIDAD 4: INTRODUCCI\u00d3N A DOCKER","text":""},{"location":"CLOUD/ud4/#concepto-y-caracteristicas","title":"CONCEPTO Y CARACTER\u00cdSTICAS","text":""},{"location":"CLOUD/ud4/#que-es-docker","title":"\u00bfQUE ES DOCKER?","text":"<ul> <li>Tecnolog\u00eda de virtualizaci\u00f3n ligera de software libre, tambi\u00e9n conocida como virtualizaci\u00f3n por contenedores.</li> <li>Son entornos de ejecuci\u00f3n aislados, con su propio sistema de ficheros, su propia configuraci\u00f3n de red y que acceden directamente a los recursos del anfitri\u00f3n (memoria, procesador...)</li> <li>No tienen kernel propio, utilizan el del anfitri\u00f3n.</li> <li>Su uso principal es para el despliegue de aplicaciones.</li> </ul>"},{"location":"CLOUD/ud4/#elementos-basicos-de-docker","title":"ELEMENTOS B\u00c1SICOS DE DOCKER","text":"<ul> <li>IMAGEN: aplicaci\u00f3n empaquetada, es el sistema de ficheros de nuestro contenedor</li> <li>CONTENEDOR: una imagen en ejecuci\u00f3n</li> <li>Los contenedores pueden conectarse a diferentes REDES VIRTUALES y tienen sus propios VOL\u00daMENES o sistemas de almacenamiento.</li> </ul>"},{"location":"CLOUD/ud4/#arquitectura-de-docker","title":"ARQUITECTURA DE DOCKER","text":"<ul> <li>DEMONIO: es el m\u00e1s importante (Docker Engine) estar\u00e1 siempre en ejecuci\u00f3n y es el que gestiona los contenedores</li> <li>CLIENTE: linea de comandos que nos permite decirle al demonio que queremos hacer</li> <li>REGISTRO: repositorio de im\u00e1genes local (existe tambien uno p\u00fablico, Docker Hub, de donde podemos descargar)</li> <li>DOCKER SWARN: software orquestador de contenedores de Docker. Sirve para gestionar y automatizar la operativa con conjuntos de contenedores ejecutados en clusteres de servidores. El m\u00e1s conocido es KUBERNETES. </li> </ul> <p>Algunas alternativas a Docker son:</p> <ul> <li>Podman (RedHat)</li> <li>Containerd (proyecto independiente basado en Docker)</li> <li>CRI-0 (RedHat, pensada para trabajar con Kubernetes)</li> <li>Pouch (AliBaba).</li> </ul>"},{"location":"CLOUD/ud4/#instalacion-de-docker","title":"INSTALACI\u00d3N DE DOCKER","text":"<ul> <li>Documentaci\u00f3n oficial</li> <li>Requerimientos m\u00ednimos Ubuntu</li> <li> <p>Docker solo corre sobre distribuciones Linux, para Windows y MAC, se puede usar instalando el software Docker Desktop, que en realidad crea una m\u00e1quina virtual Linux para ejecutar el demonio Docker sobre ella. Sin embargo el cliente si corre sobre el SO anfitri\u00f3n.</p> </li> <li> <p>Existen varios m\u00e9todos de instalaci\u00f3n, en nuestro caso usaremos los repositorios apt de de Docker:</p> <ol> <li> <p>Actualizamos los repositorios e instalamos los paquetes necesarios para instalar desde repositorios HTTPS:</p> <pre><code>sudo apt-get update\nsudo apt-get install ca-certificates curl gnupg\n</code></pre> </li> <li> <p>A\u00f1adir la clave GPG oficial de Docker:</p> <pre><code>sudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nsudo chmod a+r /etc/apt/keyrings/docker.gpg\n</code></pre> </li> <li> <p>A\u00f1adimos el repositorio oficial de Docker:</p> <pre><code>echo \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \"$(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\")\" stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre> </li> <li> <p>Instalamos Docker Engine:</p> <pre><code>sudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n</code></pre> </li> </ol> </li> <li> <p>Para manejar Docker con un usuario sin privilegio, debemos a\u00f1adir el usuario al grupo <code>docker</code>, para ello:</p> <pre><code>sudo usermod -aG docker $USER\n</code></pre> </li> <li> <p>Debes volver a iniciar una terminal con el usuario, o ejecutar el siguiente comando:</p> <pre><code>su - $USER\n</code></pre> </li> <li> <p>Y finalmente, comprobamos la versi\u00f3n con la que vamos a trabajar:</p> <pre><code>docker --version\n</code></pre> </li> <li> <p>Si queremos m\u00e1s informaci\u00f3n de las versiones de los componentes con los que vamos a trabajar, ejecutamos:</p> <pre><code>docker version\n</code></pre> </li> <li> <p>Para m\u00e1s informaci\u00f3n del sistema que hemos instalado podemos ejecutar:</p> <pre><code>docker info\n</code></pre> </li> </ul>"},{"location":"CLOUD/ud4/#ejecucion-de-contenedores","title":"EJECUCI\u00d3N DE CONTENEDORES","text":"<ul> <li>HOLA MUNDO:</li> <li> <p>Todos los subcomandos referidos a contenedores, estan dentro del bloque \"docker container\", pero por abreviaci\u00f3n, se omite \"container\" y solo se escribe \"docker\". Por ejemplo: docker container run = docker run</p> </li> <li> <p>Para ver todos los subcomandos con referidos a contenedores, podemos ejecutar:</p> <pre><code>docker container\n</code></pre> </li> <li> <p>Como m\u00ednimo, para crear un contenedor debemos indicarle una imagen. Esa imagen debe estar en nuestro REGISTRO (repositorio) local, si no es as\u00ed, la buscara en el REGISTRO p\u00fablico (Docker Hub) y la descargar\u00e1. Por ejemplo, existe la imagen p\u00fablica \"hello-world\" que ejecuta un programa Hello World en el contenedor.</p> </li> <li> <p>Si no especificamos un nombre de contenedor al crearlo, la herramienta le asigna un nombre aleatorio.</p> </li> <li> <p>Todas las im\u00e1genes tienen definido un comando por defecto que ejecutar\u00e1n al crear un contenedor con ellas. Por ejemplo, en el caso de las imagenes de sistemas operativos, como ubuntu, por defecto ejecutan el comando  <code>bash</code>.</p> </li> <li> <p>COMANDOS DE GESTI\u00d3N B\u00c1SICA:</p> </li> <li> <p>Crear y ejecutar un contenedor:</p> <pre><code>docker run hello-world\n</code></pre> </li> <li> <p>Crear un contenedor sin ejecutarlo:</p> </li> </ul> <pre><code>    docker create hello-world\n</code></pre> <ul> <li>Iniciar un contenedor ya creado:</li> </ul> <pre><code>    docker start -a micontenedor1\n    # La opci\u00f3n -a sirve para ver la salida que genera la ejecuci\u00f3n de ese contenedor, en este caso el mensaje \"Hello form Docker!\"\n</code></pre> <ul> <li>Pausar la ejecuci\u00f3n de un contenedor:</li> </ul> <pre><code>    docker pause micontenedor\n</code></pre> <ul> <li>Finalizar la ejecuci\u00f3n de un contenedor:</li> </ul> <pre><code>    docker stop micontenedor\n</code></pre> <ul> <li>Reiniciar la ejecuci\u00f3n de un contenedor:</li> </ul> <pre><code>    docker restart micontenedor\n</code></pre> <ul> <li>Renombrar un contenedor ya creado:</li> </ul> <pre><code>    docker rename micontenedor nuevo_nombre\n</code></pre> <ul> <li>Borrar un contenedor:</li> </ul> <pre><code>    #Mediante su ID:\n    docker rm 64f44087771a\n    # Mediante su nombre\n    docker rm micontenedor1\n\n    # Para forzar el borrado de un contenedor en ejecuci\u00f3n, se usar\u00eda la opci\u00f3n -f\n    docker rm -f micontenedor1\n</code></pre> <ul> <li>Enlazar con la entrada/salida de un contenedor interactivo en ejecuci\u00f3n:</li> </ul> <pre><code>    docker attach micontenedor\n</code></pre> <ul> <li>Mostrar contenedores en ejecuci\u00f3n:</li> </ul> <pre><code>    docker ps\n</code></pre> <ul> <li>Mostrar contenedores creados:</li> </ul> <pre><code>    docker ps -a\n</code></pre> <ul> <li>Mostrar im\u00e1genes de nuestro REGISTRO local:</li> </ul> <pre><code>    docker images\n</code></pre> <ul> <li>Descargar una imagen del REGISTRO p\u00fablico:</li> </ul> <pre><code>    #Por ejemplo, descargar la imagen del SO Ubuntu\n    docker pull ubuntu\n</code></pre> <ul> <li>Visualizar los pasos que se dan cuando creamos o ejecutamos contenedores:</li> </ul> <pre><code>    #Dejamos lanzado este comando y se nos mostrar\u00e1n logs detallados de todos las acciones que ejecutemos despues:\n    docker events\n</code></pre> <ul> <li>OPCIONES COMUNES SOBRE LOS COMANDOS B\u00c1SICOS:</li> <li>Indicar nombre del contenedor al crearlo:</li> </ul> <pre><code>    docker run --name contenedor1 ubuntu\n</code></pre> <ul> <li>Para especificar que comando o comandos queremos que ejecute nuestro contenedor, se indican despues de la imagen:</li> </ul> <pre><code>    docker run --name contenedor1 ubuntu echo \"Hola Mundo\"\n</code></pre> <ul> <li>Indicar hostname del contenedor al crearlo:</li> </ul> <pre><code>    #Aunque no es muy com\u00fan utilizarlo, ya que los contenedores ofrecen un servicio y por lo general no nos conectamos a ellos. Es decir, no suelen tratarse como m\u00e1quinas virtuales tradicionales a las que solemos conectarnos para realizar distintas tareas\n    docker -h contenedor_ubuntu\n</code></pre> <ul> <li>Crear una sesi\u00f3n de terminal interactivo al crear un contenedor:</li> </ul> <pre><code>    docker run -it --name contenedor2 -h cont2 ubuntu bash\n</code></pre> <ul> <li>Borrar el contenedor despues de que termine su ejecuci\u00f3n:</li> </ul> <pre><code>    docker run -it --rm --name contenedor3 -h cont3 ubuntu top\n</code></pre> <ul> <li>CONTENEDORES DEMONIO: ejecutan procesos indefinidamente y de forma desatendida (no veremos su salida). Ejemplo:</li> </ul> <pre><code># La opci\u00f3n -d indica que la ejecuci\u00f3n es desatendida, es decir, no veremos su salida. Y la opci\u00f3n -c, permite especificar entre comillas, un listado de comandos para ejecutar:\ndocker run -d --name micontenedor ubuntu bash -c \"while true; do echo hello world; sleep 1; done\"\n\n# Para ver la salida generada por un contenedor demonio\ndocker logs micontenedor\n\n#Y si queremos verlo de forma continuada, podemos especificar\ndocker logs -f micontenedor\n\n# Para detener un contenedor demonio\ndocker stop micontenedor\n\n# Una vez detenido, podemos eliminarlo si queremos\ndocker rm micontenedor\n</code></pre> <ul> <li>CREACI\u00d3N DE VARIABLES DE ENTORNO ASOCIADAS A UN CONTENEDOR: Las variables de entorno son del tipo \"clave:valor\", y podemos crearlas al arrancar un contenedor. En el siguiente ejemplo, creamos la variable \"USUARIO\" y le asignamos el valor \"prueba\":</li> </ul> <pre><code>#Crea un contenedor interactivo (-it) con la imagen de ubuntu y define una variable de entorno (-e) para ese contenedor:\ndocker run -it --name micontenedor -e USUARIO=prueba ubuntu\n</code></pre> <ul> <li>Para comprobar que realmente se ha creado la variable, dentro del BASH del contenedor escribimos <code>env</code> y veremos todas las variables d entorno.</li> <li> <p>Las variables de entorno, suele utilizarse mucho para definir ciertos par\u00e1metros de configuraci\u00f3n de las aplicaciones que se desplegamos mediante contenedores.</p> </li> <li> <p>COMANDOS DE GESTI\u00d3N M\u00c1S AVANZADOS: Ejecutar un comando dentro de un contenedor en ejecuci\u00f3n:</p> </li> </ul> <pre><code>docker  exec micontenedor ls\n#o\ndocker exec micontenedor cat datos.txt\n</code></pre> <p>El comando anterior es muy utilizado para levantar sesiones interactivas de consola en contenedores ya creados, por ejemplo:</p> <pre><code># Abrir una sesi\u00f3n interactiva en un contenedor MariaDB existente, ejecutando bash y pas\u00e1ndole usuario y contrase\u00f1a para autenticarse\ndocker exec -it some-mariadb bash -c 'mysql -u root -p$MARIADB_ROOT_PASSWORD'\n</code></pre> <p>Copiar ficheros del Host al Contenedor o viceversa:</p> <pre><code>#Para copiar del host al contenedor, se especifica el nombre del contenedor y el directorio donde lo queremos copiar\ndocker cp mifichero.txt micontenedor:/\n\n#Para copiar del contenedor al host, debemos especificar el directorio destino, en este caso \".\" para indicar el directorio actual\ndocker cp micontenedor:/hora.txt .\n</code></pre> <p>Visualizar los procesos que se estan ejecutando dentro de un contenedor:</p> <pre><code>docker top micontenedor\n</code></pre> <p>Obtener informaci\u00f3n detallada de un contenedor:</p> <pre><code># Muestra en formato JSON el identificador, puertos abiertos, almacenamiento, tama\u00f1o, configuraci\u00f3n de red, comandos, varibles de entorno... \ndocker inspect micontenedor\n</code></pre> <p>Podemos formatear la salida del comando anterior, para que solo muestre ciertos par\u00e1metros:</p> <pre><code># Para mostrar el ID del contenedor\ndocker inspect --format='{{.Id}}' micontenedor\n\n#Para mostrar todas las variables de entorno:\ndocker inspect --format='{{range .Config.Env}}{{println .}}{{end}}' micontenedor\n\n#Para mostrar la direcci\u00f3n o direcciones IPs que tiene el contenedor:\ndocker inspect --format='{{range .NetworkSettings.Networks}}{{IPAddress}}{{end}}' micontenedor\n</code></pre> <p>Etiquetar contenedores, para filtrarlos o agruparlos</p> <pre><code># USO ETIQUETADO\n</code></pre> <p>Limitar recursos utilizados por contenedores:</p> <pre><code># La cantidad de CPU --cpus\n\n# La cantidad de memoria --memory\n</code></pre> <p>Visualizar estad\u00edsticas de uso de recursos de un contenedor</p> <pre><code># ESTADISTICAS\n</code></pre> <p>Modificar en tiempo real las limitaciones de recursos de un contenedor en ejecuci\u00f3n</p> <pre><code># MODIFICACI\u00d3N LIMITACIONES\n</code></pre>"},{"location":"CLOUD/ud4/#desplegar-un-servidor-web-apache-con-docker","title":"DESPLEGAR UN SERVIDOR WEB APACHE CON DOCKER","text":"<p>Generalmente, nunca se va a utilizar la direcci\u00f3n IP del contenedor para acceder a los servicios que despliega, ya que esta es din\u00e1mica y puede ir cambiando dependiendo de que acciones realicemos en el contenedor.</p> <p>Adem\u00e1s, la direcci\u00f3n IP de un contenedor solamente es accesible desde el anfitri\u00f3n. No ser\u00eda alcanzable desde otros equipos de la red.</p> <p>Por lo tanto, en este caso para acceder al servidor Web que nos proporcionar\u00e1 este contenedor, vamos a <code>mapear puertos</code>. Es decir, con la opci\u00f3n <code>-p</code> indicamos que cuando accedamos al puerto 8080 del host, esa petici\u00f3n se reenv\u00ede al puerto 80 del contenedor, independientemente de la direcci\u00f3n IP.</p> <p>Ser\u00eda como si definieramos una regla de NAT en el Firewall del anfitri\u00f3n.</p> <pre><code># httpd:2.4 es la imagen oficial del Servidor Web APACHE\ndocker run -d --name my-apache-app -p 8080:80 httpd:2.4\n</code></pre> <p>Para ver las redirecciones o nateos que se est\u00e1n haciendo en nuestro contenedor:</p> <pre><code># Muestra tanto IPv4 como IPv6\ndocker port my-apache-app\n</code></pre> <p>Para conectarnos al servidor web bastar\u00e1 con ir al navegador del host y acceder a <code>https://localhost:8080</code></p>"},{"location":"CLOUD/ud4/#desplegar-un-servidor-de-bbdd-con-docker","title":"DESPLEGAR UN SERVIDOR DE BBDD CON DOCKER","text":""},{"location":"CLOUD/ud4/#gestion-de-imagenes-en-docker","title":"GESTI\u00d3N DE IMAGENES EN DOCKER","text":"<p>Las im\u00e1genes son plantillas de solo lectura que define el sistema de ficheros que va a tener el contenedor. Tambi\u00e9n establece el comando por defecto que ejecutar\u00e1 ese contenedor, siempre que no se indique otro.</p> <p>Por defecto en docker se usa el registro p\u00fablico de Docker Hub para descargar im\u00e1genes a nuestro registro local.</p> <p>La nomenclatura para identificar una imagen es <code>usuario/nombre:etiqueta</code>. Las im\u00e1genes oficiales de docker vienen sin nombre de usuario para diferenciarlas.</p> <p>Si no idicamos etiqueta al usar una imagen, por defecto se utiliza la etiqueta \"latest\" que se refiere a la \u00faltima versi\u00f3n disponible de esa imagen.</p> <p>Adem\u00e1s de la version, las etiquetas pueden indicar la tecnolog\u00eda interna que se usa para servir esa aplicaci\u00f3n y el SO base que usa esa imagen.</p> <ul> <li>\u00bfComo se organizan las im\u00e1genes? El sistema de ficheros (FS) de una im\u00e1gen se llama sistema de ficheros de uni\u00f3n, ya que es el resultado de la uni\u00f3n de varias capas.</li> </ul> <p>Cada capa representa una serie de directorios, que al juntarlos todos obtenemos nuestro FS final.</p> <p>Las imagenes suelen partir de una capa base, que contiene los directorios y archivos b\u00e1sicos para su funcionamiento. Y luego cada una de las otras capas define un conjunto de diferencias respecto a la capa anterior (ficheros a\u00f1adidos, modificados o eliminados).</p> <p></p> <p>Si tengo varias im\u00e1genes que tengan la misma capa base, solo se almacenar\u00e1 una vez en nuestra m\u00e1quina y ser\u00e1 compartida por todas esas im\u00e1genes. Esto podemos verlo con el comando:</p> <pre><code># Nos da la informaci\u00f3n del almacenamiento utilizado por docker\ndocker system df -v\n</code></pre> <p>Esto por ejemplo tambien ocurre cuando creamos contenedores con diferentes versiones de una misma imagen, muchas de sus capas, son compartidas.</p> <p>Cuando creamos un contenedor, usa el FS de la imagen en <code>solo lectura</code>. Por tanto, cuando instalamos o modificamos algo en un contenedor, esto se hace en una nueva <code>capa de lectura/escritura</code> que se genera al crearlo, para as\u00ed no modificar las capas de la imagen. De este modo, si creamos varios contenedores a partir de la misma imagen, todos ellos compartirar el mismo FS.</p> <p>Esto hace que al crear un contenedor, su tama\u00f1o sea m\u00ednimo Esto podemos verlo con el comando:</p> <pre><code># La opci\u00f3n -s nos muestra el tama\u00f1o del contenedor\n# indicando el tama\u00f1o de la capa R/W del contenedor y\n# el tama\u00f1o (virtual) del FS de la imagen usada\ndocker ps -a -s\n</code></pre> <p>Cuando borramos un contenedor, esta capa R/W desaparece, se perder\u00edan los datos de ese contenedor.</p>"},{"location":"CLOUD/ud4/#comandos-de-gestion-de-imagenes","title":"COMANDOS DE GESTI\u00d3N DE IM\u00c1GENES","text":"<ul> <li>Buscar im\u00e1gnes en Docker Hub:</li> </ul> <pre><code>docker search nginx\n\n# Si queremos ver los posibles filtros\ndocker search --help\n</code></pre> <ul> <li>Para borrar una imagen que ya no vayamos a usar:</li> </ul> <pre><code>docker rmi hello-world\n</code></pre> <p>ATENCI\u00d3N:</p> <p>No podremos borrar una imagen de nuestro repositorio local, mientras exista alg\u00fan contenedor creado a partir de ella.</p> <ul> <li>Ver la informaci\u00f3n detallada de una imagen, como su identificador, puertos que utiliza, arquitectura, SO, variables de entorno, el comando por defecto, las distintas capas...</li> </ul> <pre><code>docker inspect nginx:stable\n</code></pre>"},{"location":"CLOUD/ud4/#docker-hub","title":"DOCKER HUB","text":"<p>Enlace Docker Hub</p> <p>Su filosof\u00eda es bastante parecida a GitHub, ya que denominan a las im\u00e1genes como repositorios y usan practicamente los mismos comandos que este (pull, push, commit...)</p> <p>Existe contenido confiable marcado con 3 tipos de insignias, como <code>imagen oficial de docker</code> (las mantiene el equipo de docker), <code>proveedores verificados</code> (suelen ser fabricantes reconocidos) y <code>proyectos de c\u00f3digo libre esponsorizados</code>.</p> <p>Podemos entrar a un repositorio par ver toda su informaci\u00f3n, etiquetas, versiones, como utilizarlo... Hay imagenes de SO, de servicios (apache, maraidb...), de lenguajes de programaci\u00f3n o aplicaciones comerciales (Wordpress...)</p> <p>Es imporante tener en cuenta la arquitectura en la que estamos trabajando, ya que dependiendo de eso deberemos buscar una imagen u otra.</p>"},{"location":"CLOUD/ud4/#almacenamiento-de-datos-en-docker","title":"ALMACENAMIENTO DE DATOS EN DOCKER","text":"<p>Para no perder la informaci\u00f3n generada por los contenedores una vez sean borrados (por defecto se guarda en la capa R/W del contenedor), existen formas de almacenarla en el equipo anfitri\u00f3n.</p> <p>Un VOLUMEN es un directorio creado y gestionados \u00fanicamente por Docker, que se va a montar en un directorio interno del contenedor. Es decir, cuando guardemos informaci\u00f3n en ese directorio montado, se estaremos escribiendo en el directorio de nuestro Host que corresponde a ese volumen. Es decir, esa informaci\u00f3n no se perder\u00eda al borrar el contenedor.</p> <p>El directorio del contenedor donde se montan es <code>/var/lib/docker/volumes/</code>.</p> <p>Los vol\u00famenes se pueden montar simultaneamente en diferentes contenedores (almacenamiento compartido). Es decir, lo que escribe un contenedor, puede ser leido m\u00e1s tarde por otro contenedor.</p> <p>Como la informaci\u00f3n persiste al borrar el contenedor, podemos usar esa informaci\u00f3n para que sea utilizada por otro contenedor que creemos en el futuro. Adem\u00e1s, gracias a esto son muy \u00fatiles para realizar copias de seguridad o migrar datos.</p> <p>Hay dos posibles formas de asociar un volumen a un contenedor, ambas hacen exactamente lo mismo pero tienen diferente nomenclatura:</p> Volumen con <code>-v</code>Volumen con <code>--mount</code> <pre><code>    -v miweb:/usr/local/apache2/htdocs:ro\n</code></pre> <pre><code>    --mount type=volume,src=miweb,dst=/usr/local/apache2/htdocs,ro\n</code></pre> <p>Otra opci\u00f3n es BIND MOUNT, que es un directorio o fichero propiedad del usuario, que podemos montar en un directorio interno del contenedor.</p> <p>Se referencian por su ruta completa, aunque podemos crear un punto de montaje para m\u00e1s comodidad.</p> <p>En este caso, no se gestionan desde el cliente Docker. Y se puede cambiar su contenido desde el anfitri\u00f3n.</p> <p>Son \u00fatiles cuando queremos compartir archivos de configuraci\u00f3n o c\u00f3digo fuente en nuestro contenedor. Y al igual que pasaba con los vol\u00famenes, podemos asociarlos a un contenedor de dos formas distintas:</p> Bind Mount con <code>-v</code>Bind Mount con <code>--mount</code> <pre><code>    -v /opt/web:/usr/local/apache2/htdocs:ro\n</code></pre> <pre><code>    --mount type=bind,src=/opt/web,dst=/usr/local/apache2/htdocs,ro\n</code></pre> <p></p> <ul> <li>Ejercicio con Vol\u00famenes: Todos los subcomandos de acciones con Vol\u00famenes, estan bajo el bloque <code>docker volume</code>. Por ejemplo:</li> </ul> <pre><code># Para crear un volumen:\ndocker volume create mivolumen\n\n# Para borrar un volumen:\ndocker volume rm mivolumen\n\n# Mostrar los volumenes creados:\ndocker volume ls\n\n# Mostrar informaci\u00f3n detallada de un volumen que hayamos creado:\ndocker volume inspect mivolumen\n</code></pre> <p>Para asociar un contenedor a un volumen que hayamos creado, un comando de ejemplo ser\u00eda el siguiente. Aunque igualmente, si indicamos un volumen que no se haya creado previamente, docker lo crear\u00e1 en este momento:</p> <pre><code>\n</code></pre> <p>Podemos comprobar el acceso al servidor web usando el navegador web o desde la consola, usando el comando <code>curl</code>:</p> <pre><code>curl http://localhost:8080\n</code></pre> <ul> <li>Ejercicios con Bind Mount:</li> </ul> <p>En este caso, no necesitamos crear vol\u00famenes, si no que vamos a crear un directorio en el sistema de archivos del Host, donde a\u00f1adiremos nuestro fichero <code>index.html</code>. Para ello, desde la consola del host:</p> <pre><code>mkdir miweb\ncd miweb\necho \"&lt;h1&gt;Hola Mundo&lt;/h1&gt;\" &gt; index.html\n</code></pre> <p>A continuaci\u00f3n, ya podemos montar ese directorio en un contenedor:</p> <pre><code>docker run -d --name my-apache-app --mount type=bind,src=/home/usuario/miweb,dst=/usr/local/apache2/htdocs -p 8080:80 httpd:2.4\n\n# O si lo preferimos, ser\u00eda lo mismo que:\ndocker run -d --name my-apache-app -v /home/usuario/miweb:/usr/local/apache2/htdocs -p 8080:80 httpd:2.4\n</code></pre> <p>En este caso, con bind mount, puedo modificar mi fichero HTML desde el anfitri\u00f3n y al estar montado, esos cambios se ver\u00e1n directamente reflejados en mi servidor web.</p>"},{"location":"CLOUD/ud4/#desplegar-el-servicio-nextcloud-en-un-contenedor-con-almacenamiento-persistente","title":"DESPLEGAR EL SERVICIO NEXTCLOUD EN UN CONTENEDOR CON ALMACENAMIENTO PERSISTENTE","text":"<p>Lo primero es ir a la p\u00e1gina de documentaci\u00f3n de la imagen de Nextcloud en Docker Hub.</p> <p>All\u00ed buscamos el apartado <code>Persistent data</code> para saber cual es el directorio que debo montar en un volumen para no perder los datos que nos interesan generados por esta aplicaci\u00f3n. En este caso ser\u00eda <code>/var/www/html</code>.</p> <p>Por lo tanto, si usamos volumenes el comando quedar\u00eda algo as\u00ed:</p> <pre><code>docker run -d -p 8080:80 -v nextcloud:/var/www/html --name contenedor_nextcloud nextcloud:28.0.1\n</code></pre>"},{"location":"CLOUD/ud4/#desplegar-el-servicio-mariadb-en-un-contenedor-con-almacenamiento-persistente","title":"DESPLEGAR EL SERVICIO MARIADB EN UN CONTENEDOR CON ALMACENAMIENTO PERSISTENTE","text":"<p>De nuevo, vamos a la p\u00e1gina de documentaci\u00f3n de la imagen que vamos a usar en Docker Hub.</p> <p>En el caso de MariaDB, la informaci\u00f3n sobre alamcenamiento persistente, aparece bajo el t\u00edtulo <code>Where to Store Data</code>. Ah\u00ed podemos leer que el directorio a montar es <code>/var/lib/mysql</code></p> <p>En este caso vamos a hacerlo con Bind Mount, y quedar\u00eda as\u00ed:</p> <pre><code>docker run --name some-mariadb -v /opt/mariadb:/var/lib/mysql -e MARIADB_ROOT_PASSWORD=my-secret-pw -d mariadb:10.5\n</code></pre> <p>Si el directorio <code>/opt/mariadb</code> no existe en nuestro host, con la opci\u00f3n -v se crear\u00e1 en ese momento.</p>"},{"location":"CLOUD/ud4/#otros-usos-del-almacenamiento-persistente","title":"OTROS USOS DEL ALMACENAMIENTO PERSISTENTE","text":"<ul> <li> <p>Almacenamiento compartido entre distintos contenedores.</p> </li> <li> <p>Por ejemplo, tener un servidor web en un contenedor, cuyo <code>index.html</code> deba ser actualizarse autom\u00e1ticamente leyendo de un repositorio GitHub o similar. Podemos tener un segundo contenedor, que modifique el c\u00f3digo de ese HTML.</p> </li> <li> <p>Otro ejemplo ser\u00eda probar como funciona un mismo c\u00f3digo en diferentes versiones del lenguaje de programaci\u00f3n (vease el caso de PHP que hay isntrucciones que cambian su comportamiento entre la versi\u00f3n 5 y la 7, o entre la 7 y la 8).</p> </li> </ul>"},{"location":"CLOUD/ud4/#redes-en-docker","title":"REDES EN DOCKER","text":"<p>Existen 3 tipos principales de redes en Docker:</p> <ol> <li>Bridge: es la que usaremos generalmente, genera una red privada virtual, asignando direccionamiento IP propio al contenedor y proporciona reclas SNAT (salida a internet) y DNAT (acceso desde el exterior al contenedor).</li> <li>Host: el contenedor no tendr\u00eda direcci\u00f3n IP propia, si no que se ejecuta como un proceso m\u00e1s en el Host, saliendo con la IP de este por el puerto que le indiquemos.</li> <li>None: para contenedores que no queremos que tengan conexi\u00f3n a internet.</li> </ol> <p>Hay que diferenciar entre la red Bridge que crea Docker por defecto y las redes Bridge que puede crear el usuario. La red por defecto se llama bridge y va a crear un switch virtual (Linux Bridge) llamado docker0 con el direccionamiento 172.17.0.0/16 a la que estar\u00e1n conectados todos los contenedores que creemos (mientras no indiquemos lo contrario). Al anfitri\u00f3n se le asigna la 172.17.0.1, que ser\u00e1 la puerta de enlace de nuestros contenedores.</p> <p></p> <p>Sin embargo, cuando creamos una red definida por el usuario, podemos personalizar que contenedores que contenedores queremos que se conecten a esa red, adem\u00e1s tendremos un servicio de DNS que permitir\u00e1 la interconexi\u00f3n de contenedores mediante sus nombres. Tambien podemos conectar y desconectar contenedores en caliente a redes definidas por el usuario.</p> <p>Los subcomandos para gestionar las redes se engloban bajo el comando <code>docker network</code>.</p> <ul> <li>EJERCICIO CONEXION RED HOST:</li> </ul> <p>Listamos las redes disponibles en docker, y vemos que por defecto est\u00e1n los tres tipos que hemos indicado m\u00e1s arriba.</p> <p>Luego vamos a crear un contenedor con un servidor web NGINX usando la red Host. De modo que si accedemos directamente al localhost, podremos ver nuestro servidor, ya que el contenedor no tiene IP propia, si no que usa la del HOST ejecutandose como un proceso m\u00e1s sobre un puerto espec\u00edfico:</p> <pre><code>docker network ls\n\ndocker run -d --network host --name myNGINX nginx\n\ncurl http://localhost\n</code></pre> <ul> <li>EJERCICIO CONEXION RED BRIDGE POR DEFECTO:</li> </ul> <p>En la siguiente pr\u00e1ctica creamos un contenedor interactivo con la distribuci\u00f3n linux Alpine mapeando el puerto 8080 del host al 80 del contenedor.</p> <p>Luego comprobamos en el terminal del contenedor la direcci\u00f3n ip asignada, la puerta de enlace y las entradas del servicio DNS.</p> <p>Luego en el terminal del host, podemos comprobar que ha creado una conexi\u00f3n con la IP que usar\u00e1 el contenedor como Gateway.</p> <pre><code>docker run -it -p 8080:80 --name CONT1 alpine ash\n\n/$ ip a\n/$ ip r\n/$ cat /etc/resolv.conf\n\nip a    #En el anfitri\u00f3n\n</code></pre> <p>Aqu\u00ed podemos instalar un servidor apache dentro de Alpine y levantar el servicio. Luego desde el anfitri\u00f3n accedemos al localhost con el puerto 8080 y vemos que nos muestra nuestro servidor.</p> <p>Tambien desde el host, podemos comprobar las reglas iptables que se han creado para gestionar la comunicaci\u00f3n de nuestros contenedores (bajo el nombre MASQUERADE y DNAT).</p> <pre><code>/$ apk add apache2\n/$ http -D foreground\n\ncurl http://localhost:8080      #En el anfitri\u00f3n\nsudo iptables -L -n -t nat      #En el anfitri\u00f3n\n</code></pre> <ul> <li>EJERCICIO CONEXION RED DEFINIDA POR EL USUARIO:</li> </ul> <p>Para este ejercicio creamos primero una red definida por el usuario, sin indicar ningun par\u00e1metro, para ver que valores le da docker por defecto. Que como vemos, ser\u00e1 el siguiente valor a la 17, que es el bridge por defecto.</p> <p>Listamos nuestras redes en docker, para ver que la ha creado y luego consultamos la informaci\u00f3n detallada de la red que acabamos de crear.</p> <p>Tambien podemos comprobar en el HOST que se ha creado un nuevo interfaz de red que es el que har\u00e1 la funci\u00f3n de gateway para esta red.</p> <p>Por \u00faltimo, borramos esta red de prueba, ya que generalmente especificaremos el direcci\u00f3namiento que queremos.</p> <pre><code>docker network create red1\n\ndocker network ls\n\ndocker network inspect red1\n\nip a\n\ndocker network rm red1\n</code></pre> <p>Ahora, creamos una segunda red pero personalizando los valores que queramos, y luego comprobaremos que se ha creado correctamente:</p> <pre><code>docker network create --subnet 192.168.0.0/24 --gateway 192.168.0.1 red2\n\ndocker network ls\n\ndocker network inspect red2\n\nip a\n</code></pre> <ul> <li>PR\u00c1CTICA: CONTENEDOR WORDPRESS CONECTACO CON CONTENEDOR MARIADB: <p>Lo primero es revisar la documentaci\u00f3n de las im\u00e1genes de <code>mariadb</code> y de <code>wordpress</code> en <code>Docker Hub</code>, para saber en que ruta debemos montar los vol\u00famenes y que variables de entorno necesitamos crear para que se comuniquen. Nos quedar\u00e1 algo as\u00ed:</p> </li> </ul> <pre><code>docker network create --subnet 192.168.1.0/24 --gateway 192.168.1.1 red_wp\n\ndocker run -d --name server_mariadb --network red_wp -v vol_mariadb:/var/lib/mysql -e MARIADB_DATABASE=bd_wp -e MARIADB_USER=user_wp -e MARIADB_PASSWORD=user123 -e MARIADB_ROOT_PASSWORD=admin123 mariadb\n\ndocker run -d --name server_wp --network red_wp -v vol_wordpress:/var/www/html/ -e WORDPRESS_DB_HOST=server_mariadb -e WORDPRESS_DB_USER=user_wp -e WORDPRESS_DB_PASSWORD=user123 -e WORDPRESS_DB_NAME=bd_wp -p 8085:80 wordpress\n</code></pre> <p>Si te das cuenta la variable de entorno <code>WORDPRESS_DB_HOST</code> la hemos inicializado al nombre del servidor de base de datos. Como est\u00e1n conectada a la misma red bridge definida por el usuario, el contenedor WordPress al intentar acceder al nombre <code>servidor_mariadb</code> estar\u00e1 accediendo al contenedor de la base de datos.</p> <p>Como vamos a acceder desde el exterior al servidor web, por lo que hemos mapeado los puertos con la opci\u00f3n <code>-p</code>. Sin embargo, en el contenedor de la base de datos no es necesario mapear los puertos porque no vamos a acceder desde el exterior a \u00e9l. Pero el contenedor <code>servidor_wp</code> si que podr\u00e1 acceder al puerto 3306/tcp del <code>servidor_mariadb</code> sin problemas al estar conectados a la misma red.</p> <p>Nos registramos en Wordpress con un correo ficticio y creamos alg\u00fan post. Luego ejecutamos los siguientes comandos para comprobar que la informaci\u00f3n se ha guardado en la BBDD:</p> <pre><code>docker exec -it server_mariadb bash\n\nmariadb -u root -p admin123\n\nSHOW TABLES;\nSELEC * FROM wp_posts\n</code></pre>"},{"location":"CLOUD/ud4/#escenarios-multicontenedor","title":"ESCENARIOS MULTICONTENEDOR","text":"<p>Cuando queremos levantar aplicaciones o servicios compuestos por varios microservicios (contenedores), normalmente se hace uso de DOCKER COMPOSE.</p> <p>Compose es una especificaci\u00f3n de Docker que permite declrar en un \u00fanico fichero con formato .YAML o .YML, todas las caracter\u00edsticas del escenario que queremos desplegar; como contenedores, vol\u00famenes, redes, orden de arranque, variables de entorno, etc.</p> <p>Actualmente, Docker Compose V2 ya se encuentra integrado en el cliente Docker, por lo que podemos ejecutarlo con <code>docker compose</code></p>"},{"location":"CLOUD/ud4/#el-fichero-docker-composeyaml","title":"EL FICHERO DOCKER-COMPOSE.YAML","text":"<p>En \u00e9l definimos un escenario compuesto por varios servicios (<code>services</code>). Y dentro de cada servicio, especificamos todos los detalles que van a definir ese servicio.</p> <p>Los par\u00e1metros <code>version</code> y <code>name</code> son opcionales. El primero es meramente informativo y si no especificamos nombre del escenario, coger\u00e1 el del directorio en el que se encuentra nuestro fichero .YAML.</p> <p>Caracter\u00edsticas de un servicio:</p> <ul> <li>Cada servicio est\u00e1 representado por un nombre de servicio y dentro de \u00e9l cuelgan todas sus caracter\u00edsticas.</li> <li>Nombre del contenedor asociado <code>container_name</code></li> <li>Imagen usada <code>image</code></li> <li>Pol\u00edtica de reinicio cuando hay un fallo o error <code>restart</code></li> <li>Comando a ejecutar cuando creamos el contenedor <code>command</code></li> <li>Variables de entorno <code>environment</code></li> <li>Dependencias de arranque y apagado con otros servicios <code>depends_on</code></li> <li>Mapeo de puertos <code>ports</code></li> <li>Vol\u00famenes de almacenamiento <code>volumes</code></li> <li>Configuraci\u00f3n de red <code>networks</code></li> </ul> <p>Por defecto, al ejecutar un escenario compose se crear una red definida por el usuario, que permite la conexi\u00f3n entre todos los contenedores que se han generado,aceptando conexiones por nombre de contenedor o por nombre de servicio. Es por esto, que generalmente no suelen definirse las redes en los ficheros .YAML:</p> <p>Para arrancar un escenario, vamos al directorio donde est\u00e1 nuestro <code>docker-compose.yaml</code> y ejecutamos docker compose up -d.</p> <p>Para eliminar un escenario, ser\u00eda con el comando docker compose down -v. \u00a1OJO! Esto eliminar\u00e1 tambien los volumenes asociados al escenario, si quisieramos mantenerlos, podemos quitar la opci\u00f3n <code>-v</code>.</p>"},{"location":"CLOUD/ud4/#uso-de-parametros-en-docker-compose","title":"USO DE PAR\u00c1METROS EN DOCKER COMPOSE","text":"<p>Podemos crear plantillas para el despliegue de aplicaciones o servicios mediante Docker Compose, y arrancarlas con diferentes valores, seg\u00fan la finalidad o necesidades que tengamos en los distintos entornos en que podemos ejecutar nuestro escenario.</p> <p>Para ello, en lugar de dar valores est\u00e1ticos a las caracter\u00edsticas definidas en el fichero .YAML, podemos usar variables usando la nomenclatura <code>${NOMBRE_VARIABLE}</code>. Por ejemplo:</p> <pre><code>version: '3.1'\nservices:\ndb:\n    container_name: servidor_mysql\n    image: mariadb:${VERSION_MDB}\n    restart: always\n    environment:\n      MARIADB_DATABASE: ${BASEDEDATOS}\n      MARIADB_USER: ${USUARIO}\n      MARIADB_PASSWORD: ${PASS}\n      MARIADB_ROOT_PASSWORD: ${PASS_ROOT}\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n</code></pre> <p>Los valores de esas variables se definen en un fichero aparte de tipo <code>CLAVE=valor</code>, que por convenio podemos nombrar como <code>env_nombre_entorno</code>. Por ejemplo:</p> <pre><code>VERSION_MDB=latest\nPUERTO=8080\nUSUARIO=\"prueba\"\nPASS=\"asdasd\"\nPASS_ROOT=\"asdasd\"\nBASEDEDATOS=\"wordpress\"\n</code></pre> <p>Es decir, en el directorio donde se encuantre nuestro fichero .YAML crearemos tantos ficheros como posibles entornos de ejecuci\u00f3n hayamos previsto. Por ejemplo, \"env_desarrollo\" y \"env_produccion\".</p> <p>Cuando queramos que nuestra plantilla arranque con los valores de un entorno espec\u00edfico, simplemente tendremos que renombrar ese fichero como <code>.env</code>, por ejemplo: <code>mv env_desarrollo .env</code>; y luego arrancar el escenario normalmente con <code>docker compose up -d</code>.</p> <p>Podemos comprobar el valor de las variables de entorno con las que ha arrancado nuestro contenedor con:</p> <pre><code>docker compose exec db env\n</code></pre> <p>IMPORTANTE</p> <p>No olvidar que cuando queramos cambiar de entorno primero debemos deshacer el renombrado anterior con <code>mv .env env_desarrollo</code>; y luego renombrar el entorno que queremos arrancar ahora <code>mv env_produccion .env</code>.</p>"},{"location":"CLOUD/ud4/#despliegue-real-con-docker-compose","title":"DESPLIEGUE REAL CON DOCKER COMPOSE","text":"<p>Vamos a ver un ejemplo pr\u00e1ctico real de Docker Compose, donde desplegaremos una aplicaci\u00f3n de c\u00f3digo abierto para gesti\u00f3n de reuniones online, similar al servicio Google Meet.</p> <p>Si accedemos al repositorio oficial de Jitsi en Github Jitsi Meet, tenemos toda la documentaci\u00f3n necesaria para desplegar la aplicaci\u00f3n con Docker, incluyendo el fichero <code>docker-compse.yaml</code>.</p> <p>Si seguimos las intrucciones ah\u00ed indicadas:</p> <ol> <li>Descargamos los ficheros del repositorio, lo descomprimimos, accedemos al directorio y vemos lo que contiene:</li> </ol> <pre><code>wget $(curl -s https://api.github.com/repos/jitsi/docker-jitsi-meet/releases/latest | grep 'zip' | cut -d\\\" -f4)\nunzip stable-9258\ncd jitsi-docker-jitsi-meet-c92026a/\nls\n</code></pre> <ol> <li>Utilizamos el fichero de variables globales para configurar la aplicaci\u00f3n y ejecutamos el script para generar las contrase\u00f1as:</li> </ol> <pre><code>cp env.example .env\n $ ./gen-passwords.sh\n</code></pre> <ol> <li>Luego dentro del fichero .env, descomentamos el par\u00e1metro <code>PUBLIC_URL</code> y modificamos su valor con la direcci\u00f3n que queramos usar:</li> </ol> <pre><code>nano .env\nPUBLIC_URL=https://localhost:8443\n</code></pre> <ol> <li>Creamos los directorios donde vamos a guardar la informaci\u00f3n de la aplicaci\u00f3n (Bind Mount en este caso):</li> </ol> <pre><code>mkdir -p ~/.jitsi-meet-cfg/{web,transcripts,prosody/config,prosody/prosody-plugins-custom,jicofo,jvb,jigasi,jibri}\n</code></pre> <ol> <li>Por \u00faltimo, levantamos el escenario y accedemos a la URL desde un navegador web:</li> </ol> <pre><code>docker compose up -d\n</code></pre> <p></p> <p>Si revisamos los contenedores que se han creado, veremos que Jitsi esta compuesto por 4 servicios: Se crean 4 contenedores que corresponde a cuatro componentes de Jitsi:</p> <ul> <li>web: Jitsi Meet web UI, aplicaci\u00f3n web servida por nginx.</li> <li>prosody: Prosody, servidor XMPP.</li> <li>jicofo: [Jicofo], el componente JItsi COnference FOcus.</li> <li>jvb: Jitsi Videobridge, el enrutador de v\u00eddeo.</li> </ul>"},{"location":"CLOUD/ud4/#creacion-de-imagenes-en-docker","title":"CREACI\u00d3N DE IM\u00c1GENES EN DOCKER","text":"<p>Hay dos mec\u00e1nismos b\u00e1sicos de construcci\u00f3n:</p> <ul> <li>A partir de un contenedor con <code>docker commit</code></li> <li>Automatizar su construcci\u00f3n (recomendada), usando un fichero <code>Dockerfile</code> y el comando <code>docker build</code>.</li> </ul> <p>El Dockerfile es como una receta que contiene todos los comandos para construir la im\u00e1gen. Adem\u00e1s, se puede distribuir, versionar y cambiar la imagen base de manera sencilla.</p> <p>Tambien hay dos posibles formas de distribuci\u00f3n de nuestras im\u00e1genes:</p> <ul> <li>En un fichero: <code>docker load</code> / <code>docker save</code></li> <li>En un registro (recomendada): <code>docker push</code> / <code>docker pull</code></li> </ul> <p></p> <p>EJERCICIO PR\u00c1CTICO: Creaci\u00f3n de una im\u00e1gen a partir de un contenedor. Vamos a crear un contenedor a partir de una imagen base del SO Debian.</p> <pre><code>docker  run -it --name contenedor1 debian \n</code></pre> <p>Realizamos las modificaciones que queramos sobre el contenedor, por ejemplo, actualizar, instalar un servidor web y modificar el fichero index.html:</p> <pre><code>apt update\napt install apache2 -y\necho \"&lt;h1&gt;Curso Docker&lt;/h1&gt;\" &gt; /var/www/html/index.html\nexit\n</code></pre> <p>Creamos una nueva imagen partiendo de ese contenedor usando <code>docker commit</code>.</p> <pre><code> docker commit --change='CMD apachectl -D FOREGROUND' contenedor1 josedom24/myapache2:v1\n</code></pre> <p>Si quiero subir mi imagen a Docker Hub, es muy importante ponerle delante nuestro nombre de usuario de Docker Hub, si no, no me dejar\u00e1. El formato ser\u00eda nombre_usuario/nombre_imagen:versi\u00f3n (si no indicamos versi\u00f3n, asignar\u00e1 la etiqueta latest)</p> <p>El contenedor creado, va a ejecutar el comando por defecto de la imagen base, en este caso Debian, al ser un SO ejecuta <code>bash</code> por defecto. Pero podemos personalizarlos con la opci\u00f3n <code>--change</code> y la instruccion <code>CMD</code>. Por ejemplo, en este caso queremos que ejecute el servidor web por defecto, y e comando ser\u00eda <code>apachectl -D FOREGROUND</code>.</p>"},{"location":"CLOUD/ud4/#el-fichero-dockerfile","title":"EL FICHERO DOCKERFILE","text":"<p>Esta compuesto por una serie de instrucciones que se ejecutan de forma secuencial para crear de manera automatizada im\u00e1genes Docker.</p> <p>La primera linea de este fichero es <code># syntax=docker/dockerfile:1</code>.</p> <p>Hay multitud de instrucciones que pueden en un DockerFile, las m\u00e1s utilizadas son:</p> <ul> <li>FROM: especifica la imagen base.</li> <li>MAINTAINER: indica los datos del autor de la imagen.</li> <li>LABEL: a\u00f1ade metadatos a la imagen del tipo <code>clave:valor</code>.</li> <li>RUN: ejecuta un comando que modifica el sistema de ficheros de la imagen base.</li> <li>COPY: copia ficheros desde mi equipo a la imagen, estos deben estar en la misma carpeta que el Dockerfile.</li> <li>ADD: similar a \"COPY\", pero permite descargar archivos desde una URL o extraer autom\u00e1ticamente archivos <code>tar.gz</code> en el destino especificado.</li> <li>EXPOSE: indica los puertos abiertos que usar\u00e1 esta imagen.</li> <li>CMD: establede el comando por defecto que se ejecuta al crear un contenedor con esta imagen.</li> <li>WORKDIR: establece el directorio de trabajo dentro de la imagen. Las siguientes instrucciones se ejecutar\u00e1n en esa ruta.</li> <li>ENV: establece las variables de entorno que se podr\u00e1n usar dentro del contenedor.</li> <li>ARG: define par\u00e1metros que se pueden personalizar a la hora de hacer el <code>docker build</code>.</li> <li>ENTRYPOINT: pr\u00e1cticamente igual que CMD, pero no puede modificarse al crear un contenedor.</li> <li>VOLUME: crea un punto de montaje en el directorio especificado y lo marca como volumen.</li> </ul> <p>Los comandos RUN, COPY y ADD, crean nuevas capas en la imagen, ya que modifican el sistema de ficheros de la imagen base.</p> <p>Un ejemplo de DockerFile ser\u00eda:</p> <pre><code>    FROM debian:stable-slim\n    RUN apt-get update  &amp;&amp; apt-get install -y  apache2 \n    WORKDIR /var/www/html\n    COPY index.html .\n    CMD apache2ctl -D FOREGROUND\n</code></pre> <p>Ejecutando el comando <code>docker build</code> en el mismo directorio del Dockerfile, crearemos la imagen definida en este. Por ejemplo:</p> <pre><code>    docker build -t profe_web/milinux:v1 .\n</code></pre> <p>IMPORTANTE</p> <p>Nunca usar la etiqueta latest para crear im\u00e1genes, ya que esta apunta a la \u00faltima versi\u00f3n de una imagen. Lo ideal es indicar versiones espec\u00edficas de nuestra imagen.</p> <p>Cuando usamos el comando docker build para construir im\u00e1genes, es com\u00fan que aparezcan en nuestro repositorio local im\u00e1genes con nombre y etiqueta <code>&lt;none&gt;</code>. Son registros intermedios que se generan y que podriamos borrar mediante el comando <code>docker image prune</code>.</p> <p>IMPORTANTE</p> <p>La opci\u00f3n PRUNE sirve para eliminar objetos docker de forma m\u00e1siva, ya sean im\u00e1genes, contenedores, redes, vol\u00famenes... Es por ello, que debemos usarla con cautela para no borrar cosas que no queramos.</p>"},{"location":"CLOUD/ud4/#distribucion-de-imagenes-docker","title":"DISTRIBUCI\u00d3N DE IM\u00c1GENES DOCKER","text":"<p>El comando <code>docker save</code> nos permite coger una imagen de nuestro repositorio local y comprimirla en un fichero <code>.TAR</code>. Y del mismo modo, con <code>docker load -i</code> puedo recuperar la imagen comprimida en ese .TAR.</p> <p>No obstante, no es la pr\u00e1ctica m\u00e1s recomendada para distribuir im\u00e1genes. Ya que lo ideal es subirla al registro p\u00fablico de Docker Hub (es necesario estar registrado).</p> <p>Desde el terminal podemos hacerlo con:</p> <pre><code>    docker login\n    docker push profe_web/milinux:v1\n</code></pre> <p>Una vez subidas, puedo acceder a ellas desde cualquier sitio mediante <code>docker pull</code>.</p>"},{"location":"CLOUD/ud4/#parametrizar-el-fichero-dockerfile","title":"PARAMETRIZAR EL FICHERO DOCKERFILE","text":"<p>Podemos crear variables dentro del Dockerfile, para que a la hora de crear las im\u00e1genes el usuario pueda indicar valores espec\u00edficos para ellas. Para ello usamos el comando <code>ARG</code> y un ejemplo ser\u00eda el siguiente:</p> <pre><code>    ARG PHP_VERSION=8.2-apache\n    FROM php:${PHP_VERSION}\n    ARG APP_VERSION=desarrollo\n    ENV VERSION=${APP_VERSION}\n    COPY app /var/www/html/\n    EXPOSE 80\n</code></pre> <p>De este modo, si al crear la imagen no se especifica nada, las variables coger\u00e1n el valor por defecto especificado dentro del comando ARG:</p> <pre><code>docker build  -t josedom24/app_php:v1 .\n</code></pre> <p>Y en caso de que el usuario quiera personalizar sus valores, podr\u00eda indicarlo en la cosntrucci\u00f3n de la siguiente manera:</p> <pre><code>docker build --build-arg PHP_VERSION=7.4-apache --build-arg APP_VERSION=produccion -t josedom24/app_php:v2 .\n</code></pre>"},{"location":"CLOUD/ud4/#dockerizar-aplicaciones-python","title":"DOCKERIZAR APLICACIONES PYTHON","text":"<p>En este ejemplo tenemos una aplicaci\u00f3n web desarrollada en Python mediante el m\u00f3dulo Flask. Que va a servir el contenido por el puerto 3000.</p> <pre><code>    from flask import Flask, render_template, abort, redirect, request\n    import datetime\n    import socket\n\n    app = Flask(__name__)\n\n    @app.route('/',methods=[\"GET\",\"POST\"])\n    def inicio():\n        hoy=datetime.datetime.now()\n        return render_template(\"inicio.html\",hoy=hoy,server=socket.gethostname())\n\n    if __name__ == '__main__':\n        app.run('0.0.0.0',3000,debug=True)\n</code></pre> <p>Un posible dockerfile para crear la imagen de mi aplicaci\u00f3n web, ser\u00eda el siguiente:</p> <pre><code>    FROM debian:12\n    RUN apt-get update &amp;&amp; apt-get install -y python3-pip  &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*\n    WORKDIR /usr/share/app\n    COPY app .\n    RUN pip3 install --no-cache-dir --break-system-packages -r requirements.txt\n    EXPOSE 3000\n    CMD python3 app.py\n</code></pre> <p>Para crear un contenedor a partir de la imagen que hemos creado:</p> <pre><code>    docker run -d -p 80:3000 --name appweb profe_web/miappweb:v1\n</code></pre> <p>Otra opci\u00f3n, ser\u00eda usar una imagen base que ya contenga el paquete PIP, y el dockerfile quedar\u00eda as\u00ed:</p> <pre><code>    FROM python:3.12.1-bookworm\n    WORKDIR /usr/share/app\n    COPY app .\n    RUN pip install --no-cache-dir -r requirements.txt\n    EXPOSE 3000\n    CMD python app.py\n</code></pre>"},{"location":"CLOUD/ud5/","title":"UNIDAD 5: INTRODUCCI\u00d3N A KUBERNETES (K8S)","text":"Logo Kubernetes"},{"location":"CLOUD/ud5/#que-es-kubernetes","title":"\u00bfQUE ES KUBERNETES?","text":"<p>Es una plataforma de c\u00f3digo abierto que sirve para automatizar la implementaci\u00f3n, escalado y operaci\u00f3n de aplicaciones con contenedores. Desarrollado por Google y luego liberado como c\u00f3digo abierto en 2014, actualmente es uno de los proyectos m\u00e1s populares de la Cloud Native Computing Foundation (CNCF). Ya que se ha convertido en la plataforma de orquestaci\u00f3n de contenedores m\u00e1s utilizada y ampliamente adoptada por empresas de todo el mundo.</p> <p>Kubernetes crea una capa de abstracci\u00f3n entre la infraestructura y las aplicaciones. Por ejemplo, ten\u00edendo m\u00faltiples servidores, te permite agruparlos en lo que llamariamos cl\u00faster y consumirlo como una pieza individual, permitiendo desplegar aplicaciones sobre todos los nodos del cl\u00faster de una forma transparente para el usuario.</p> <p>Por ejemplo, en un entorno tradicional un administrador de sistemas tendr\u00eda que provisionar una m\u00e1quina virtual (con sus configuraciones de red, paqueter\u00eda, hardware, etc) por cada aplicaci\u00f3n.</p> Despliegue Tradicional <p>Mientras que en un entorno de Kubernetes, el administrador solo tiene que a\u00f1adir y mantener los nodos del cluster, de modo que cuando se solicita una nueva aplicaci\u00f3n, se le asigna una reserva l\u00f3gica de recursos del cluster. Es decir, no le asignamos una \"m\u00e1quina\" sino un num\u00e9ro de recursos cuatificados en CPU y RAM, que no tienen por que estar en un nodo en concreto.</p> Despliegue Kubernetes <p>En resumen, Kubernetes nos aporta:</p> <ul> <li>Automatizaci\u00f3n de tareas y simplicaci\u00f3n de la operativa.</li> <li>Escalabilidad en funci\u00f3n de la demanda (Contenedores \u00f3 Nodos).</li> <li>Resiliencia ante errores o ca\u00eddas.</li> <li>Estandarizaci\u00f3n entre diferentes entornos (migraciones).</li> <li>Ecosistemas de servicios y funcionalidades.</li> </ul> <p>Oportunidades laborales</p> <p>Kubernetes es una tecnolog\u00eda muy demandada en el mercado laboral, por lo que tener conocimientos en Kubernetes puede abrirte muchas puertas en tu carrera profesional ya sea como especialista DevOps, Administrador de Sistemas o especialista en seguridad.</p>"},{"location":"CLOUD/ud5/#arquitectura-de-kubernetes","title":"ARQUITECTURA DE KUBERNETES","text":"<p>Todo cl\u00faster gestionado con Kubernetes consta de dos piezas fundamentales:</p> <p>El \"control plane\" o nodo maestro: responsable de gestionar al resto de nodos del cl\u00faster. No ejecuta <code>pods</code> ni ning\u00fan tipo de carga de trabajo, solo se limita a interactuar con el resto de nodos y gestionar los recursos del cl\u00faster.</p> <p>Los \"workers\" o nodos de trabajo alojan los <code>pods</code> (contenedores) y las cargas de trabajo, es decir, son los encargados de ejecutar las aplicaciones y servicios que se despliegan en el cl\u00faster.</p> Arquitectura Kubernetes"},{"location":"CLOUD/ud5/#componentes-basicos-de-cualquier-nodo","title":"COMPONENTES B\u00c1SICOS DE CUALQUIER NODO","text":"<p>CONTAINER RUNTIME: es el software que se encarga de ejecutar los contenedores. Docker es el m\u00e1s popular, pero en Kubernetes lo m\u00e1s habitual es usar containerd o CRI-O, versiones m\u00e1s ligeras y especializadas es este tipo de entornos.</p> <p>KUBELET: es el encargado de gestionar los contenedores en un nodo y de garantizar que estos se mantengan en el estado deseado. Se comunica con el API Server para recibir instrucciones y transmitirlas al runtime de contenedores.</p> <p>KUBE-PROXY: gestiona el tr\u00e1fico de red en el nodo. Se encarga de enrutar las peticiones a los servicios y de balancear la carga entre los pods. Tambi\u00e9n se encarga de la exposici\u00f3n de los servicios al exterior. Traduce las necesidades de red de los servicios a reglas de iptables de forma autom\u00e1tica.</p>"},{"location":"CLOUD/ud5/#componentes-especificos-del-nodo-maestro","title":"COMPONENTES ESPEC\u00cdFICOS DEL NODO MAESTRO","text":"<p>KUBE-APISERVER: es el punto de entrada al cl\u00faster. Es el componente que recibe las peticiones de los usuarios y de los nodos de trabajo. Es el \u00fanico que se comunica directamente con la base de datos de Kubernetes, etcd. Almacena el estado del cl\u00faster, gestiona las peticiones y las transforma en acciones.</p> <p>KUBE-SCHEDULER: es el encargado de decidir en qu\u00e9 nodo se ejecutar\u00e1 un pod. Se basa en las necesidades de los pods y en las capacidades de los nodos para tomar la decisi\u00f3n.</p> <p>ETCD: es la base de datos de Kubernetes. Almacena el estado del cl\u00faster y es el \u00fanico componente que almacena informaci\u00f3n de forma persistente. Es altamente consistente y tolerante a fallos.</p> <p>KUBE-CONTROLLER-MANAGER: es el componente que se encarga de gestionar los controladores de Kubernetes. Los controladores son procesos que se ejecutan de forma continua y que se encargan de mantener el estado deseado del cl\u00faster. Por ejemplo, el controlador de replicaci\u00f3n se encarga de mantener el n\u00famero de r\u00e9plicas de un pod en el estado deseado.</p> <p>CLOUD-CONTROLLER-MANAGER: es como el kube-controller-manager pero para entornos en la nube. Se encarga de interactuar con los servicios del proveedor, como los vol\u00famenes de almacenamiento, balanceadores de carga, etc.</p> <p>En resumen, el api de kubernetes gestiona todas las peticiones de los usuarios o de los nodos y el scheduler decide donde se ejecutan los pods. Mientras que el controlador mantiene el estado deseado del cl\u00faster y el etcd almacena el estado del cl\u00faster.</p> Cluster Kubernetes y sus componentes"},{"location":"CLOUD/ud5/#instalacion-de-kubernetes","title":"INSTALACI\u00d3N DE KUBERNETES","text":"<p>Existen varias formas mediante las cuales podemos instalar Kubernetes, dependiendo de que para que finalidad vayamos a usarlo. Principalmente, distinguiremos el uso en entornos de desarrollo y en entornos de producci\u00f3n.</p> <ul> <li> <p>Desarrollo: para crear de forma r\u00e1pida entornos de prueba o laboratorios de pr\u00e1cticas ligeros, existen varias alternativas como MiniKube, Kind o a trav\u00e9s de Docker Desktop.</p> </li> <li> <p>Producci\u00f3n: por un lado, podemos crear un cluster Kubernetes mediante la herramienta oficial Kubeadm, la cual requiere que instalemos manualmente todos los recursos necesarios y puede ser una tarea compleja, sobretodo la primera vez que se hace.</p> <p>Y por otro lado, la forma m\u00e1s recomendada para un entorno de producci\u00f3n profesional, que es contratando servicios en la nube como Amazon EKS o Google GKE; que aunque conllevan un coste a\u00f1adido, facilita mucho las cosas ya que el proveedor gestiona el plano de control por nosotros.</p> </li> </ul>"},{"location":"CLOUD/ud5/#instalacion-con-kubeadm","title":"INSTALACI\u00d3N CON KUBEADM","text":"Logo Kubeadm <p>En el siguiente enlace podemos ver un tutorial bastante completo sobre como crear un laboratorio pr\u00e1ctico de Kubernetes con 3 m\u00e1quinas virtuales Ubuntu (1 Nodo Maestro y 2 Nodos Trabajadores). Sin embargo, nosotros seguiremos el resumen de pasos que tenemos a continuaci\u00f3n:</p>"},{"location":"CLOUD/ud5/#a-ejecutar-en-todos-los-nodos-del-cluster","title":"A EJECUTAR EN TODOS LOS NODOS DEL CL\u00daSTER","text":"<p>Hasta que se indique lo contrario, todos los siguientes comandos se ejecutan como root, para actualizar repositorio de paquetes, instalar requisitos previos, desactivar el swap, cargar m\u00f3dulos necesarios y configuraci\u00f3n sysctl:</p> <pre><code>sudo su\n\napt update &amp;&amp; apt upgrade -y\napt install curl apt-transport-https git wget software-properties-common lsb-release ca-certificates socat -y\n\nswapoff -a\nsed -i '/swap/s/^\\(.*\\)$/#\\1/g' /etc/fstab\n\nmodprobe overlay\nmodprobe br_netfilter\n\ncat &lt;&lt; EOF | tee /etc/sysctl.d/kubernetes.conf\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\nEOF\n\nsysctl --system\n</code></pre> <p>Instalar las claves gpg de Docker para luego instalar y configurar containerd para que use cgroups:</p> <pre><code>sudo install -m 0755 -d /etc/apt/keyrings\n\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\napt update &amp;&amp; apt install containerd.io -y\n\ncontainerd config default | tee /etc/containerd/config.toml\n\nsed -e's/SystemdCgroup = false/SystemdCgroup = true/g' -i /etc/containerd/config.toml\n\nsystemctl restart containerd\n</code></pre> <p>Instalar claves gpg de Kubernetes, a\u00f1adir el repositorio (cambiar la versi\u00f3n si es necesario) e instalar kubeadm, kubelet y kubectl:</p> <pre><code>curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n\necho \"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /\" | sudo tee /etc/apt/sources.list.d/kubernetes.list\n\napt update\n\napt install -y kubeadm=1.30.1-1.1 kubelet=1.30.1-1.1 kubectl=1.30.1-1.1\n\napt-mark hold kubelet kubeadm kubectl\n</code></pre> <p>Editamos el fichero <code>/etc/hosts</code>, para a\u00f1adir el nombre del nodo maestro al DNS local, de modo que sea alcanzable por su hostname (en este ejemplo el hostname ser\u00eda k8scp):</p> <pre><code>echo \"&lt;Direcci\u00f3n_IP_Maestro&gt; k8scp\" &gt;&gt; /etc/hosts\n</code></pre>"},{"location":"CLOUD/ud5/#a-ejecutar-solo-en-el-nodo-maestro","title":"A EJECUTAR SOLO EN EL NODO MAESTRO","text":"<p>Iniciar el cluster con kubeadm (importante cambiar el rango de IPs para pods por uno que no est\u00e9 en uso en tu red, evitar tambi\u00e9n el rango 10.XXX.XXX.XXX ya que es un rango reservado para redes privadas). Por \u00faltimo, a\u00f1adimos el nombre del nodo maestro (recuerda usar el de antes) y el puerto 6443:</p> <pre><code>kubeadm init --pod-network-cidr=&lt;rango de IPs para pods&gt; --control-plane-endpoint=&lt;Nombre a\u00f1a\u00f1adido en el /etc/hosts&gt;:6443\n\n# EJEMPLO: kubeadm init --pod-network-cidr=192.168.0.0/16 --control-plane-endpoint=k8scp:6443\n</code></pre> <p>\u00a1\u00a1IMPORTANTE!!</p> <p>La salida del comando anterior nos mostrar\u00e1 una serie de datos, incluyendo un comando <code>kubeadm join</code> que luego tendremos que ejecutar en los nodos workers para unirlos al cluster.</p> <p>\u00bfComo eliminar un cluster inicializado con Kubeam?</p> <pre><code>sudo kubeadm reset\nsudo rm -R /etc/cni/net.d\nsudo iptables -F\n\nsudo rm -rf /etc/kubernetes/pki/\nsudo rm -rf /var/lib/kubelet/*\nsudo rm -rf /var/lib/etcd/\nsudo rm -rf ~/.kube/config\n</code></pre> <p>Salir del modo root y configurar kubectl e instalar autocompletado:</p> <pre><code>exit\n#Comprobar si existe ya la carpeta, si no, crearla con: mkdir -p $HOME/.kube\n\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nsudo apt install bash-completion -y\n\nsource &lt;(kubectl completion bash)\n\necho 'source &lt;(kubectl completion bash)' &gt;&gt; ~/.bashrc\n\ncurl -fsSL https://packages.buildkite.com/helm-linux/helm-debian/gpgkey | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg &gt; /dev/null\n\necho \"deb [signed-by=/usr/share/keyrings/helm.gpg] https://packages.buildkite.com/helm-linux/helm-debian/any/ any main\" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list\n</code></pre> <p>Instalar Helm (necesario para instalar algunas aplicaciones en Kubernetes) y Cilium (nos permitir\u00e1 conectar los pods entre s\u00ed):</p> <pre><code>sudo apt update\n\nsudo apt install helm -y\n\nhelm repo add cilium https://helm.cilium.io/\n\nhelm repo update\n\nhelm template cilium cilium/cilium --version 1.16.1 --namespace kube-system &gt; cilium.yaml\n\nkubectl apply -f cilium.yaml\n</code></pre>"},{"location":"CLOUD/ud5/#unir-todos-los-nodos-al-cluster","title":"UNIR TODOS LOS NODOS AL CLUSTER","text":"<p>En cada uno de los nodos worker pegamos el comando que nos devolvio la instrucci\u00f3n <code>kubeadm init</code> lanzar el siguiente comando:</p> <pre><code>    kubeadm join &lt;hostname_nodo_maestro&gt;:6443 --token &lt;token&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt;\n</code></pre> <p>Si por alg\u00fan motivo, no copiamos ese comando o no conocemos algunos de los datos necesarios, podemos ejecutar lo siguiente en el Nodo Maestro para conseguir la informaci\u00f3n:</p> <ul> <li> <p>Para ver el token o si fuera necesario, crear uno nuevo:</p> <pre><code>kubeadm token list\nkubeadm token create\n</code></pre> </li> <li> <p>Para ver el hash:</p> <pre><code>openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'\n</code></pre> </li> </ul> <p>Por \u00faltimo, comprobamos que los nodos se han a\u00f1adido correctamente, ejecutando el siguiente comando en el nodo Maestro:</p> <pre><code>kubectl get nodes\n</code></pre>"},{"location":"CLOUD/ud5/#instalacion-kubernetes-con-kind","title":"INSTALACI\u00d3N KUBERNETES CON KIND","text":"<p>En este caso, vamos a configurar un entorno de pr\u00e1cticas m\u00e1s ligero y facil de configurar usando \"KIND\" (Kubernetes in Docker), que nos permite crear un cl\u00faster Kubernetes en el que cada nodo sea un contenedor.</p> Logo Kind <p>Partimos de una m\u00e1quina Ubuntu en la que tenemos previamente instalado Docker. Entonces, vamos a descargar el binario de Kind y a colocarlo en un directorios accesible desde <code>$PATH</code>:</p> <pre><code>curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.10.0/kind-linux-amd64\nchmod +x ./kind\nsudo mv ./kind /usr/local/bin\nkind version\n</code></pre> <p>Por otro lado, instalamos la utilidad <code>kubectl</code> que es el cliente usado para interactuar con nuestro cl\u00faster Kubernetes:</p> <pre><code>curl -Lo ./kubectl \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x ./kubectl\nsudo mv ./kubectl /usr/local/bin\nkubectl version --client\n</code></pre> <p>Con estos simples pasos, ya podemos empezar a definir nuestro cluster Kubernetes con Kind.</p>"},{"location":"CLOUD/ud5/#practica-1-creacion-de-un-cluster-con-kind","title":"PR\u00c1CTICA 1: CREACI\u00d3N DE UN CLUSTER CON KIND","text":""},{"location":"CLOUD/ud5/#personalizar-la-red-virtual-del-cluster","title":"PERSONALIZAR LA RED VIRTUAL DEL CLUSTER","text":"<p>Cuando levantamos un cluster con KIND, este crea una red Bridge llamada kind con un direccionamiento por defecto. Para que ese direccionamiento no se solape o interfiera en los direccionamientos que ya tenemos en uso, vamos a crear nosotros esa red con los par\u00e1metros que queramos:</p> <pre><code>docker network create --subnet 192.168.0.0/24 --gateway 192.168.0.1 kind\n</code></pre>"},{"location":"CLOUD/ud5/#crear-fichero-de-configuracion-del-cluster","title":"CREAR FICHERO DE CONFIGURACI\u00d3N DEL CLUSTER","text":"<p>Por otro lado, podemos personalizar las caracter\u00edsticas que tendr\u00e1 nuestro cluster mediante el fichero <code>config.yaml</code>, como el nombre del cluster, el n\u00famero de nodos, el rol de cada nodo, mapeado de puertos, direccionamiento de los pods y servicios, almacenamiento persistente, etc. Un ejemplo sencillo de un cluster con 4 nodos, puede ser:</p> nano config.yaml <pre><code>kind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nname: cpd\nnodes:\n- role: control-plane\n- role: worker\n- role: worker\n- role: worker\n</code></pre>"},{"location":"CLOUD/ud5/#levantar-el-cluster","title":"LEVANTAR EL CLUSTER","text":"<p>Por \u00faltimo, solo tenemos que crear nuestro cluster con el siguiente comando:</p> <pre><code>kind create cluster --config=config.yaml\n</code></pre> <p>Credenciales de Acceso al Cluster</p> <p>Podemos comprobar que cuando se crea un cluster, se crea tambi\u00e9n el fichero de configuraci\u00f3n con nuestras credenciales para el acceso en <code>~/.kube/config</code>.</p> <p>Comprobaremos que se han creado tantos contenedores como nodos habiamos indicado en el fichero de configuraci\u00f3n:</p> <pre><code>docker ps\n</code></pre> <p>Y si todo ha ido bien, podemos usar la funcionalidad <code>kubectl</code> para confirmar que todos los nodos est\u00e1n en estado \"Ready\":</p> <pre><code>kind get clusters\nkubectl get nodes\n</code></pre>"},{"location":"CLOUD/ud5/#tipos-de-objetos-kubernetes","title":"TIPOS DE OBJETOS KUBERNETES","text":"<p>Un objeto o recurso, es cualquier cosa que podemos definir en un cluster de kubernetes. Cada objeto es de un tipo concreto y tiene unas propiedades y atributos que lo definen. Para definir un objeto, se hace mediante archivos manifiesto que se aplican al cluster para que se crear o modificar recursos. Estos manifiestos pueden ser escritos en formato YAML o JSON, y los principales objetos que podemos definir son:</p> <p>POD: es el recurso m\u00e1s b\u00e1sico que podemos crear en Kubernetes, generalmente compuesto por un contenedor (o varios). No es habitual crear pods manualmente, si no a partir de un objeto \"Deployment\".</p> <p>DEPLOYMENT: generalmente se utilizan para definir aplicaciones compuestas por varios \"Pods\" y las caracter\u00edsticas espec\u00edficas de cada uno.</p> <p>SERVICE: permite exponer los pods o aplicaciones para que se accede desde fuera del cluster.</p> <p>VOLUME: usado para persistir informaci\u00f3n de uno o varios pods.</p> <p>NAMESPACE: permite agrupar una serie de recursos en diferentes espacios l\u00f3gicos separados, dentro del mismo cluster.</p> Objetos Kubernetes"},{"location":"CLOUD/ud5/#los-manifiestos-yaml","title":"LOS MANIFIESTOS .YAML","text":"<p>En el archivo .yaml del objeto que queramos crear, obligatoriamente debemos indicar (como m\u00ednimo) los siguientes apartados:</p> <ul> <li>apiVersion: versi\u00f3n de la API de Kubernetes que se va a usar.</li> <li>kind: tipo de objeto que quieres crear.</li> <li>metadata: datos que identifican un\u00edvocamente al objeto (name, uid, namespace...).</li> <li>spec: caracter\u00edsticas espec\u00edficas del objeto (contendores, volumenes...).</li> </ul> <p>Por otro lado, es importante destacar que podemos crear varios objetos diferentes usando un \u00fanico manifiesto.yaml, simplemente deben ir separados por un triple gui\u00f3n <code>---</code>.</p>"},{"location":"CLOUD/ud5/#pods","title":"PODS","text":"<p>Como ya mencionamos, un pod es el recurso m\u00e1s b\u00e1sico de Kubernetes y aunque lo m\u00e1s com\u00fan es crearlos a trav\u00e9s de manifiestos de mayor nivel, como un Deployment; tambi\u00e9n es posible crear pods individualmente de las siguientes formas:</p>"},{"location":"CLOUD/ud5/#con-kubectl","title":"CON KUBECTL","text":"<p>Los principales gestores y orquestadores de contenedores, estan basados en el mismo estandar OCI (Open Container Initiative), es por ello que podemos usar cualquier im\u00e1gen descargada de Docker Hub, para crear un Pod en Kubernetes:</p> <pre><code>kubectl run mypod1 --image=nginx\n</code></pre>"},{"location":"CLOUD/ud5/#con-un-manifiesto","title":"CON UN MANIFIESTO","text":"<p>No obstante, como ya hemos comentado, en Kubernetes lo normal es definir los recursos mediante manifiestos. Por lo tanto, un ejemplo para crear un Pod igual que el anterior a trav\u00e9s de un fichero <code>pod.yaml</code>, ser\u00eda el siguiente:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n    name: mypod2\nspec:\n    containers:\n      - name: webproxy\n        image: nginx\n</code></pre> <p>Luego creamos el Pod mediante el comando:</p> <pre><code>kubectl apply -f pod.yaml\n</code></pre> <p>Una vez que hemos creado un recurso mediante un manifiesto, podemos modificarlo sin necesidad de pararlo. Simplemente editando su manifiesto y volviendo a ejecutar <code>kubectl apply</code>. Por ejemplo:</p> <pre><code>kubectl exec nginx -- cat /etc/os-release\nnano nginx.yaml\n\n#  Modificamos la imagen por \"image: nginx:alpine\"\n\n kubectl apply -f pod.yaml\n kubectl exec nginx -- cat /etc/os-release\n</code></pre> <p>Como vemos, con la instrucci\u00f3n <code>kubectl exec &lt;nombre_pod&gt; -- &lt;comando&gt;</code> podemos ejecutar ordenes dentro de un pod.</p> <p>Tambi\u00e9n, usando la instrucci\u00f3n <code>kubectl describe pod &lt;nombre_pod&gt;</code> podemos ver informaci\u00f3n detalla de un pod, como la imagen usada, en que nodos del cluster se est\u00e1 ejecutando o un hist\u00f3rico de eventos, entre otros.</p> <p>Por \u00faltimo, podemos borrar un pod usando la instrucci\u00f3n <code>kubectl delete pod &lt;nombre_pod&gt;</code>.</p>"},{"location":"CLOUD/ud5/#namespace-y-contexto","title":"NAMESPACE y CONTEXTO","text":"<p>Los namespaces son una forma de agrupar los recursos de kubernetes. Esto permite que podamos gestionar los diferentes recursos de una aplicaci\u00f3n ( pod, deployment, service, etc) para establecer unas cuotas recursos, pol\u00edticas de seguridad y configuraciones espec\u00edficas.</p> <p>Por defecto, existen cuatro namespaces que usa Kubernetes, que no debemos tocar. Para listar los namespaces creados en nuestro cluster, mostrando sus etiquetas (opci\u00f3n que nos puede ser muy \u00fatil m\u00e1s adelante) podemos usar:</p> <pre><code>kubectl get ns --show-labels\n</code></pre> <p>Al igual que pasaba con los pods, podemos crear namespaces por l\u00ednea de comandos con <code>kubectl create ns &lt;nombre_namespace&gt;</code>; o mediante un manifiesto con la opci\u00f3n <code>kubectl create -f &lt;nombre_fichero&gt;</code>. Un ejemplo muy simple de manifiesto para un namespace ser\u00eda:</p> <pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\nname: desarrollo\nlabels:\n    name: desarrollo\n</code></pre> <p>Para ejecutar comandos dentro de un namespace, usaremos la instrucci\u00f3n:</p> <pre><code>kubectl --namespace desarrollo get pods\n</code></pre> <p>Sin embargo, salvo que queramos lanzar un comando puntual, lo que se suele hacer es asociar el namespace donde queremos trabajar al contexto actual. Un contexto Kubernetes define la configuraci\u00f3n de acceso a un cluster espec\u00edfico, incluyendo el nombre del cluster, nombre de usuario y namespace predeterminado. Podemos ver nuestro contexto actual mediante el comando:</p> <pre><code>kubectl config view\n</code></pre> <p>Como por defecto, usamos el namespace \"default\", vemos que no se indica ning\u00fan namespace. Pero podemos asignar el namespace que queramos a nuestro contexto, usando:</p> <pre><code>kubectl config set-context &lt;contexto_actual&gt; --namespace=&lt;nombre_namespace&gt;\n</code></pre> <p>Para volver al namespace por default</p> <p>Es importante remarcar que un namespace no es una barrera de seguridad, sino una forma de organizar y gestionar los recursos de forma agrupada. Para aislar recursos de forma segura, debemos usar Network Policies y RBAC.</p>"},{"location":"CLOUD/ud5/#deployment-y-replicaset","title":"DEPLOYMENT y REPLICASET","text":"<p>Los Deployments son elementos de configuraci\u00f3n que permiten la creaci\u00f3n de una aplicaci\u00f3n de una sola instancia. El deployment gestiona uno o varios objetos replicaset y estos a su vez gestionan uno o m\u00e1s pods.</p> <p>Un ReplicaSet es un objeto Kubernetes que asegura que un n\u00famero espec\u00edfico de r\u00e9plicas de un pod est\u00e9n ejecut\u00e1ndose en todo momento. Los deployments utilizan este recurso para gestionar la creaci\u00f3n, actualizaci\u00f3n y eliminaci\u00f3n de pods; asegurando la alta disponibilidad y escalabilidad.</p>"},{"location":"CLOUD/ud5/#practica-2-despliegue-nginx-en-kubernetes","title":"PR\u00c1CTICA 2: DESPLIEGUE NGINX EN KUBERNETES","text":""},{"location":"CLOUD/ud5/#crear-el-fichero-deployment","title":"CREAR EL FICHERO DEPLOYMENT","text":"nano deployment.yaml <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: nginx\nnamespace: default\nlabels:\n    app: nginx\nspec:\nrevisionHistoryLimit: 2\nstrategy:\n    type: RollingUpdate\nreplicas: 2\nselector:\n    matchLabels:\n    app: nginx\ntemplate:\n    metadata:\n    labels:\n        app: nginx\n    spec:\n    containers:\n    - image: nginx\n        name: nginx\n        ports:\n        - name: http\n        containerPort: 80\n</code></pre>"},{"location":"CLOUD/ud5/#crear-el-fichero-service","title":"CREAR EL FICHERO SERVICE","text":"nano service.yaml <pre><code>apiVersion: v1\nkind: Service\nmetadata:\nname: nginx\nnamespace: default\nspec:\ntype: NodePort\nports:\n- name: http\n    port: 80\n    targetPort: http\nselector:\n    app: nginx\n</code></pre>"},{"location":"CLOUD/ud5/#crear-el-despliegue-y-el-servicio","title":"CREAR EL DESPLIEGUE Y EL SERVICIO","text":"<pre><code>kubectl apply -f deployment.yaml \nkubectl create -f service.yaml\n</code></pre> <p>Comprobamos que se han creado los pods relativos al despiegue y estan en ejecuci\u00f3n; y que se ha creado el servicio y sobre que puerto del nodo lo ha mapeado:</p> <pre><code>kubectl get all\n</code></pre> <p>Por \u00faltimo, comprobamos la direcci\u00f3n ip que tiene el nodo maestro (ya que ser\u00e1 el que reciba las peticiones):</p> <pre><code>docker inspect cpd-control-plane | grep Address\n</code></pre> <p>Y si todo fue bien, abrimos un navegador y deber\u00edamos poder acceder al servicio indicando la IP del nodo y el puerto en el que se ha mapeado el servicio. Por ejemplo <code>http://192.168.0.4:31287</code>.</p>"},{"location":"CLOUD/ud5/#monitorizacion-de-cluster-kubernetes","title":"MONITORIZACI\u00d3N DE CL\u00daSTER KUBERNETES","text":"Logo Prometheus Logo Grafana"},{"location":"CLOUD/ud5/#que-es-prometheus","title":"\u00bfQU\u00c9 ES PROMETHEUS?","text":"<p>Prometheus  es un conjunto de herramientas de c\u00f3digo abierto para la monitorizaci\u00f3n y notficaci\u00f3n de alertas de sistemas.</p> <p>Prometheus recopila y almacena localmente m\u00e9tricas sobre aplicaciones y servicios en ejecuci\u00f3n en datos de series de tiempo, es decir, la informaci\u00f3n de las m\u00e9tricas se almacena con la marca de tiempo en la que se registr\u00f3, junto con pares clave-valor opcionales llamados etiquetas.</p> <p>Podemos visualizar estos datos mediante clientes API como Grafana.</p>"},{"location":"CLOUD/ud5/#componentes-prometheus","title":"COMPONENTES PROMETHEUS","text":"<p>El ecosistema Prometheus consta de m\u00faltiples componentes, muchos de los cuales son opcionales:</p> <ul> <li>El servidor  principal de Prometheus que recopila y almacena datos de series temporales.</li> <li>Librer\u00edas de cliente para instrumentar el c\u00f3digo de la aplicaci\u00f3n.</li> <li>Un push gateway para dar soporte a trabajos (jobs) de corta duraci\u00f3n.</li> <li>Exportadores de terceros para diferentes prop\u00f3sitos, como por ejemplo <code>Grafana</code>.</li> <li>Un Alert Manager  para gestionar alertas.</li> <li>Herramientas de soporte variadas.</li> </ul> Arquitectura Prometheus"},{"location":"CLOUD/ud5/#que-es-grafana","title":"\u00bfQU\u00c9 ES GRAFANA?","text":""},{"location":"CLOUD/ud5/#practica-3-monitorizando-mi-cluster-kubernetes","title":"PR\u00c1CTICA 3: MONITORIZANDO MI CL\u00daSTER KUBERNETES","text":"<p>Antes de nada, comprobamos que nuestro cl\u00faster se encuentra funcionando correctamente y todos los nodos est\u00e1n \"Ready\". Tambi\u00e9n, confirmamos si tenemos HELM instalado:</p> <pre><code>kubectl get nodes\n\nhelm version\n</code></pre> <p>Agregamos el paquete (chart) de Prometheus al repositorio de Helm y luego lo actualizamos:</p> <pre><code>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\n\nhelm repo update\n</code></pre> <p>Creamos un Namespace espec\u00edfico para las herramientas de monitorizaci\u00f3n:</p> <pre><code>kubectl create namespace monitoring\n</code></pre> <p>Objeto SECRET</p> <p>Un \"Secret\" en Kubernetes es un recurso para almacenar informaci\u00f3n sensible (contrase\u00f1as, tokens, claves SSH) de forma segura, separada del c\u00f3digo y las configuraciones no confidenciales. Permitiendo que los Pods los consuman como archivos montados o variables de entorno sin exponerlos directamente.</p> <p>Creamos dos ficheros, uno para el nombre de usuario y otro para la contrase\u00f1a. Y con ellos creamos un objeto <code>secret</code> donde se almacenar\u00e1 esa informaci\u00f3n sensible:</p> <pre><code>echo -n 'admin' &gt; ./admin-user\n\necho -n 'mipass123' &gt; ./admin-password\n\nkubectl create secret generic grafana-admin-credentials --from-file=./admin-user --from-file=admin-password -n monitoring\n</code></pre> <p>Confirmamos que se ha creado nuestro secret y en caso positivo, podemos borrar los ficheros previamente creados:</p> <pre><code>kubectl describe secret -n monitoring grafana-admin-credentials\n\nrm admin-user &amp;&amp; rm admin-password\n</code></pre> <p>Si queremos verificar el usuario y contrase\u00f1a:</p> <pre><code># PARA EL NOMBRE DE USUARIO\nkubectl get secret -n monitoring grafana-admin-credentials -o jsonpath=\"{.data.admin-user}\" | base64 --decode\n\n# PARA LA CONTRASE\u00d1A\nkubectl get secret -n monitoring grafana-admin-credentials -o jsonpath=\"{.data.admin-password}\" | base64 --decode\n</code></pre> <p>Descargamos el archivo values.yaml  desde el repositorio de Prometheus. Este archivo contiene todos los par\u00e1mentros que podemos configurar dentro de la herramienta (nombre de los elementos, servicios habilitados, permisos...):</p> <pre><code>curl -O https://raw.githubusercontent.com/prometheus-community/helm-charts/refs/heads/main/charts/kube-prometheus-stack/values.yaml\n</code></pre> <p>Y lo personalizamos para que Grafana coja las credenciales que hemos creado m\u00e1s arriba:</p> <pre><code>sed -n '1321p' values.yaml\n\nsed -i '1321c\\    existingSecret: \"grafana-admin-credentials\"' values.yaml\n\nsed -n '1321p' values.yaml\n</code></pre> <p>DESINSTALACI\u00d3N:</p> <p>Si por alg\u00fan  motivo necesitamos eliminar el despliegue de Prometheus, podemos hacerlo con:     helm uninstall prometheus -n monitoring</p> <p>Y procedemos a instalar la herramienta:</p> <pre><code>helm install -n monitoring prometheus prometheus-community/kube-prometheus-stack -f values.yaml\n</code></pre> <p>Si necesitamos realizar cambios en la configuraci\u00f3n del values.yaml, podemos aplicar los cambios ejecutando:</p> <pre><code>helm upgrade -n monitoring prometheus prometheus-community/kube-prometheus-stack -f values.yaml\n</code></pre> <p>Por \u00faltimo, creamos un renvio de puertos hac\u00eda el contenedor de Grafana (\u00a1OJO!: deberemos consultar primero su nombre), para que podamos acceder a la interfaz gr\u00e1fica desde un navegador fuera de nuestro cl\u00faster:</p> <pre><code># Para no permitir cualquier acceso, podemos sustituir \"0.0.0.0\" por la direcci\u00f3n IP del nodo Maestro\n\nkubectl port-forward -n monitoring prometheus-grafana-xxxxxxx 52222:3000 --address 0.0.0.0\n</code></pre> <p>ERROR PODS NOT RUNNING</p> <pre><code>kubectl rollout restart *\n</code></pre> <p>ERROR KUBECTL PORT 6443</p> <pre><code>sudo -i\nswapoff -a\nexit\n</code></pre> <p>Ahora ya podemos ir a nuestro navegador (desde un PC que tenga conectividad con los nodos de nuestro cl\u00faster) y podemos ver la interfaz de Grafana usando la direcci\u00f3n <code>http://&lt;IP_NODO_MAESTRO&gt;:52222</code>. Tras iniciar sesi\u00f3n, iremos al men\u00fa lateral izquierdo, al apartado de \"Connnections\":</p> Conections en Grafana"},{"location":"CLOUD/ud6/","title":"UNIDAD 6: INTRODUCCI\u00d3N A TERRAFORM","text":"Logo de Terraform"},{"location":"PYTHON/indexp/","title":"PROGRAMACI\u00d3N CON PYTHON","text":"<p>\u00cdNDICE DE CONTENIDOS:</p> <ol> <li>Libros y Herramientas \u00datiles</li> <li>Fundamentos Python</li> <li>Manipulaci\u00f3n de datos</li> <li>Creaci\u00f3n de APIs REST</li> <li>Aplicaciones web con Python</li> </ol> <p>MATERIALES FORMACI\u00d3N PROFESIONAL INFORM\u00c1TICA by Lorenzo Le\u00f3n Valor is licensed under CC BY-NC-SA 4.0</p>"},{"location":"PYTHON/ud0/","title":"LIBROS Y HERRAMIENTAS \u00daTILES PARA EL DESARROLLO DEL M\u00d3DULO","text":""},{"location":"PYTHON/ud0/#libros-de-referencia","title":"LIBROS DE REFERENCIA","text":""},{"location":"PYTHON/ud0/#herramientas-web-utiles","title":"HERRAMIENTAS WEB \u00daTILES","text":""},{"location":"PYTHON/ud0/#anaconda","title":"ANACONDA","text":"<p>\u00bfQue hace?</p> <p>Es una distribuci\u00f3n de c\u00f3digo abierto de Python y R, muy utilizada para la ciencia de datos y la inteligencia artificial, que incluye un gestor de paquetes (Conda) y cientos de librer\u00edas preinstaladas.</p> <p></p>"},{"location":"PYTHON/ud1/","title":"FUNDAMENTOS DE PYTHON","text":""},{"location":"PYTHON/ud1/#que-es-python","title":"\u00bfQUE ES PYTHON?","text":"<p>Python es un lenguaje de programaci\u00f3n creado por Guido Van Rossum y lanzado en 1991. Aunque su logotipo son dos cabezas de pit\u00f3n, su nombre no viene del nombre del animal, si no del grupo c\u00f3mico ingles \"Monty Python\".</p>"},{"location":"PYTHON/ud1/#caracteristicas-principales","title":"Caracter\u00edsticas principales","text":"<p>Se trata de un lenguaje de alto nivel, con tipado dinamico y fuerte. Adem\u00e1s, es un lenguaje interpretado y orientado a objetos.</p>"},{"location":"PYTHON/ud1/#alto-nivel","title":"Alto Nivel","text":"<p>Se dice que un lenguaje es de alto nivel cuando su sintaxis se asemeja m\u00e1s al lenguaje humano, que al lenguaje m\u00e1quina. En este caso, podriamos decir que Python es de muy alto nivel, ya que tiene una gram\u00e1tica sencilla y facilmente legible. Se llega a decir (bromeando) que cualquiera que sepa ingl\u00e9s, puede entender c\u00f3digo fuente en Python.</p>"},{"location":"PYTHON/ud1/#fuertemente-tipado","title":"Fuertemente Tipado","text":"<p>Quiere decir en este lenguaje hace una distinci\u00f3n estricta entre los diferentes tipos de datos, es decir, no va a permitir que una variable de un tipo espec\u00edfico (por ejemplo num\u00e9rico) se utilice directamente como si fuera de otro tipo (como un texto) sin una conversi\u00f3n expl\u00edcita.</p>"},{"location":"PYTHON/ud1/#tipado-dinamico","title":"Tipado Din\u00e1mico","text":"<p>Se refiere que el tipo de dato de una variable se asigna y verifica en tiempo de ejecuci\u00f3n, no en la compilaci\u00f3n. Esto quiere decir que una variable puede cambiar su tipo de dato durante la ejecuci\u00f3n del programa y no necesitas declarar expl\u00edcitamente el tipo de dato al crear la variable.</p>"},{"location":"PYTHON/ud1/#interpretado","title":"Interpretado","text":"<p>Quiere decir que es traducido y ejecutado l\u00ednea por l\u00ednea en tiempo real, sin necesidad de un paso de compilaci\u00f3n previo. Un programa llamado int\u00e9rprete lee y ejecuta directamente el c\u00f3digo fuente. Esto aporta facilidad para desarrollar y depurar, y para su portabilidad entre diferentes sistemas operativos.</p>"},{"location":"PYTHON/ud1/#orientado-a-objetos","title":"Orientado a objetos","text":"<p>Es un paradigma de programaci\u00f3n donde, mediante c\u00f3digo fuente, se trata de representar entidades u objetos del mundo real. Para ello se crean clases (objetos), que definen una serie de caracter\u00edsticas (atributos) y comportamientos (m\u00e9todos) propios de dicho objeto. Estas clases son usadas luego a modo de plantillas, permitiendo la reutilizaci\u00f3n de c\u00f3digo, mejor organizaci\u00f3n y modularidad, encapsulaci\u00f3n de datos y un facil mantenimiento y modificaci\u00f3n de los programas.</p>"},{"location":"PYTHON/ud1/#porque-aprender-python","title":"\u00bfPORQUE APRENDER PYTHON?","text":"<p>Ampliamente utilizado en m\u00faltitud de campos laborales: </p> <p>Uno de los lenguajes de programaci\u00f3n m\u00e1s popular en la actualidad: </p>"},{"location":"PYTHON/ud1/#instalacion-de-python","title":"INSTALACI\u00d3N DE PYTHON","text":"<ul> <li>Descargar desde: https://www.python.org/downloads</li> <li>Aseg\u00farate de marcar la opci\u00f3n \"Add Python to PATH\" en Windows.</li> <li>Podemos verificar la instalaci\u00f3n as\u00ed como la versi\u00f3n instalada con el siguiente comando:</li> </ul> <pre><code>python --version\n</code></pre>"},{"location":"PYTHON/ud1/#instalacion-y-configuracion-del-entorno-de-desarrollo","title":"INSTALACI\u00d3N Y CONFIGURACI\u00d3N DEL ENTORNO DE DESARROLLO","text":"<ul> <li>Existen multitud de IDE que podemos usar para programar en Python, en nuestro caso usaremos VsCode</li> <li>Descargar desde: https://code.visualstudio.com/download</li> <li>Como antes, marcamos la opci\u00f3n \"Add to PATH\".</li> <li>Una vez instalado, vamos a la pesta\u00f1a Extensiones y debemos buscar e instalar Python (de Microsoft). Con ella obtendremos una serie de extensiones que nos ofrecen diferentes funcionalidades a la hora de programar en Python. </li> </ul>"},{"location":"PYTHON/ud1/#creacion-de-un-entorno-virtual","title":"CREACI\u00d3N DE UN ENTORNO VIRTUAL","text":""},{"location":"PYTHON/ud1/#que-es","title":"\u00bfQue es?","text":"<p>Es un directorio aislado que contiene una instalaci\u00f3n de Python y sus propias librer\u00edas y paquetes. Su principal objetivo es aislar las dependencias entre diferentes proyectos para evitar conflictos entre diferentes versiones de paquetes y asegurar que cada proyecto tenga unicamente las bibliotecas que necesita.</p>"},{"location":"PYTHON/ud1/#trabajar-con-entornos-virtuales-en-vscode","title":"Trabajar con entornos virtuales en VsCode","text":""},{"location":"PYTHON/ud1/#pasos-previos","title":"Pasos Previos","text":"<p>En primer lugar crearemos el directorio f\u00edsico donde se alojaran los archivos de nuestro proyecto.</p> <p>Luego abrimos ese directorio en el Explorador de VsCode: </p>"},{"location":"PYTHON/ud1/#creacion","title":"Creaci\u00f3n","text":"<p>Desde la pesta\u00f1a Terminal abrimos un nuevo terminal y ejecutamos el siguiente comando, que crear\u00e1 nuestro entorno virtual:</p> <pre><code>python -m venv envMiEntorno\n</code></pre>"},{"location":"PYTHON/ud1/#activacion","title":"Activaci\u00f3n","text":"<p>Una vez hemos creado el entorno, debemos activarlo. Para ello escribiremos lo siguiente:</p> <pre><code>envMiEntorno\\Scripts\\activate\n</code></pre> <p>Posible Error de Activaci\u00f3n</p> <p>Es posible que recibamos un error al ejecutar el comando anterior, ya que Windows por defecto tiene deshabilitada la ejecuci\u00f3n de scripts. En ese caso, abriremos PowerShell como Administrador y ejecutamos los siguientes comandos:</p> <pre><code>Get-ExecutionPolicy -List\nSet-ExecutionPolicy RemoteSigned -Scope CurrentUser\n</code></pre>"},{"location":"PYTHON/ud1/#instalacion-de-librerias-externas","title":"Instalaci\u00f3n de librer\u00edas externas","text":"<p>Mediante el comando pip accedemos al gestor de paquetes est\u00e1ndar de Python, que nos permite instalar y administrar software de terceros f\u00e1cilmente, para que podamos usarlo en nuestro proyecto. Para ello hace uso del repositorio Python Package Index (PyPI). Por ejemplo:</p> <pre><code>pip install mkdocs\npip install mkdocs-material\n</code></pre> <p></p>"},{"location":"PYTHON/ud1/#listar-dependencias","title":"Listar dependencias","text":"<p>Una dependencia es cualquier paquete software o librer\u00eda externa que tu proyecto requiere para funcionar, pero que no est\u00e1 incluido en la instalaci\u00f3n b\u00e1sica de Python.</p> <p>Por lo tanto, cada vez que instalamos un nuevo paquete, estamos a\u00f1adiendo dependencias a nuestro proyecto.</p> <p>Con el siguiente comando podemos ver cada una de las dependencias instaladas en nuestro entorno virtual, con sus correspondientes versiones:</p> <pre><code>pip freeze\n</code></pre>"},{"location":"PYTHON/ud1/#exportar-dependencias","title":"Exportar dependencias","text":"<p>Por buenas pr\u00e1cticas de programaci\u00f3n, los entornos virtuales nunca se suben a los repositorios de \"git\" o de cualquier otro manejador de versiones.</p> <p>Por ello, siempre es muy recomendable crear un archivo llamado requirements.txt, en el cual almacenaremos el listado de todas las dependencias que necesita nuestro proyecto:</p> <pre><code>pip freeze &gt; requirements.txt\n</code></pre> <p>Este archivo SI se sube al repositorio. De modo que, podremos generar nuevamente nuestro entorno en cualquier dispositivo o sistema operativo que deseemos, mediante el siguiente comando:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"PYTHON/ud1/#estructura-de-un-programa-en-python","title":"ESTRUCTURA DE UN PROGRAMA EN PYTHON","text":"<p>Un programa Python se divide en un n\u00famero de l\u00edneas l\u00f3gicas que se ejecutan de forma seuencial.</p> <p>El final de una l\u00ednea l\u00f3gica est\u00e1 representado por el caracter especial NEWLINE (salto de l\u00ednea).</p> <p>Uni\u00f3n de l\u00edneas expl\u00edcita: dos o m\u00e1s l\u00edneas f\u00edsicas pueden unirse en una \u00fanica l\u00ednea l\u00f3gica utilizando el caracter de barra invertida (). Una l\u00ednea que termina en barra invertida no puede llevar un comentario.</p> <pre><code>if 1900 &lt; year &lt; 2100 and 1 &lt;= month &lt;= 12 \\\n   and 1 &lt;= day &lt;= 31 and 0 &lt;= hour &lt; 24 \\\n   and 0 &lt;= minute &lt; 60 and 0 &lt;= second &lt; 60:   # Parece una fecha v\u00e1lida\n        return 1 \n</code></pre> <p>Uni\u00f3n de l\u00edneas implicita: las expresiones entre par\u00e9ntesis, entre corchetes o entre rizos pueden dividirse en m\u00e1s de una l\u00ednea f\u00edsica sin usar barras invertidas. Las l\u00edneas continuas impl\u00edcitas pueden llevar comentarios.</p> <pre><code>month_names = ['Januari', 'Februari', 'Maart',      # Son los\n               'April',   'Mei',      'Juni',       # nombres holandeses\n               'Juli',    'Augustus', 'September',  # para los meses\n               'Oktober', 'November', 'December']   # del a\u00f1o \n</code></pre> <p>Sangr\u00eda o Indentaci\u00f3n: a diferencia de otros lenguajes, en Python los espacios en blanco o tabulaciones al principio de cada l\u00ednea de c\u00f3digo, son un requisito de sintaxis que afecta directamente al funcionamiento del programa. Ya que se utilizan para agrupar instrucciones y definir bloques de c\u00f3digo, indicando qu\u00e9 l\u00edneas pertenecen, por ejemplo, a una funci\u00f3n, un bucle o una condici\u00f3n.</p> <p>En resumen, un programa de Python se construye a partir de uno o varios bloques de c\u00f3digo. Llamando bloque a cada parte del c\u00f3digo del programa que se ejecuta como una unidad. Como pueden ser por ejemplo, un m\u00f3dulo, el cuerpo de una funci\u00f3n o la definici\u00f3n de una clase.</p>"},{"location":"PYTHON/ud1/#sintaxis-basica-y-convenciones","title":"SINT\u00c1XIS B\u00c1SICA Y CONVENCIONES","text":""},{"location":"PYTHON/ud1/#convenciones-del-lenguaje","title":"Convenciones del Lenguaje","text":"<p>Se recomienda usar 4 espacios para cada nivel de indentaci\u00f3n.</p> <p>Uso de snake_case para variables, funciones y m\u00e9todos.</p> <pre><code>nombre_usuario = \"Juan\" \n</code></pre> <p>Uso de PascalCase para clases.</p> <pre><code>class MiClase \n</code></pre> <p>Uso de UPPERCASE para variables cuyo valor ser\u00e1 el mismo durante toda la ejecuci\u00f3n.</p> <pre><code>PI = 3.14159\n</code></pre>"},{"location":"PYTHON/ud1/#uso-de-comentarios-y-documentacion-del-codigo","title":"Uso de comentarios y documentaci\u00f3n del c\u00f3digo","text":"<p>Comentarios de una l\u00ednea: almohadilla (#)</p> <pre><code># Esto es un comentario de una l\u00ednea\n</code></pre> <p>Comentarios multil\u00ednea: comillas triples simples (''') o dobles (\"\"\"). Generalmente usadas para docstrings.</p> <pre><code>\"\"\" Esto es un comentario\nde varias l\u00edneas (tambi\u00e9n usado para documentaci\u00f3n)\n\"\"\"\n</code></pre> <p>Docstring: cadena de documentaci\u00f3n que describe la funcionalidad de un m\u00f3dulo, clase, m\u00e9todo o funci\u00f3n; y que es accesibles a trav\u00e9s del atributo doc del objeto.</p> <pre><code>def sumar(a, b):\n'''Devuelve la suma de los dos n\u00fameros\nque recibe como argumentos'''\nreturn a + b\n</code></pre>"},{"location":"PYTHON/ud1/#tipos-de-datos-y-variables","title":"TIPOS DE DATOS Y VARIABLES","text":""},{"location":"PYTHON/ud1/#tipos-de-datos","title":"Tipos de datos","text":"<ul> <li>En Python, vamos a diferenciar 4 tipos b\u00e1sicos de datos:</li> <li>N\u00fameros: int (entero), float (decimal), complex (complejos)</li> <li>Texto: str (cadenas de texto)</li> <li>Booleanos: bool (verdadero o falso)</li> <li>Ausencia de valor: None (se utiliza cuando queremos crear una variable sin un valor o tipo de dato espec\u00edfico por el momento.)</li> </ul> <pre><code>edad = 25 # N\u00famero entero\nprecio = 19.99 # N\u00famero decimal\nnombre = \"Python\" # Cadena de texto\nactivo = True # Booleana\nventas = None # Ausencia de valor\n</code></pre>"},{"location":"PYTHON/ud1/#colecciones","title":"Colecciones","text":"<ul> <li> <p>Listas: listado de valores mutable, que pueden ser del mismo o de diferentes tipos. Se definen entre corchetes.</p> <pre><code>lista1 = [5, 10, 2, 25]\nlista2 = [\"Hello\", \"Bye\", \"See you\"]\nlista3 = [10, \"Juan\", True, 35.6]\n</code></pre> </li> <li> <p>Tuplas: son como listas pero inmutables, es decir, sus valores no pueden modificarse. Se definen entre par\u00e9ntesis.</p> <pre><code>tupla1 = (10, 20, 30, 40)\n</code></pre> </li> <li> <p>Diccionarios conjunto no ordenado y mutable de pares (clave:valor), siendo las claves \u00fanicas dentro de un mismo diccionario. Se definen entre llaves.</p> <pre><code>diccionario1 = {\n    \"nombre\":\"Paquito\",\n    \"apellido\":\"Chocolatero\",\n    \"usuario\":\"chocopaquito\",\n    \"contrase\u00f1a\":\"1234\"\n    }\n</code></pre> </li> <li> <p>Conjuntos colecci\u00f3n no ordenada y mutable de elementos \u00fanicos. Suelen usarse para verificaci\u00f3n de pertenencia y eliminaci\u00f3n de entradas duplicadas. Se definen entre llaves.</p> <pre><code>conjunto1 = {10, 20, 30, 40}\nconjunto2 = {1, 2, 3, \"hola\", \"adios\"}\n</code></pre> </li> </ul>"},{"location":"PYTHON/ud1/#conversion-de-tipos","title":"Conversi\u00f3n de tipos","text":"<ul> <li>La conversi\u00f3n de tipos o casting, se realiza de forma expl\u00edcita utilizando las funciones constructoras int(), float(), str() para transformar valores de un tipo a otro. Por ejemplo:         <pre><code>int(\"10\")       # 10 (toma una cadena y devuelve un n\u00famero entero)\nstr(20)         # \"20\" (toma un n\u00famero entero y devuelve una cadena)\nfloat(\"3.14\")   # 3.14 (toma una cadena y devuelve un n\u00famero decimal)\n</code></pre></li> </ul>"},{"location":"PYTHON/ud1/#palabras-reservadas","title":"PALABRAS RESERVADAS","text":"<ul> <li>Las palabras reservadas son t\u00e9rminos que tienen un significado espec\u00edfico y est\u00e1n reservados por el lenguaje para su uso interno. Estos t\u00e9rminos no pueden ser utilizados como nombres de variables, funciones, etc.</li> </ul> <pre><code>False      await      else       import     pass\nNone       break      except     in         raise\nTrue       class      finally    is         return\nand        continue   for        lambda     try\nas         def        from       nonlocal   while\nassert     del        global     not        with\nasync      elif       if         or         yield\n</code></pre>"},{"location":"PYTHON/ud1/#estructuras-de-control","title":"ESTRUCTURAS DE CONTROL","text":""},{"location":"PYTHON/ud1/#condicionales","title":"Condicionales","text":"<ul> <li>if, elif y else: if es la sentencia condicional por excelencia, que puede ir seguido de cero o varios bloques elif, y de un bloque else de manera opcional.</li> </ul> <pre><code>if edad &gt; 18:\n    print(\"Eres mayor de edad\")\nelif edad == 18:\n    print(\"Tienes justo 18\")\nelse:\n    print(\"Eres menor de edad\")\n</code></pre> <ul> <li>match: recibe una expresi\u00f3n y compara su valor con patrones sucesivos dados en uno o m\u00e1s bloques \"case\". S\u00f3lo se ejecuta el primer caso que coincide, si no coincide ninguno, ninguna rama es ejecutada. Si queremos que la coincidencia nunca falle, podemos usar el gui\u00f3n bajo como comod\u00edn.</li> </ul> <pre><code>match estado_web:\n        case 400:\n            return \"Bad request\"\n        case 401 | 403:\n            return \"Not allowed\"\n        case 404:\n            return \"Not found\"\n        case _:\n            return \"Something's wrong with the internet\"\n</code></pre>"},{"location":"PYTHON/ud1/#bucles","title":"Bucles","text":"<ul> <li>for: en Python itera sobre los elementos de una secuencia (lista, tupla, cadena de texto...) o cualquier otro objeto iterable; en el orden que aparecen en dicha secuencia.</li> </ul> <pre><code>words = ['gato', 'ventana', 'perro']\nfor w in words:\n    print(w)\n</code></pre> <ul> <li>Por ello, cuando  necesitamos iterar sobre una secuencia de n\u00fameros en Python, es apropiado utilizar la funci\u00f3n integrada range(), la cual genera progresiones aritm\u00e9ticas:</li> </ul> <pre><code>for i in range(5):\n    print(i)\n</code></pre> <ul> <li>while: se usa para la ejecuci\u00f3n repetida de un bloque de c\u00f3digo, siempre que una expresi\u00f3n sea verdadera.</li> </ul> <pre><code>contador = 0\nwhile contador &lt; 5:\n    print(contador)\n    contador += 1\n</code></pre>"},{"location":"PYTHON/ud1/#control-de-flujo","title":"Control de flujo","text":"<ul> <li>break: termina el bucle adjunto m\u00e1s cercano, omitiendo la cl\u00e1usula else opcional si el bucle tiene una</li> <li>continue: contin\u00faa con la siguiente iteraci\u00f3n del bucle envolvente m\u00e1s cercano.</li> </ul> <pre><code>for i in range(10):\n    if i == 5:\n        break  # sale del bucle\n    if i % 2 == 0:\n        continue  # salta al siguiente ciclo\n    print(i)\n</code></pre> <ul> <li>pass: no hace nada. Es \u00fatil cuando por la sint\u00e1xis de Python se requiere una declaraci\u00f3n, pero nuestro programa no requiere ejecutar ning\u00fan c\u00f3digo.</li> </ul> <pre><code>class MiClaseVacia:\n    pass  #no hace nada, se usa como marcador de posici\u00f3n\n</code></pre>"},{"location":"PYTHON/ud1/#expcepciones-en-python","title":"Expcepciones en Python","text":"<ul> <li>En Python, cuando se produce un error, se genera una excepci\u00f3n. Las excepciones son eventos que simbolizan el error y contiene informaci\u00f3n sobre este. Si no se gestionan, lo m\u00e1s normal es que la ejecuci\u00f3n de nuestro programa termine de forma abrupta.</li> <li>Para evitar esto, podemos \"capturar\" excepciones usando bloques \"Try-Except\", como veremos a continuaci\u00f3n.</li> <li>El bloque try se utiliza para encapsular el c\u00f3digo que puede generar una excepci\u00f3n. Si no se produce ninguna excepci\u00f3n, el flujo del programa contin\u00faa normalmente. Si se produce una excepci\u00f3n, el flujo del programa se desv\u00eda al bloque except.</li> <li> <p>El bloque except se utiliza para capturar y manejar las excepciones que se producen dentro del bloque try. Dentro de este bloque se coloca el c\u00f3digo que se desea ejecutar en caso de que se produzca una excepci\u00f3n. Veamos un ejemplo:</p> <pre><code>try:\n    # C\u00f3digo que puede lanzar una excepci\u00f3n\n    resultado = 10 / 0\nexcept:\n    # C\u00f3digo a ejecutar si se produce una excepci\u00f3n\n    print(\"Se produjo una excepci\u00f3n.\")\n</code></pre> </li> <li> <p>Capturar varias excepciones: Podemos capturar excepciones espec\u00edficas utilizando la sintaxis \"except TipoDeExcepcion\" o capturar cualquier tipo de excepci\u00f3n utilizando simplemente \"except\":</p> <pre><code>try:\n    # C\u00f3digo que puede lanzar una excepci\u00f3n\n    resultado = 10 / 0\nexcept ZeroDivisionError:\n    # C\u00f3digo a ejecutar si se produce una excepci\u00f3n del tipo ZeroDivisionError\n    print(\"No se puede dividir por cero.\")\nexcept ValueError:\n    # C\u00f3digo a ejecutar si se produce una excepci\u00f3n del tipo ValueError\n    print(\"Valor incorrecto.\")\nexcept:\n    # C\u00f3digo a ejecutar si se produce cualquier tipo de excepci\u00f3n\n    print(\"Se produjo una excepci\u00f3n.\")\n</code></pre> </li> <li> <p>Bloques ELSE y FINALLY: </p> </li> <li>Se puede usar un bloque else despu\u00e9s de los \"except\" para ejecutar c\u00f3digo si no se produce ninguna excepci\u00f3n.  </li> <li>Y tambi\u00e9n existe la opcion del bloque finally, que se utiliza para ejecutar c\u00f3digo independientemente de si se produce una excepci\u00f3n o no. Por ello es muy com\u00fan usarlo para liberar recursos o realizar alguna limpieza.</li> </ul> <pre><code>try:\n    # C\u00f3digo que puede lanzar una excepci\u00f3n\n    resultado = 10 / 2\nexcept ZeroDivisionError:\n    # C\u00f3digo a ejecutar si se produce una excepci\u00f3n del tipo ZeroDivisionError\n    print(\"No se puede dividir por cero.\")\nelse:\n    # C\u00f3digo a ejecutar si no se produce ninguna excepci\u00f3n\n    print(\"La divisi\u00f3n fue exitosa. El resultado es:\", resultado)\nfinally:\n    # C\u00f3digo a ejecutar siempre, independientemente de si se produce una excepci\u00f3n o no\n    print(\"Esta l\u00ednea se ejecutar\u00e1 siempre.\")\n</code></pre>"},{"location":"PYTHON/ud1/#funciones-y-modulos","title":"FUNCIONES Y M\u00d3DULOS","text":""},{"location":"PYTHON/ud1/#funciones","title":"Funciones","text":"<ul> <li>Definici\u00f3n de funciones: Una definici\u00f3n de funci\u00f3n, define una secuencia ejecutable determinada por el usuario. La definici\u00f3n de la funci\u00f3n no ejecuta el cuerpo de la funci\u00f3n, este solo se ejecuta cuando se llama a la funci\u00f3n.</li> </ul> <pre><code>def saludar(nombre):\n    return f\"Hola, {nombre}\"\n</code></pre> <ul> <li>Llamadas a funciones: para llamar a una funci\u00f3n en Python, se usa el nombre de la funci\u00f3n seguido de par\u00e9ntesis, que puede contener valores (argumentos) separados por comas. Al hacer una llamada, la ejecuci\u00f3n del programa salta al cuerpo de la funci\u00f3n, para luego regresar al punto donde fue llamada.</li> </ul> <pre><code>print(saludar(\"Luc\u00eda\"))\n</code></pre> <ul> <li>Retorno de valores: la cl\u00e1usula retunr, se usa para finalizar la ejecuci\u00f3n de una funci\u00f3n y enviar un valor de vuelta a la parte del programa que la llam\u00f3, permitiendo que ese resultado sea almacenado en una variable o utilizado inmediatamente.</li> </ul> <pre><code>def sumar(a, b):\n  suma = a + b\n  return suma   # Devuelve la suma de a y b\n\ntotal = sumar(5, 3)  # total ahora ser\u00e1 8\n</code></pre>"},{"location":"PYTHON/ud1/#modulos","title":"M\u00f3dulos","text":"<ul> <li> <p>Importar un m\u00f3dulo est\u00e1ndar: Un m\u00f3dulo es un archivo .py que contiene c\u00f3digo python (funciones, variables, clases...) que podeos usar en otros programas. Los m\u00f3dulos nos permiten dividir el c\u00f3digo en m\u00faltiples ficheros, de forma que quede mejor organizado y sea m\u00e1s facil de reutilizar. Python incluye una extensa biblioteca est\u00e1ndar con m\u00f3dulos ya hechos, pero tamb\u00eden cualquier usuario puede crear m\u00f3dulos propios.  </p> <pre><code>import math     #importamos el m\u00f3dulo math completo\nprint(math.sqrt(16))\n</code></pre> </li> <li> <p>Importar funciones espec\u00edficas de un m\u00f3dulo: En caso de no querer importar m\u00f3dulos completos en nuestro programa, podemos usar la cl\u00e1usula from, para indicar que solo queremos importar algunas funciones concretas de dicho m\u00f3dulo:</p> <pre><code>from math import sqrt #solo importa la funci\u00f3n sqrt\nprint(sqrt(25))\n</code></pre> </li> <li> <p>Crear m\u00f3dulos propios: Para crear un m\u00f3dulo en Python, simplemente creamos un archivo con extensi\u00f3n .py y escribimos nuestro c\u00f3digo en \u00e9l. Por ejemplo, podemos crear un m\u00f3dulo llamado \"operaciones.py\" con algunas funciones matem\u00e1ticas:</p> </li> </ul> <pre><code># operaciones.py\n\ndef suma(a, b):\n    return a + b\n\ndef resta(a, b):\n    return a - b\n\ndef multiplicacion(a, b):\n    return a * b\n\ndef division(a, b):\n    if b != 0:\n        return a / b\n    else:\n        return \"Error: Divisi\u00f3n por cero\"\n</code></pre> <p>Luego solo tendremos que importarlo desde nuestro archivo principal. Por ejemplo, supongamos que tenemos un archivo \"main.py\" que importa y utiliza las funciones del m\u00f3dulo operaciones.:</p> <pre><code># main.py\n\nimport operaciones\n\nresultado_suma = operaciones.suma(5, 3)\nprint(\"Resultado de la suma:\", resultado_suma)\n</code></pre> <p>Tambi\u00e9n podemos utilizar alias al importar m\u00f3dulos o funciones. Esto nos permite utilizar un nombre m\u00e1s corto o conveniente en nuestro c\u00f3digo:</p> <pre><code># main.py\n\nimport operaciones as ops\n\nresultado_suma = ops.suma(5, 3)\nprint(\"Resultado de la suma:\", resultado_suma)\n\nfrom operaciones import resta as restar\n\nresultado_resta = restar(10, 4)\nprint(\"Resultado de la resta:\", resultado_resta)\n</code></pre>"},{"location":"PYTHON/ud2/","title":"MANEJO DE DATOS CON PANDAS","text":""},{"location":"PYTHON/ud2/#introduccion","title":"INTRODUCCI\u00d3N","text":"<p>Pandas es la librer\u00eda est\u00e1ndar para manipulaci\u00f3n de datos en Python. Permite leer, limpiar, transformar y exportar datos f\u00e1cilmente, y ser\u00e1 muy \u00fatil para preparar la informaci\u00f3n que serviremos desde nuestras APIs.</p> <p>ESTRUCTURAS PRINCIPALES:</p> <ul> <li>Series \u2192 estructura 1D (como una lista con etiquetas).</li> <li>DataFrame \u2192 estructura 2D (tabla con filas y columnas).</li> </ul> <p>INSTALACI\u00d3N</p> <p>Si usas Google Colab, Jupyter Notebook o Anaconda, pandas ya est\u00e1 instalado. Si trabajas desde VS Code, la terminal o un entorno virtual, inst\u00e1lalo con:</p> <pre><code>pip install pandas\n</code></pre>"},{"location":"PYTHON/ud2/#ides-interactivos-para-trabajar-con-datos","title":"IDEs INTERACTIVOS PARA TRABAJAR CON DATOS","text":"<p>A la hora de manejar datos, es importante poder visualizar en tiempo real y de manera sencilla la salida o resultados de los comandos que ejecutamos. Para ello existen entornos de desarrollo interactivos, que nos van a facilitar mucho esta tarea.</p>"},{"location":"PYTHON/ud2/#jupyter-notebook","title":"JUPYTER NOTEBOOK","text":""},{"location":"PYTHON/ud2/#google-colab","title":"GOOGLE COLAB","text":""},{"location":"PYTHON/ud2/#otras-alternativas","title":"OTRAS ALTERNATIVAS","text":"<p>Fuente: J.Enrique Ati\u00e9nzar</p>"},{"location":"PYTHON/ud3/","title":"CREACI\u00d3N DE APIs REST EN PYTHON","text":""},{"location":"PYTHON/ud3/#que-es-una-api","title":"\u00bfQU\u00c9 ES UNA API?","text":"<p>Una API (Interfaz de Programaci\u00f3n de Aplicaciones) es un conjunto de reglas y protocolos que permiten el intercambio de datos entre dos sistemas inform\u00e1ticos, de una manera segura y estandarizada.</p> <p>Es decir, act\u00faa como un intermediario que define la forma en que una aplicaci\u00f3n puede solicitar, recibir y enviar informaci\u00f3n a otra.</p> <p>Su principal utilidad es simplificar el desarrollo de aplicaciones, ya que permiten reutilizar c\u00f3digo e integrar servicios existentes con facilidad, sin necesidad de crear todo desde cero.</p> <p></p>"},{"location":"PYTHON/ud3/#caracteristicas-de-una-api-rest","title":"CARACTER\u00cdSTICAS DE UNA API REST","text":"<p>Una API REST (Representational State Transfer) sigue un conjunto de principios arquitect\u00f3nicos que permiten comunicar sistemas usando peticiones HTTP est\u00e1ndar como GET, POST, PUT, DELETE.</p>"},{"location":"PYTHON/ud3/#cliente-servidor","title":"CLIENTE-SERVIDOR","text":""},{"location":"PYTHON/ud3/#sin-estados","title":"SIN ESTADOS","text":""},{"location":"PYTHON/ud3/#acceso-url","title":"ACCESO URL","text":"<p>En REST, todo recurso de la aplicaci\u00f3n debe estar representado por una URL \u00fanica, mediante la que podremos acceder a \u00e9l.</p> <p>Es decir, para comunicarnos con una API usaremos un navegador web, donde introduciendo diferentes URL, podremos acceder a los distintos recursos que nos proporciona. El formato correcto y las partes que debemos diferenciar en cualquier URL son:</p> <ul> <li>Protocolo: el protocolo de comunicaciones web por excelencia es <code>http://</code> o <code>https://</code>.</li> <li>Dominio: nombre del host en el que est\u00e1 alojada la API. Por ejemplo, <code>www.eltiempo.es</code>.</li> <li>Endpoint: ubicaci\u00f3n l\u00f3gica espec\u00edfica a la que se env\u00eda la solicitud. Por ejemplo, <code>/Toledo</code>.</li> <li> <p>Par\u00e1metros: etiquetas con valores que podemos usar para consultar datos concretos dentro de un endpoint. Por ejemplo, <code>?hora=15:00</code>. Si hay varios parametros, deben ir separados por el s\u00edmbolo <code>&amp;</code>.</p> <p>https://www.eltiempo.es/Toledo?hora=15:00</p> </li> </ul> <p>Adem\u00e1s, HTTP proporciona diferentes m\u00e9todos, que nos permiten especificar la acci\u00f3n queremos realizar sobre un recurso:</p> <ul> <li>GET: para obtener datos.</li> <li>POST: para crear datos.</li> <li>PUT: para actualizar datos.</li> <li>DELETE: para eliminar datos.</li> </ul>"},{"location":"PYTHON/ud3/#formato-json","title":"FORMATO JSON","text":""},{"location":"PYTHON/ud3/#principales-frameworks-python-para-apis","title":"PRINCIPALES FRAMEWORKS PYTHON PARA APIs","text":"<p>Al crear aplicaciones web en Python, hay tres opciones de frameworks que destacan sobre el resto: Django, Flask y FastAPI. Cada uno aporta fortalezas, limitaciones y contextos de uso distintos, como vemos en la siguiente tabla:</p> Frameworks Python CARACTER\u00cdSTICAS DJANGO FLASK FASTAPI Definici\u00f3n Framework web de alto nivel y full stack, que viene con todas las funciones y componentes necesarios para un uso completo desde el principio. Microframework ligero y minimalista, de f\u00e1cil aprendizaje y que apuesta por la flexibilidad. Framework moderno y de alto rendimiento pensado para construir APIs con validaci\u00f3n, y generaci\u00f3n de documentaci\u00f3n autom\u00e1tica. Uso Recomendado Aplicaciones web grandes con base de datos, panel de administraci\u00f3n y varias funcionalidades listas para usar, como un e-commerce, CMS o ERP. APIs peque\u00f1as o medianas, prototipos y proyectos de aprendizaje donde se busque libertad tecnol\u00f3gica. REST APIs y microservicios, aplicaciones en tiempo real como chat o IoT y despliegue de modelos de machine learning e IA cuando el rendimiento es cr\u00edtico. Desventajas Es m\u00e1s pesado y menos flexible al imponer convenciones y no tan r\u00e1pido cuando se trata de APIs de alto rendimiento. Al ser tan ligero, suele ser necesario instalar librer\u00edas externas para integrar ciertas funcionalidades, lo que en proyectos grandes puede ser algo tedioso. Al ser m\u00e1s joven que los dos anteriores, puede que su comunidad no sea tan extensa y no est\u00e1 orientado a aplicaciones monol\u00edticas. <p>Fuente: Q2B Studio</p>"},{"location":"PYTHON/ud3/#fastapi","title":"FastAPI","text":""},{"location":"PYTHON/ud3/#requerimientos-minimos","title":"REQUERIMIENTOS M\u00cdNIMOS","text":"<p>\u00bfQUE ES UVICORN?</p> <p>Uvicorn es una librer\u00eda de Python que act\u00faa como servidor web as\u00edncorno (ASGI) de alto rendimiento y se utiliza para ejecutar aplicaciones web y APIs, como las creadas con FastAPI. En caso de que instalemos fastapi y uvicorn por separado, este se usa desde la l\u00ednea de comandos para levantar un servidor local en nustra m\u00e1quina y poder probar el funcionamiento de la API.</p> <p>Por ejemplo, si tu archivo se llama \"main.py\" y tu API se llama \"app\", ejecutar\u00edamos: <code>uvicorn main:app --reload</code>.</p> <p>FastAPI solo puede usarse con Python 3.6 o superior.</p> <p>Para utilizarlo, com\u00fanmente se sol\u00edan instalar dos librer\u00edas: <code>fastapi</code> y <code>uvicorn</code>. Pero m\u00e1s recientemente se lanz\u00f3 el paquete <code>fastapi[standard]</code>, que incluye FastAPI, Uvicorn y otras dependencias recomendadas.</p> <p>Por lo tanto, para usarlo, \u00fanicamente debemos instalar:</p> <pre><code>pip install fastapi[standard]\n</code></pre> <p>Adem\u00e1s, si instalamos esta librer\u00eda que incluye todo, podemos probar nuestra API ejecutando lo siguiente desde un terminal:</p> <pre><code>fastapi run main.py --reload\n</code></pre>"},{"location":"PYTHON/ud3/#mi-primera-api-con-fastapi","title":"MI PRIMERA API CON FASTAPI","text":"<pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef bienvenida():\n    return {\"Hola desde FastAPI!\"}\n</code></pre> <p>Fuente: Ander Fernandez</p>"},{"location":"PYTHON/ud3/#validacion-de-datos-con-pydantic","title":"VALIDACI\u00d3N DE DATOS CON PYDANTIC","text":"<p>Cuando trabajamos con APIs, los datos que llegan desde clientes externos no son fiables. Pueden venir incompletos, con tipos incorrectos o con valores que no cumplen las reglas del negocio de la API.</p> <p>Para resolver este problema de forma autom\u00e1tica, FastAPI utiliza Pydantic. Pydantic es una librer\u00eda Python que permite definir modelos de estructura de datos en clases y adem\u00e1s se encarga de verificar los tipos de datos, realizar conversiones autom\u00e1ticas y generar errores detallados si la validaci\u00f3n falla. Si entramos m\u00e1s en detalle:</p> <ol> <li> <p>Validaci\u00f3n autom\u00e1tica de datos: verifica los tipos de datos (str, int, float, bool, list, dict, etc.), campos obligatorios, valores por defecto, estructuras complejas (listas, objetos anidados), restricciones (m\u00ednimos, m\u00e1ximos, longitudes\u2026). Y si algo no se cumplo devuelve un error 422 con los detalles.</p> </li> <li> <p>Conversi\u00f3n de tipos (\u201cparsing\u201d): convierte autom\u00e1ticamente los valores al tipo esperado, haciendo que la l\u00f3gica interna siempre reciba tipos correctos. Por ejemplo:</p> <pre><code>\"10\" \u2192 int(10)\n\"true\" \u2192 bool(True)\n\"2024-05-10\" \u2192 datetime.date\n\"12.5\" \u2192 float(12.5)\n</code></pre> </li> <li> <p>Modelado de estructuras complejas: Cuando los datos contienen objetos dentro de objetos, listas, relaciones\u2026 se necesita una estructura clara y tipada. FastAPI entiende este modelo, valida la anidaci\u00f3n y genera documentaci\u00f3n autom\u00e1tica. Por ejemplo:</p> <pre><code>from pydantic import BaseModel\n\nclass Direccion(BaseModel):\ncalle: str\nciudad: str\n\nclass Usuario(BaseModel):\nnombre: str\nedad: int\ndireccion: Direccion\n</code></pre> </li> <li> <p>Documentaci\u00f3n autom\u00e1tica: a trav\u00e9s de los modelos Pydantic, FastAPI genera autom\u00e1ticamente documentaci\u00f3n interactiva, esquemas OpenAPI y ejemplos de entrada/salida. De modo que cualquier cliente entienda exactamente como utilizar la API. Adem\u00e1s mediante las siguientes funcionalidades podemos probar la API sin escribir c\u00f3digo adicional:</p> <ul> <li>Swagger UI \u2192 <code>/docs</code></li> <li>ReDoc \u2192 <code>/redoc</code></li> </ul> </li> <li> <p>Consistencia de entrada y salida: los modelos pueden usarse tanto para recibir datos (request) como para devolverlos (response). Evitando inconsistencias en nuestra API:</p> <ul> <li>Entrada \u2192 valida lo que env\u00eda el cliente</li> <li>Salida \u2192 define claramente qu\u00e9 devuelve tu API</li> </ul> </li> </ol> <p>Fuente: J.Enrique Ati\u00e9nzar</p>"},{"location":"PYTHON/ud4/","title":"APLICACIONES WEB CON PYTHON","text":""},{"location":"PYTHON/ud4/#flask","title":"FLASK","text":"<p>Flask es un microframework de Python ligero y flexible dise\u00f1ado para crear aplicaciones web y APIs RESTful de forma r\u00e1pida y sencilla. Basado en herramientas como Jinja2 y Werkzeug, permite iniciar un servidor web con pocas l\u00edneas de c\u00f3digo sin imponer una estructura r\u00edgida. Ideal para desarrolladores que buscan libertad y minimalismo.</p> Logo Flask"},{"location":"PYTHON/ud4/#dependencias","title":"DEPENDENCIAS","text":"<p>A medida que evolucione nuestr aplicaci\u00f3n, seguramente necesitemos a\u00f1adir otras librer\u00edas, pero para comenzar a trabajar, bastar\u00e1 con instalar <code>flask</code>:</p> <pre><code>pip install flask\n</code></pre>"},{"location":"PYTHON/ud4/#estructura-basica-api","title":"ESTRUCTURA B\u00c1SICA API","text":"<pre><code>#Importaci\u00f3n de m\u00f3dulos\nfrom flask import Flask\n\n#Creaci\u00f3n de una instancia de la clase Flask\napp = Flask(__name__)\n\n#Definici\u00f3n de los endpoints usando decoradores\n@app.route('/', methods=['GET'])\n#Definici\u00f3n de la funci\u00f3n que ejecuta dicho endpoint\ndef raiz():\n    return \"Hola desde Flask\"\n\n#Definici\u00f3n del bloque IfName, para controlar la ejecuci\u00f3n del m\u00f3dulo principal.\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"PYTHON/ud4/#ejecucion-del-servidor-de-pruebas","title":"EJECUCI\u00d3N DEL SERVIDOR DE PRUEBAS","text":"<p>Flask por defecto, levanta un servidor local sobre el puerto 5000, para que podamos testear nuestro c\u00f3digo. Si nuestro m\u00f3dulo se llama <code>app.py</code>, podemos ejecutarlo con:</p> <pre><code>flask run \n</code></pre> <p>Pero si queremos realizar pruebas con diferentes m\u00f3dulos que tengan otros nombres, lo ejecutaremos con:</p> <pre><code>flask --app mimodulo.py --debug run \n</code></pre>"},{"location":"PYTHON/ud4/#tipos-de-rutas-para-los-endpoint","title":"TIPOS DE RUTAS PARA LOS ENDPOINT","text":""},{"location":"PYTHON/ud4/#ruta-estatica","title":"RUTA EST\u00c1TICA","text":"<p>Se especifica una ruta fija para el endpoint:</p> <pre><code>@app.route('/blog', methods=['GET'])\ndef blog():\n    return \"Bienvenido a la seci\u00f3n BLOG\"\n</code></pre>"},{"location":"PYTHON/ud4/#ruta-variable","title":"RUTA VARIABLE","text":"<p>El endpoint contiene un par\u00e1metro variable y dependiendo de su valor, se mostrar\u00e1 un contenido u otro:</p> <pre><code>@app.route('/blog/&lt;id_articulo&gt;', methods=['GET'])\ndef articulo(id_articulo):\n    return f\"Estas viendo el \u00e1rticulo n\u00ba {id_articulo} del BLOG\"\n</code></pre>"},{"location":"PYTHON/ud4/#tipos-de-metodos-para-los-endpoint","title":"TIPOS DE M\u00c9TODOS PARA LOS ENDPOINT","text":"M\u00e9todo Acci\u00f3n Descripci\u00f3n <code>GET</code> Read  Obtiene informaci\u00f3n del servidor. <code>PUT</code> Write  Crea un recurso nuevo. <code>POST</code> Update  Reemplaza un recurso completo. <code>PATCH</code> Update  Modifica parte de un recurso. <code>DELETE</code> Remove  Borra un recurso completo."},{"location":"PYTHON/ud4/#tipos-de-return-para-los-endpoints","title":"TIPOS DE RETURN PARA LOS ENDPOINTS","text":""},{"location":"PYTHON/ud4/#texto-plano","title":"TEXTO PLANO","text":"<p>Es la opci\u00f3n m\u00e1s simple y generalmente solo la usamos para probar el funcionamiento inicial de nuestra app:</p> <pre><code>@app.route('/', methods=['GET'])\ndef raiz():\n    return \"Bienvenido a mi app web\"\n</code></pre>"},{"location":"PYTHON/ud4/#fichero-json","title":"FICHERO JSON","text":"<p>Flask incluye la funcionalidad <code>jsonify</code>, que convierte automaticamente diccionarios, listas u otros objetos Python en una respuesta JSON v\u00e1lida, estableciendo el Content-Type a \"application/json\". Es muy \u00fatil cuando queremos crear una API:</p> <pre><code>from flask import jsonify\n\nestudiantes = [\n    {\"id\": 1, \"nombre\": \"Ana\", \"edad\": 20},\n    {\"id\": 2, \"nombre\": \"Luis\", \"edad\": 22},\n    {\"id\": 3, \"nombre\": \"Mar\u00eda\", \"edad\": 21}]\n\n@app.route('/students', methods=['GET'])\ndef get_students():\n    return jsonify(estudiantes)\n</code></pre>"},{"location":"PYTHON/ud4/#documento-html","title":"DOCUMENTO HTML","text":"<p>Flask tambien nos permite devolver directamente el contenido de un documento HTML, usando la funci\u00f3n <code>render_template</code>, que carga y procesa este tipo de archivos utilizando el motor <code>Jinja2</code>. Para ello, es estrictamente necesario que estos ficheros HTML se encuentren en la carpeta <code>templates</code> (que deberemos crear en nuestro proyecto):</p> <pre><code>from flask import render_template\n\n@app.route('/', methods=['GET'])\ndef raiz():\n    return render_template(\"base.html\")\n</code></pre>"},{"location":"PYTHON/ud4/#uso-de-plantillas-con-jinja2","title":"USO DE PLANTILLAS CON JINJA2","text":"Logo Jinja2 <p>Flask incluye un motor de plantillas llamado Jinja2, que permite, no solo renderizar documentos HTML, si no que tambi\u00e9n podemos pasarles variables y aplicar sobre ellas estructuras de programaci\u00f3n como condicionales y bucles.</p>"},{"location":"PYTHON/ud4/#delimitadores-en-jinja2","title":"DELIMITADORES EN JINJA2","text":"<ul> <li> <p><code>{% %}</code>: Declaraci\u00f3n de sentencias de control de flujo (condicionales, bucles...) y operaciones con plantillas.</p> </li> <li> <p><code>{{ }}</code>: Evaluar y mostrar valores devueltos por las sentencias anteriores. </p> </li> </ul>"},{"location":"PYTHON/ud4/#uso-de-variables-en-jinja2","title":"USO DE VARIABLES EN JINJA2","text":"<p>Cuando renderizamos un archivo HTML con Jinja2, podemos pasarle variables y dependiendo de sus valores mostrar unas cosas u otras. Por ejemplo, en el endpoint podemos devoler lo siguiente:</p> <pre><code>@app.route('/blog', methods=['GET'])\ndef blog():\n    return render_template(\"blog.html\", autor=\"ProfeDIW\", logeado=False)\n</code></pre>"},{"location":"PYTHON/ud4/#uso-condicionales-en-jinja2","title":"USO CONDICIONALES EN JINJA2","text":"<p>Siguiente con el ejemplo anterior, dentro del c\u00f3digo de \"blog.html\", podemos utilizar las variables que hemos pasado, ya sea para mostrar su valor o usarlas en condicionales:</p> <pre><code>&lt;h2&gt;Bienvenido al blog&lt;/h2&gt;\n&lt;p&gt;Mi nombre es {{ autor }}, y soy el creador de este sitio.&lt;/p&gt;\n{% if logeado %}\n&lt;p&gt;Has iniciado sesi\u00f3n correctamente.&lt;/p&gt;\n{% else %}\n&lt;p&gt;Necesitas iniciar sesi\u00f3n para ver este contenido.&lt;/p&gt;\n{% endif %}\n</code></pre>"},{"location":"PYTHON/ud4/#uso-de-bucles-en-jinja2","title":"USO DE BUCLES EN JINJA2","text":"<p>Del mismo modo, tambi\u00e9n podemos utilizar bucles <code>for</code> dentro de un HTML, mediante los delimitadores Jinja2. Por ejemplo, imaginemos que tenemos una lista de alumnos llamada \"estudiantes\" y queremos imprimir una tarjeta por cada persona en la lista. No ser\u00e1 necesario escribir el c\u00f3digo muchas veces, simplemente podr\u00edamos aplicar algo como lo siguiente:</p> <pre><code>{% for alumno in estudiantes %}\n &lt;div class=\"card\"&gt;\n  &lt;div class=\"card-content\"&gt;\n    &lt;h2&gt; {{alumno.nombre}} &lt;/h2&gt;\n    &lt;h3&gt; Curso: {{alumno.curso}} &lt;/h3&gt;\n    &lt;h3&gt; Edad: {{alumno.edad} }&lt;/h3&gt;\n  &lt;/div&gt;\n &lt;/div&gt;\n{% endfor %}\n</code></pre>"},{"location":"PYTHON/ud4/#herencia-de-plantillas-en-jinja2","title":"HERENCIA DE PLANTILLAS EN JINJA2","text":"<p>Otra gran ventaja de las plantillas es evitar la repetici\u00f3n de c\u00f3digo HTML, mediante el uso de la herencia.</p> <p>Esto nos permite usar un documento \"base.html\", en el que incluiremos todo el c\u00f3digo que sea com\u00fan a todas las p\u00e1ginas de nuestra aplicaci\u00f3n web.</p> <p>De este modo, en cada p\u00e1gina espec\u00edfica solo tendremos que aplicar la sentencia <code>extends</code> y a\u00f1adir el contenido a mostrar mediante un bloque de contenido, <code>block</code>. Por ejemplo, la plantilla <code>base.html</code>, podr\u00eda tener el siguiente aspecto:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"es\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;P\u00e1gina Base&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    {%block contenidos%}\n    {%end block%}    \n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Y por otro lado, en las diferentes p\u00e1ginas tendr\u00edamos algo parecido a esto:</p> <pre><code>{% extends \"base.html\" %}\n\n{% block contenidos %}\n&lt;h2&gt;Contenido exclusivo de esta p\u00e1gina&lt;/h2&gt;\n{% endblock %}\n</code></pre> <p>Podemos utilizar estilos predefinidos como los de Bootswatch en nuestros templates, para darle un dise\u00f1o m\u00e1s profesional y de forma r\u00e1pida a nuestra app web.</p>"},{"location":"PYTHON/ud4/#formularios-wtf","title":"FORMULARIOS WTF","text":"Logo WTForms <p>Existe tambi\u00e9n una extensi\u00f3n para Flask llamada <code>Flask-WTF</code>, la cual integra la biblioteca WTForms, que nos permite definir formularios web como clases Python, facilitando mucho la creaci\u00f3n, renderizado y validaci\u00f3n segura de estos.</p>"},{"location":"PYTHON/ud4/#dependencias-wtforms","title":"DEPENDENCIAS WTFORMS","text":"<p>Necesitaremos instalar la siguiente extensi\u00f3n:</p> <pre><code>pip install flask-wtf\n</code></pre>"},{"location":"PYTHON/ud4/#uso-de-wtforms","title":"USO DE WTFORMS","text":"<p>Ante cualquier duda o error, podemos consultar su documentaci\u00f3n oficial, sin embargo, a continuaci\u00f3n algunos pasos b\u00e1sicos que nos van a ayudar a familiarizarnos con su uso:</p>"},{"location":"PYTHON/ud4/#importar-modulos","title":"IMPORTAR M\u00d3DULOS","text":"<p>Necesitaremos importar los siguientes componentes:</p> <pre><code>from flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\n</code></pre>"},{"location":"PYTHON/ud4/#crear-clave-secreta","title":"CREAR CLAVE SECRETA","text":"<p>Lo primero que debemos hacer es crear una clave secreta <code>SECRET_KEY</code>, que Flask-WTF utilizar\u00e1 para firmar criptogr\u00e1ficamente los tokens CSRF (Cross-Site Request Forgery) y las cookies de sesi\u00f3n. Garantizando as\u00ed la seguridad de los formularios y previniendo ataques de terceros o peticiones maliciosas.</p> <p>Esta clave consistir\u00e1 en una cadena de caracteres aleatorios, que se recomienda que sea larga y compleja para mayor seguridad. Por ejemplo:</p> <pre><code>app.config['SECRET_KEY']=\"a262hs7sjd893jd74ejd83hwnsgh2y262h\"\n</code></pre>"},{"location":"PYTHON/ud4/#definir-nuestra-clase-formulario","title":"DEFINIR NUESTRA CLASE FORMULARIO","text":"<p>Podemos crear un m\u00f3dulo <code>formularios.py</code>, donde definir todos nuestros formularios como clases de Python. Por ejemplo, si queremos a\u00f1adir un formulario de registro, podr\u00eda ser algo as\u00ed:</p> <pre><code>from flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\n\nclass SignUpForm(FlaskForm):\n    usuario = StringField('Username')\n    contrase\u00f1a = PasswordField('Password')\n    confirmar = SubmitField('Sign up')\n</code></pre>"},{"location":"PYTHON/ud4/#usar-nuestro-formulario-en-el-html-y-el-endpoint","title":"USAR NUESTRO FORMULARIO EN EL HTML Y EL ENDPOINT","text":"<p>A la hora de definir el endpoint, podemos hacerlo as\u00ed:</p> <pre><code>from formularios import SignUpForm\n\n@app.route('/signup', methods=['GET', 'POST'])\n def signup():\n    formulario = SignUpForm()\n    return render_template(\"blog.html\", form=formulario)\n</code></pre> <p>Luego en el HTML:</p> <pre><code>{% extends \"base.html\" %}\n\n{% block content %}\n\n&lt;h2&gt; Sign Up &lt;/h2&gt;\n&lt;form action=\"\" method=\"POST\"&gt;\n    &lt;p&gt;\n        {{ form.usuario.label }} &lt;br&gt;\n        {{ form.usuario(size=30) }}\n    &lt;/p&gt;\n    &lt;p&gt;\n        {{ form.contrase\u00f1a.label }} &lt;br&gt;\n        {{ form.contrase\u00f1a(size=30) }}\n    &lt;/p&gt;\n    &lt;p&gt;{{ form.confirmar() }}&lt;/p&gt;\n&lt;/form&gt;\n\n{% endblock %}\n</code></pre>"},{"location":"PYTHON/ud4/#recuperar-datos-de-un-formulario","title":"RECUPERAR DATOS DE UN FORMULARIO","text":"<p> Pr\u00f3ximamente...\ud83d\udea7\ud83d\udc77\u200d\u2642\ufe0f\ud83d\udea7</p>"},{"location":"PYTHON/ud4/#enlaces-html-a-los-diferentes-endpoints","title":"ENLACES HTML A LOS DIFERENTES ENDPOINTS","text":"<p>Una vez tengamos definida nuestra estructura de plantillas Flask (templates), cuando queramos movernos entre ellas usando enlaces dentro del c\u00f3digo HTML <code>(&lt;a href=\"\"&gt;)</code>, no lo haremos indicando el nombre del documento html, que es lo que solemos hacer cuando estamos programando un sitio web normal.</p> <p>En este caso, como estamos usando Flask y su motor de plantillas Jinja2, debemos enlazarlo con el comando <code>url_for()</code> e indicar dentro el nombre de la funci\u00f3n a la que queremos llamar (sin parentesis), es decir, la funci\u00f3n que ejecuta alguno de nuestros endpoints. Por ejemplo:</p> <pre><code>&lt;a class=\"nav-link\" href=\"{{ url_for('blog') }}\"&gt;Abrir Blog&lt;/a&gt;\n</code></pre>"},{"location":"PYTHON/ud4/#persistencia-en-mongodb","title":"PERSISTENCIA EN MONGODB","text":"Logo MongoDB"},{"location":"PYTHON/ud4/#introduccion-a-mongodb","title":"INTRODUCCI\u00d3N A MONGODB","text":"<p>MongoDB es una base de datos NoSQL de c\u00f3digo abierto, orientada a documentos y de alto rendimiento, dise\u00f1ada para la flexibilidad y escalabilidad en el desarrollo moderno.</p> <p>En lugar de tablas y filas, utiliza documentos tipo JSON (con almacenamiento BSON binario) agrupados en colecciones, lo que permite manejar datos estructurados, semiestructurados y no estructurados con esquemas din\u00e1micos.</p>"},{"location":"PYTHON/ud4/#dependencias-mongo","title":"DEPENDENCIAS MONGO","text":"<p>Insalaremos la siguiente librer\u00eda para poder interactuar con nuestra BBDD Mongo:</p> <pre><code>pip install pymongo\n</code></pre>"},{"location":"PYTHON/ud4/#levantar-mongodb-en-un-contenedor","title":"LEVANTAR MONGODB EN UN CONTENEDOR","text":"<p>Podr\u00edamos hacerlo mediante el comando \"docker run\", pero queremos poder gestionar nuestra BBDD tambi\u00e9n a trav\u00e9s de una interfaz gr\u00e1fica. Es por ello que levantaremos 2 servicios interconectados, mongoDB y mongoXpress, usando la utilidad <code>docker compose</code>. A continuaci\u00f3n se adjunta una sugerencia de configuraci\u00f3n para el fichero .YAML:</p> docker-compose.yml <pre><code>    services:\n        mongo:\n            image: mongo\n            container_name: mongoDB\n            restart: always\n            environment:\n                MONGO_INITDB_ROOT_USERNAME: root\n                MONGO_INITDB_ROOT_PASSWORD: pass123\n            volumes:\n                - mongoData:/data/db\n        mongo-express:\n            image: mongo-express\n            container_name: mongoGUI\n            restart: always\n            ports:\n                - 8081:8081\n            environment:\n                ME_CONFIG_MONGODB_URL: mongodb://root:pass123@mongo:27017/\n                ME_CONFIG_BASICAUTH_ENABLED: true\n                ME_CONFIG_BASICAUTH_USERNAME: mongoexpressuser\n                ME_CONFIG_BASICAUTH_PASSWORD: mongoexpresspass\n    volumes:\n        mongoData:\n</code></pre> <p>Para levantar los servicios definidos en el fichero anterior, abrimos un terminal y nos ubicamos en la carpeta donde se encuentre, luego lanzamos el comando:</p> <pre><code>docker compose up -d\n</code></pre>"},{"location":"PYTHON/ud4/#vincular-mi-api-con-mongo","title":"VINCULAR MI API CON MONGO","text":""},{"location":"PYTHON/ud4/#importamos-la-libreria","title":"IMPORTAMOS LA LIBRERIA","text":"<pre><code>from pymongo import MongoClient\n</code></pre>"},{"location":"PYTHON/ud4/#cadena-de-conexion-a-mongo","title":"CADENA DE CONEXI\u00d3N A MONGO","text":"<p>Para conectarnos el sistema de Mongo desde otras aplicaciones o herramientas, se utiliza un par\u00e1metro llamado <code>MONGO_URI</code>, el cual podemos definir en una variable de entorno. Su estructura es la siguiente:</p> <pre><code># El Nombre de la BBDD es opcional:\nmongodb://[usuario]:[contrase\u00f1a]@[hostname]:[puerto]/[nombreBBDD]\n</code></pre> <p>En nuestro c\u00f3digo Python, realizamos la conexi\u00f3n mediante el m\u00e9todo <code>MongoClient</code> y la podemos asignar a una variable, para usarla de manera sencilla cuando queramos realizar operaciones en Mongo:</p> <pre><code>cliente = MongoClient(\"mongodb://root:pass123@mongo:27017\")\n</code></pre>"},{"location":"PYTHON/ud4/#ejemplos-utiles-de-operaciones-en-mongo-desde-python","title":"EJEMPLOS \u00daTILES DE OPERACIONES EN MONGO DESDE PYTHON","text":""},{"location":"PYTHON/ud4/#crear-una-bbdd-nueva","title":"CREAR UNA BBDD NUEVA","text":"<pre><code># Creamos una BBDD llamada COLEGIO y dentro de ella, una tabla llamada ALUMNOS\nnew_db = cliente['colegio']\ntabla_alumnos = new_db['alumnos']\n</code></pre>"},{"location":"PYTHON/ud4/#listar-todos-los-registros-de-una-tabla","title":"LISTAR TODOS LOS REGISTROS DE UNA tabla","text":"<pre><code>alumnado = list(tabla_alumnos.find({}, {'_id': 0}))\n</code></pre>"},{"location":"PYTHON/ud4/#devolver-un-alumno-por-su-id","title":"DEVOLVER UN ALUMNO POR SU ID","text":"<pre><code>alumno = tabla_alumnos.find_one({\"id_alumno\":myid}, {\"_id\":0})\n</code></pre>"},{"location":"PYTHON/ud4/#borrar-un-alumno-por-su-id","title":"BORRAR UN ALUMNO POR SU ID","text":"<pre><code>borrado = tabla_alumnos.delete_one({\"id_alumno\": int(myid)})\n</code></pre>"},{"location":"PYTHON/ud4/#dockerizar-nuestra-aplicacion-web","title":"DOCKERIZAR NUESTRA APLICACI\u00d3N WEB","text":"<p> En construcci\u00f3n...\ud83d\udea7\ud83d\udc77\u200d\u2642\ufe0f\ud83d\udea7</p>"},{"location":"PYTHON/ud4/#django","title":"DJANGO","text":"Logo de Django"},{"location":"PYTHON/ud4/#introduccion-a-django","title":"INTRODUCCI\u00d3N A DJANGO","text":"<p>Como ya hab\u00edamos mencionado, Django es un framework de c\u00f3digo abierto basado en Python, que nos permite crear sitios web complejos de forma r\u00e1pida y sencilla.</p> <p>Ya que nos permite simplificar las tareas repetiticas y pesadas que pueden darse a la hora de desarrollar este tipo de aplicaciones.</p>"},{"location":"PYTHON/ud4/#modelo-vista-controlador-mvc","title":"MODELO VISTA CONTROLADOR (MVC)","text":"<p>Este modelo se basa en dividir una aplicaci\u00f3n en 3 grandes m\u00f3dulos:</p> <ul> <li> <p>MODELO: se encarga de gestionar la informaci\u00f3n almacenada en una Base de Datos.</p> </li> <li> <p>VISTA: define todo lo referente a la interfaz grafica de usuario (GUI), es decir, que es lo que el usuario ve (Frontend); tanto a la hora de hacer una petici\u00f3n, como a la hora de visualizar la informaci\u00f3n solicitada.</p> </li> <li> <p>CONTROLADOR: encargado de gestionar las comunicaciones entre la VISTA y el MODELO.</p> </li> </ul> Modelo Vista Controlador <p>Este modelo hace que nuestras aplicaciones sean m\u00e1s funcionales y faciles de mantener y escalar. Es por ello que la muchos de los principales frameworks de desarrollo de aplicaciones se basan en \u00e9l.</p> <p>Aunque Django no usa exactamente este modelo, su filosofia es exactamente la misma. Se podr\u00eda decir que es un MVC personalizado, llamado Model Template View (MTV), donde el <code>Template = Vista</code> y el <code>View = Controlador</code>.</p>"},{"location":"PYTHON/ud4/#primeros-pasos-con-django","title":"PRIMEROS PASOS CON DJANGO","text":"<p>En primer lugar, creamos una nueva carpeta para nuestros proyectos Django y la abrimos en Visual Studio Code. Luego creamos nuestro entorno virtual, lo activamos e instalamos Django en \u00e9l:</p> <pre><code>python -m venv envDjango\n\n.\\envDjango\\Scripts\\activate\n\npip install django\n\npython -m django --version\n</code></pre> <p>Para crear nuestro primer proyecto, podemos hacerlo con el siguiente comando:</p> <pre><code>django-admin startproject Proyecto1\n</code></pre> <p>Pr\u00e1cticamente todo proyecto de Django (se presupone que si usamos este framework es porque estamos desarrollando una aplicaci\u00f3n medianamente compleja) estar\u00e1 compuesto por una o varias apps. Las apps, no son m\u00e1s que bloques de c\u00f3digo separados que podremos reutilizar dentro de otros proyectos.</p> <p>Para crear nuestra primera app, accedemos a la carpeta que se ha creado con el nombre de nuestro proyecto y ejecutamos lo siguiente:</p> <pre><code>cd Proyecto1\npython manage.py startapp InicioSesion\n</code></pre>"},{"location":"PYTHON/ud4/#bbdd-en-django-en-construccion-","title":"BBDD EN DJANGO  -- En construcci\u00f3n... \ud83d\udea7 --","text":"<pre><code># En el \"models.py\" creamos tantas clases como tablas vaya a tener nuestra BBDD, para esta App.\n# En el \"settings.py\" a\u00f1adimos nuestra App en la lista de \"INSTALED APPS\"\n\n# Para comprobar si hay algun problema en nuestro c\u00f3digo:\npython manage.py check InicioSesion\n\n# Para crear la BBDD vac\u00eda (esto nos devuelve un n\u00ba de migraci\u00f3n, por ejemplo 0001)\npython manage.py makemigrations\n\n# Para generar las tablas definidas en el \"models.py\" (debemos indicar el n\u00ba de miraci\u00f3n anterior):\npython manage.py sqlmigrate InicioSesion 0001\n\n# Para incorportar esas tablas a nuestra BBDD:\npython manage.py migrate\n</code></pre>"},{"location":"PYTHON/ud5/","title":"REDES NEURONALES EN PYTHON","text":"Logo Tensorflow Logo PyTorch"},{"location":"WEB/indexw/","title":"DISE\u00d1O DE INTERFACES WEB","text":"<p>\u00cdNDICE DE CONTENIDOS:</p> <ol> <li>Libros y Herramientas \u00datiles</li> <li>Principios del Dise\u00f1o</li> <li>Maquetaci\u00f3n web con CSS</li> <li>Preprocesadores CSS</li> <li>Implantaci\u00f3n de contenidos Multimedia</li> <li>Frameworks CSS</li> </ol> <p>MATERIALES FORMACI\u00d3N PROFESIONAL INFORM\u00c1TICA by Lorenzo Le\u00f3n Valor is licensed under CC BY-NC-SA 4.0</p>"},{"location":"WEB/ud0/","title":"LIBROS Y HERRAMIENTAS \u00daTILES PARA EL DESARROLLO DEL M\u00d3DULO","text":""},{"location":"WEB/ud0/#libros-de-referencia","title":"LIBROS DE REFERENCIA","text":""},{"location":"WEB/ud0/#herramientas-web-utiles","title":"HERRAMIENTAS WEB \u00daTILES","text":""},{"location":"WEB/ud0/#caninclude","title":"CANINCLUDE","text":"<p>\u00bfQue hace?</p> <p>. Sirve para validar si puedes anidar una etiqueta HTML dentro de otra. .</p> <p></p>"},{"location":"WEB/ud0/#caniuse","title":"CANIUSE","text":"<p>\u00bfQue hace?</p> <p>Sirve para consultar la compatibilidad de tecnolog\u00edas web con diferentes navegadores y sus versiones.</p> <p></p>"},{"location":"WEB/ud1/","title":"PLANIFICACI\u00d3N DE INTERFACES GR\u00c1FICAS","text":""},{"location":"WEB/ud1/#1-interaccion-hombre-maquina","title":"1. INTERACCI\u00d3N HOMBRE-M\u00c1QUINA","text":""},{"location":"WEB/ud1/#que-es-una-interfaz-de-usuario","title":"\u00bfQu\u00e9 es una Interfaz de Usuario?","text":"<ul> <li>Denominamos UI (User Interface), a la parte de una aplicaci\u00f3n, dispositivo o servicio con la que interact\u00faa un usuario. La UI abarca desde todos los elementos gr\u00e1ficos y visuales, como botones, men\u00fas, im\u00e1genes, disposici\u00f3n de la pantalla... hasta accesorios y dispositivos f\u00edsicos que permitan la comunicaci\u00f3n entre el usuario y el sistema, como pantallas, ratones, teclados, mandos o paneles de control.</li> <li>Seg\u00fan la forma en la que interactua el usuario, diferenciamos 3 grandes tipos de interfaces:</li> <li>CLI: Interfaz de l\u00ednea de comandos </li> <li>Es la m\u00e1s antigua pero que a d\u00eda de hoy se sigue utilizando. Se basa en comandos de texto ingresados por el usuario para ejecutar tareas y gestionar programas o archivos. Ejemplo de esta UI es el sistema operativo MS-DOS, as\u00ed como tambi\u00e9n, el Shell de comandos que forma parte del sistema operativo Windows.</li> <li>GUI: Interfaz gr\u00e1fica de usuario </li> <li>Se trata del tipo de interfaz m\u00e1s usado en la actualidad para ordenadores o dispositivos m\u00f3viles. Este entorno se fundamenta en im\u00e1genes y elementos gr\u00e1ficos que presentan tanto la informaci\u00f3n, como las acciones que se encuentran disponibles para interactuar entre el usuario y el dispositivo. Una p\u00e1gina web o la mayor\u00eda de aplicaciones de escritorio actuales, se basan en ella.</li> <li>NUI: Interfaz de usuario natural </li> <li> <p>Es un tipo de interfaz busca crear una conexi\u00f3n lo m\u00e1s natural posible con el usuario. Para ello se fundamenta en la interacci\u00f3n intuitiva mediante gestos corporales, toques o movimientos f\u00edsicos, as\u00ed como en el reconocimiento de \u00f3rdenes por voz.  Ejemplos de esta interfaz son los dispositivos de realidad virtual (VR), o sistemas que usan sensores de movimiento como el antiguo Kinect de Xbox.</p> </li> <li> <p>Nosotros desde la perspectiva del Dise\u00f1o Web, vamos a centrarnos principalmente en las GUI y en como utilizar de forma eficiente los elementos de dise\u00f1o, para crear interfaces intuitivas, agradables e interactivas.</p> </li> </ul>"},{"location":"WEB/ud1/#que-es-la-experiencia-de-usuario","title":"\u00bfQu\u00e9 es la Experiencia de Usuario?","text":"<ul> <li>La experiencia de usuario o UX (User Xperience) es la manera en que el usuario percibe, siente o interact\u00faa con un sistema o servicio. Se trata de las sensaciones del usuario mientras esta haciendo uso de una web, una app o cualquier otro servicio.</li> <li> <p>UX es un grupo de disciplinas: interacci\u00f3n, arquitectura de la informaci\u00f3n, animaci\u00f3n en dise\u00f1o, estilo de comunicaci\u00f3n. Pero tambi\u00e9n es un proceso din\u00e1mico que debe involucrar una serie de fases para garantizar la calidad de un producto.</p> </li> <li> <p>Los principales m\u00e9todos para mejorar la UX son:</p> </li> <li>Anal\u00edtica Web</li> <li>Card Sorting</li> <li>Diagramas de interacci\u00f3n</li> <li>Dise\u00f1o modular</li> <li>Encuestas y entrevistas</li> <li>Evaluaci\u00f3n eur\u00edstica</li> <li>Personajes y escenarios.</li> <li>Pruebas A/B</li> <li>Pruebas con usuarios</li> <li>ROI</li> <li> <p>Wireframes</p> </li> <li> <p>Conceptos fundamentales de UX:</p> </li> <li>Usabilidad: es un atributo de calidad de un producto que se refiere sencillamente a su facilidad de uso.</li> <li>Accesibilidad: que se refiere a la posibilidad de que pueda ser usado sin problemas por el mayor n\u00famero de personas posibles, independientemente de las limitaciones propias del individuo o de las derivadas del contexto de uso.     </li> <li>Arquitectura de informaci\u00f3n: se refiere a la pr\u00e1ctica de definir, organizar y presentar los elementos y contenidos de un entorno digital, de forma que resulte los m\u00e1s intuitivo y facil posible para el usuario.     </li> </ul>"},{"location":"WEB/ud1/#ui-vs-ux","title":"UI vs UX","text":""},{"location":"WEB/ud1/#diseno-centrado-en-el-usuario","title":"Dise\u00f1o centrado en el usuario","text":"<ul> <li> <p>Tambien conocido como UCD (User-Centered Design) hace referencia a una filosof\u00eda de dise\u00f1o en la que el proceso est\u00e1 conducido por informaci\u00f3n acerca de la audiencia objetiva del producto. Su principal diferencia frente a otros enfoques es que su proceso no es secuencial o lineal, sino que presenta ciclos en los que iterativamente se prueba el dise\u00f1o y se optimiza hasta alcanzar el nivel de calidad esperado. </p> </li> <li> <p>Metodolog\u00eda Agile: es una de las m\u00e9todolog\u00edas de desarrollo de proyectos centrada en el usuario m\u00e1s populares, sobre todo en el mundo del desarrollo software. Su manifiesto se basa en 12 principios fundamentales. </p> </li> </ul>"},{"location":"WEB/ud1/#2-elementos-basicos-del-diseno-grafico","title":"2. ELEMENTOS B\u00c1SICOS DEL DISE\u00d1O GR\u00c1FICO","text":"<ul> <li>La l\u00ednea</li> <li>La forma</li> <li>El espacio</li> <li>La escala</li> <li>El color</li> <li>La textura</li> <li>La tipograf\u00eda</li> </ul>"},{"location":"WEB/ud1/#3-principios-del-diseno","title":"3. PRINCIPIOS DEL DISE\u00d1O","text":"<ul> <li>A continuaci\u00f3n veremos los principios m\u00e1s relevantes en el dise\u00f1o para la experiencia de usuario, incluyendo descripci\u00f3n y ejemplos de cada uno:</li> <li>Clasificaci\u00f3n</li> <li>Color</li> <li>Eficiencia</li> <li>Error humano</li> <li>Est\u00e9tica</li> <li>Fotograf\u00edas</li> <li>Iconos</li> <li>Inteligencia colectiva</li> <li>Jerarqu\u00eda visual</li> <li>Legibilidad e inteligibilidad</li> <li>Ley de Fitts</li> <li>Mapeo Natural</li> <li>Ordenaci\u00f3n</li> <li>Relevancia</li> <li>Taxonom\u00edas</li> <li>Toma de decisions</li> <li>Visibilidad y retroalimentaci\u00f3n</li> </ul> <p>Fuente: Experiencia de usuario: Principios y m\u00e9todos, Yusef Hassan Montero </p>"},{"location":"WEB/ud1/#4-sistemas-de-diseno","title":"4. SISTEMAS DE DISE\u00d1O","text":""},{"location":"WEB/ud1/#que-son","title":"\u00bfQu\u00e9 son?","text":""},{"location":"WEB/ud1/#elementos","title":"Elementos","text":""},{"location":"WEB/ud1/#herramientas-softare","title":"Herramientas Softare","text":""},{"location":"WEB/ud2/","title":"MAQUETACI\u00d3N CSS","text":""},{"location":"WEB/ud2/#selectores-css","title":"SELECTORES CSS","text":""},{"location":"WEB/ud2/#maquetacion-tradicional","title":"MAQUETACI\u00d3N TRADICIONAL","text":""},{"location":"WEB/ud2/#maquetacion-con-flex","title":"MAQUETACI\u00d3N CON FLEX","text":""},{"location":"WEB/ud2/#maquetacion-con-grid","title":"MAQUETACI\u00d3N CON GRID","text":""},{"location":"WEB/ud2/#maquetacion-responsiva","title":"MAQUETACI\u00d3N RESPONSIVA","text":""},{"location":"WEB/ud3/","title":"PREPROCESADORES CSS","text":"Logo Sass"},{"location":"WEB/ud3/#introduccion-a-sass","title":"INTRODUCCI\u00d3N A SASS","text":""},{"location":"WEB/ud3/#entorno-de-trabajo","title":"ENTORNO DE TRABAJO","text":"<p> VSCODE: Plugins Sass y Scss Intellisense.</p> <p> NODE.JS: Para usar su gestor de paquetes NPM.</p> <p> SASS: Para compilar nuestros ficheros SCSS a CSS.</p>"},{"location":"WEB/ud3/#que-es-sass","title":"\u00bfQUE ES SASS?","text":"<p>Recomendaciones de uso y sentido com\u00fan: Enlace</p> <p>P\u00e1gina de documentaci\u00f3n oficial SASS: Enlace</p>"},{"location":"WEB/ud3/#instalacion-sass","title":"INSTALACI\u00d3N SASS","text":"<p>Previa instalaci\u00f3n de Node.js, usamos su gestor de paquetes para ejecutar:</p> <pre><code>npm install -g sass\nsass --version\n</code></pre>"},{"location":"WEB/ud3/#elementos-basicos-de-sass","title":"ELEMENTOS B\u00c1SICOS DE SASS","text":""},{"location":"WEB/ud3/#variables","title":"Variables","text":"<p>Podemos definir variables donde almacenar valores, que usaremos posteriormente. Por ejemplo:</p> <pre><code>$color-fondo:white;\n$color-texto: grey;\n</code></pre> <p>Tipos de datos b\u00e1sicos para una variable (Valores):</p> <ul> <li>N\u00fameros: 48 48px 0.5em</li> <li>Cadenas: \u2018left\u2019 \u201cleft\u201d left</li> <li>Colores: rg(255, 0, 0) hsl(0, 100%, 50%), #f00 #ff0000</li> <li>Booleanos: (true y false)</li> <li>null</li> <li>Mapas y Listas</li> </ul> <p>Las variables pueden ser globales (fuera de cualquier bloque) o locales (definidas dentro de un bloque, por ejemplo dentro de un elemento \"section\").</p>"},{"location":"WEB/ud3/#comentarios","title":"Comentarios","text":"<ul> <li>Unil\u00ednea: //Esto es una sola l\u00ednea</li> <li>Multil\u00ednea: /Esto es multilinea/</li> </ul>"},{"location":"WEB/ud3/#listas-y-mapas","title":"Listas y mapas","text":"<p>Las listas son colecciones de valores separados por comas. Similares a un array de una dimensi\u00f3n:</p> <pre><code>$lista-banderas: (espana, francia, italia, alemania);\n</code></pre> <p>Mientras que los mapas son colecciones de valores del tipo \"clave:valor\", separados por comas:</p> <pre><code>$mapa-paises: (\n    espana: \"espana.png\",\n    francia: \"francia.png\",\n    italia: \"italia.png\",\n    alemania: \"alemania.png\"\n    );\n</code></pre>"},{"location":"WEB/ud3/#interpolacion","title":"Interpolaci\u00f3n","text":""},{"location":"WEB/ud3/#anidamiento","title":"Anidamiento","text":""},{"location":"WEB/ud3/#compilacion-sass-a-css","title":"COMPILACI\u00d3N SASS A CSS","text":"<p>Para compilar nuestro archivo .SCSS en un archivo .CSS, el cual podamos enlazar desde una p\u00e1gina HTML; usaremos el siguiente comando:</p> <pre><code>sass input.scss output.css\n</code></pre> <p>Ese comando admite diversas opciones de personalizaci\u00f3n, una de las m\u00e1s comunes que usaremos, sirve para que la herramienta se quede a la espera de cambios y autocompile nuestro SCSS cada vez que lo guardemos:</p> <pre><code>sass --watch input.scss output.css\n</code></pre>"},{"location":"WEB/ud3/#estructuras-de-control-en-sass","title":"ESTRUCTURAS DE CONTROL EN SASS","text":""},{"location":"WEB/ud3/#condicional-if-else","title":"Condicional <code>@if / @else</code>","text":"<pre><code>nav{\n    @if $light-theme == true{\n        background-color: $navbar-background-color-light;\n    } @else if $dark-theme{\n        background-color: $navbar-background-color-dark;\n    } @else{\n        background-color: $navbar-background-color;\n    }\n}\n</code></pre>"},{"location":"WEB/ud3/#bucle-while","title":"Bucle <code>@while</code>","text":"<pre><code>@while $num &lt; 6{\n    figure:nth-child(#{$num}){\n        background-color: nth($color-list, $num);\n    }\n    $num: $num + 1;\n}\n</code></pre>"},{"location":"WEB/ud3/#bucle-for","title":"Bucle <code>@for</code>","text":"<pre><code>@for $i from 1 to 5{\n    li:nth-of-type(#{$i}){\n        color: nth($color-list2, $i);\n    }\n}\n</code></pre>"},{"location":"WEB/ud3/#bucle-each","title":"Bucle <code>@each</code>","text":"<pre><code>@each $c, $v in $mapa{\n    div.#{$c}{\n        background-image: url(\"img/#{$v}\");\n        background-repeat: no-repeat;\n        background-size: contain;\n    }\n}\n</code></pre>"},{"location":"WEB/ud3/#funciones-en-sass","title":"FUNCIONES EN SASS","text":"<p>Nativas:</p> <p>Creadas por el usuario:</p> <pre><code>@function anchura_col($cols, $total){\n    @return percentage($cols/$total);\n}\n</code></pre>"},{"location":"WEB/ud3/#reglas-y-directivas-sass","title":"REGLAS Y DIRECTIVAS SASS","text":""},{"location":"WEB/ud3/#import","title":"@import","text":"<p>Permite construir una \u00fanica hoja de estilos que sea la combinaci\u00f3n de distintos archivos CSS o SCSS, denominados \"partials\".</p> <p>Los figheros partials, deber\u00e1n nombrarse comenzando por gui\u00f3n bajo, por ejemplo, \"_colores.scss\" o \"_botones.scss\"</p> <p>A la hora de compilarlos en un \u00fanico CSS, no es necesario indicar ese gui\u00f3 bajo, por ejemplo:</p> <pre><code>@import \"colores.scss\";\n@import \"botones.scss\";\n</code></pre>"},{"location":"WEB/ud3/#extend","title":"@extend","text":"<p>Nos permite construir los estilos de un elemento, usando como base los estilos de otro. Por ejemplo:</p> <pre><code>.btn {\nborder-radius: 2px;\ncolor: #FFF;\npadding: 5px 0;\nmargin: 2px auto;\ntext-align: left;\nwidth: 150px;\n}\n\n.btn-error {\n    @extend .btn;  \n    background-color: #F00;  \n}\n\n.btn-ok {\n    @extend .btn;\n    background-color: #0F0;\n}\n</code></pre> <p>Puede ser que queramos que el selector usado para el @extend, no aparezca en el CSS resultante de la compilaci\u00f3n. Para ello podemos usar un selector placeholder, a\u00f1adiendo el car\u00e1cter % delante del nombre del selector. Es decir, en el ejemplo anterior, sustituirimos \".btn\" por \"%btn\".</p>"},{"location":"WEB/ud3/#error-warn-debug","title":"@error / @warn / @debug","text":"<p>Son directivas \u00fatiles cuando estamos depurando nuestro SCSS. Nos permiten mostrar mensajes y valores de variables, funciones etc..durante el proceso de generaci\u00f3n del CSS.</p> <pre><code>$test: false;\nbody {\n    @if $test {\n        @error \"Mensaje de error\";\n        @debug \"Test tiene el siguiente valor: #{$test}\";\n    }\n    else {\n        @warn \"Mensaje de warning\";\n        @debug \"Test tiene el siguiente valor: #{$test}\";\n    }\n}\n</code></pre>"},{"location":"WEB/ud3/#at-root","title":"@at-root","text":"<p>La directiva @at-root permite que selectores dentro de reglas con anidamiento sean movidos a la ra\u00edz del documento. Su uso no es algo com\u00fan y se puede llegar a usar con anidamientos avanzados que usan funciones de selecci\u00f3n y selectores referentes a elementos padre.</p> <p>Por ejemplo, si tenemos el siguiente c\u00f3digo SCSS:</p> <pre><code>.item {\n    color: black;    \n    @at-root #{&amp;}is-active {\n    color: blue;\n    }\n}\n</code></pre> <p>Generar\u00e1 el siguiente CSS:</p> <pre><code>.item {\ncolor: black;\n}\n.item.is-active {\ncolor: blue;\n}\n</code></pre>"},{"location":"WEB/ud3/#media-support-keyframes","title":"@media / @support / @keyframes","text":"<p>Sass tambi\u00e9n soporta las directivas <code>@media</code>, <code>@support</code> y <code>@keyframes</code> que son directivas propias de CSS y su uso es igual.</p>"},{"location":"WEB/ud3/#mixins-sass","title":"MIXINS SASS","text":"<p>Nos permite definir estilos que luego voy a poder reutilizar a lo largo de mi hoja de estilos. Por ejemplo:</p> <pre><code>@mixin centrado {\n    margin: 0px auto;\n}\n\nheader {\n    @include centrado;\n    background-color: black;\n    color: white;\n}\n</code></pre> <p>Como vemos, para usar un mixim debemos usar la directiva @include.</p>"},{"location":"WEB/ud3/#principales-usos","title":"Principales usos","text":"<p>Los mixins, se usan generalmente en Media Queries, Prefijos relativos a los navegadores, Transformaciones CSS, Animaciones CSS, Colocaci\u00f3n fija de elementos o Gradientes.</p> <p>En el repositorio SCSS-MIXINS-COLLECTION se puede ver una colecci\u00f3n de mixins, agrupados por tem\u00e1tica.</p> <p>Por ejemplo, podemos crear mixins que incluyan selectores completos de tal manera que se pueda usar en cualquier parte de mi SCSS:</p> <pre><code>@mixin highlighted-link {\n    a {\n        background-color: yellow;\n        font-style: italic;\n        text-decoration: none;\n    }\n}\n\n@include highlighted-link;\n</code></pre> <p>Tambien puedo usar mixins dentro de otro mixin.</p> <pre><code>@mixin centrado_menu {\n    @include centrado;\n\n    background-color: #666;\n    color: white;\n    height: 3rem;\n}\n\n.main_menu {\n    @include centrado_menu();\n}\n</code></pre>"},{"location":"WEB/ud3/#parametros","title":"Par\u00e1metros","text":"<p>Tambi\u00e9n tenemos la posibilidad de que nuestros mixins reciban una serie de par\u00e1metros, que ser\u00e1n obligatorios u opcionales. En caso de ser opcionales tenemos que asignarles un valor por defecto en la definici\u00f3n del par\u00e1metro.</p> <p>Un ejemplo de parametros obligatorios:</p> <pre><code>@mixin girar($grados) {\n-webkit-transfrom: rotate(#{gradosdeg}deg);\n-ms-transform: rotate(#{gradosdeg}deg);\ntransform: rotate(#{gradosdeg}deg);\n}\n</code></pre> <p>Otro ejemplo que incluye par\u00e1metros opcionales:</p> <pre><code>@mixin logo($image, $radio: 10px) {\nbackground-image: url(\"#{$image}\");\nbackground-position: center;\nborder-radius: $radio;\n}\n</code></pre> <p>A la hora de usarlos, podemos especificar o no un valor para los paremetros opcionales:</p> <pre><code>.logo-cuadrado {\n@include logo(\"img/milogocuadrado.png\", 0px);\n}\n</code></pre>"},{"location":"WEB/ud3/#documentacion-en-sass","title":"DOCUMENTACI\u00d3N EN SASS","text":""},{"location":"WEB/ud3/#que-es-sassdoc","title":"\u00bfQu\u00e9 es SassDoc?","text":"<p>Sistema de documentaci\u00f3n que permite generar de manera autom\u00e1tica, documentaci\u00f3n de tipo profesional en HTML a partir de los comentarios de nuestros ficheros Sass.</p>"},{"location":"WEB/ud3/#instalacion","title":"Instalaci\u00f3n","text":"<p>Para instalarlos, debemos partir de un entorno en el que ya contemos con Nodejs, Npm y Npx (de no tener alguno de ellos, deberemos instalarlo); podemos comprobarlo con:</p> <pre><code>node --version\nnpm --version\nnpx --version\n</code></pre> <p>Una vez comprobado esto, podemos instalar SassDoc con el siguiente comando:</p> <pre><code>npm install sassdoc -g\nsassdoc --version\n</code></pre>"},{"location":"WEB/ud3/#uso-basico","title":"Uso b\u00e1sico","text":"<p>Para una documentaci\u00f3n aceptable, como m\u00ednimo, debemos comentar las variables, las funciones y los mixins.</p> <p>Dentro de los comentarios SassDoc, existen una serie de palabras reservadas o anotaciones, que nos permitir\u00e1n darle m\u00e1s sentido y mejor compresi\u00f3n a la documentaci\u00f3n generada.</p> <p>Podemos ver el detalle de cada una de ellas en la Documentaci\u00f3n Oficial, pero la lista completa ser\u00eda:</p> <pre><code>@access     @ignore     @return\n@alias      @link       @see\n@author     @name       @since\n@content    @output     @content\n@deprecated @parameter  @throw\n@example    @property   @todo\n@group      @require    @type\n</code></pre> <p>Los comentarios SassDoc, comenzar\u00e1n por triple barra y se colocar\u00e1n encima de los elementos a comentar:</p> <pre><code>/// Color de fondo de la web\n///@group colores\n$background-color-principal: #white;\n</code></pre> <p>Tambi\u00e9n podemos especificar al comienzo del archivo comentarios con cuadruple barra, los cuales se incluir\u00e1n en todas las secciones de comentarios que definamos en ese fichero:</p> <pre><code>//// @access public \n//// @author IES Azarquiel\n</code></pre> <p>Otro ejemplo m\u00e1s completo, podr\u00eda ser el siguiente:</p> <pre><code>/// @group colores\n/// @parameter {color} $color - Valor del color que quiero aclarar\n/// @parameter {floar} $transparencia - Valor de la transparencia a aplicar de -1 a 1.\n/// @return {color}\n/// @example scss - Funcion Aclarar\n/// bacground-color: aclarar(#00AA00, -0.2)\n@function aclarar($color, $transparencia){\n    @return adjust-color($color, $alpha: $transparencia);\n}\n</code></pre> <p>Una vez tengamos todos los comentarios que queramos a\u00f1adir, ejecutamos el comando:</p> <pre><code>sassdoc scss/\n</code></pre> <p>Esto crear\u00e1 una carpeta sassdoc dentro del directorio \"scss\", con toda la documentaci\u00f3n generada y cuyo punto de entrada es el fichero <code>index.html</code>.</p>"},{"location":"WEB/ud4/","title":"IMPLANTACI\u00d3N DE CONTENIDOS MULTIMEDIA","text":""},{"location":"WEB/ud4/#tipos-de-imagenes-digitales","title":"TIPOS DE IM\u00c1GENES DIGITALES","text":"<p>Existen 2 grandes tipos de im\u00e1genes digitales: mapa de bits, tambi\u00e9n llamadas rasterizadas; y vectoriales.  Cada una de ellas tiene caracter\u00edsticas y aplicaciones diferentes, como veremos en la siguiente tabla.</p> Vector VS Bitmap MAPA DE BITS VECTORIAL Composici\u00f3n Compuestas por peque\u00f1os cuadrados, llamados p\u00edxeles (unidad m\u00ednima de representaci\u00f3n de un \u00fanico color en una pantalla digital); los cuales se disponen en una matriz (filas y columnas) donde cada uno ocupa una posici\u00f3n \u00fanica para dar forma a la imagen final. Compuestas por l\u00edneas llamadas vectores, definidos por funciones matem\u00e1ticas para dar lugar a diferentes elementos geom\u00e9tricos (rectas, arcos, pol\u00edgonos...); los cuales en conjunto daran lugar a la imagen final. Zoom Pierden calidad al hacer zoom, ya que el es limitado. No pierden calidad al hacer zoom, ya que al estar definidas por f\u00f3rmulas mem\u00e1ticas, el trazado seguir\u00e1 siendo el mismo por mucho que ampliemos. Espacio El tama\u00f1o en bytes del archivo es proporcional al tama\u00f1o de la imagen. El tama\u00f1o en bytes del archivo es independiente del tama\u00f1o de la imagen y en general van a ocupar menos que un mapa de bits. Usos Im\u00e1genes realistas o con mucho detalle (fotografias), imagenes animadas (gif). Dibujos, ilustraciones, logos, iconos, tipograf\u00edas, diagramas, infograf\u00edas, planos, videojuegos..."},{"location":"WEB/ud4/#formatos-mas-comunes","title":"FORM\u00c1TOS M\u00c1S COMUNES","text":"<p>Dentro de estos dos grandes tipos de im\u00e1genes digitales, existen multitud de formatos de almacenamientoque podemos generar, los m\u00e1s utilizados son:</p> Formatos de im\u00e1genes por tipo"},{"location":"WEB/ud4/#creacion-de-graficos-svg-con-inkscape","title":"CREACI\u00d3N DE GR\u00c1FICOS SVG CON INKSCAPE","text":"<p>Inkscape es un editor de gr\u00e1ficos vectoriales gratuito y de c\u00f3digo abierto, similar a Adobe Illustrator, que permite crear y editar logotipos, diagramas, ilustraciones y c\u00f3mics usando el est\u00e1ndar SVG.</p> <p>Por motivos de tiempo, dentro del m\u00f3dulo de Dise\u00f1o de Interfaces Web, no vamos a profundizar en como usarlo para crear gr\u00e1ficos vectoriales desde cero. Pero si que nos puede resultar muy valioso para convertir una im\u00e1gen de Mapa de Bits (JPG o PNG, por ejemplo) a una imagen vectorial. Y es lo que vamos a ver a continuaci\u00f3n.</p> <p>En primer lugar, descargamos la herramienta de la p\u00e1gina oficial, en nuestro caso el instalador para Windows. Lo instalamos en nuestro equipo y una vez accedamos a la aplicaci\u00f3n, haremos lo siguiente:</p> <ol> <li>En la ventana de Bienvenida de la aplicaci\u00f3n, seleccionamos la pesta\u00f1a \"Hora de dibujar\" y luego la opci\u00f3n \"ABRIR\", para abrir una imagen existente en formato mapa de bits.</li> <li>Seleccionamos nuestra imagen y en las caracter\u00edsticas de importaci\u00f3n que nos consulta, indicamos \"Incrustar\", \"Desde Archivo\" y \"Ninguno\"; luego pulsamos \"OK\".</li> <li>Hacemos click derecho sobre la imagen abierta y elegimos \"Vectorizar Mapa de bits\".</li> <li>Dentro del submen\u00fa que se muestra, seleccionamos la pesta\u00f1a \"Multicolor\", luego elegimos el modo de detecci\u00f3n \"Colores\".</li> <li>Personalizamos los siguientes par\u00e1metros: PASADAS = N\u00ba colores diferentes de nuestra imagen, MOTAS = 25 y OPTIMIZAR = 0.250; y pulsamos \"Aplicar\".</li> </ol> <p>Con esto nos crear\u00e1 una nueva imagen en SVG, compuesta por tantas capas como pasadas hayamos indicado y ya podremos editarla como gr\u00e1fico vectorial o simplemente guardarla para usar en nuestra web.</p>"},{"location":"WEB/ud4/#creacion-y-uso-de-un-fichero-de-sprites-svg","title":"CREACI\u00d3N Y USO DE UN FICHERO DE SPRITES SVG","text":"<p>Las hojas de sprites son una t\u00e9cnica de optimizaci\u00f3n utilizada principalemente en los videojuegos 2D, pero que tambi\u00e9n se aplica en el dise\u00f1o Web.</p> <p>Esta consiste en combinar m\u00faltiples im\u00e1genes peque\u00f1as (como iconos, botones, logos...) en un \u00fanico archivo de imagen grande para reducir el n\u00famero de peticiones HTTP al servidor, reduciendo as\u00ed el tiempo de carga y mejorando el rendimiento de la p\u00e1gina.</p> <p>Nosotros vamos a crear nuestro propio fichero de sprites SVG, pero en lugar de editar un archivo de imagen, editaremos el c\u00f3digo XML que las define. Es decir, vamos a crear un \u00fanico archivo en formato SVG, el cual englobar\u00e1 todos los logos, iconos, tipograf\u00edas, ilustraciones o cualquier otro tipo de gr\u00e1fico vectorial que vayamos a usar en nuestra p\u00e1gina web.</p> <p>Llamaremos a nuestro fichero sprites.svg y su formato estructura general ser\u00e1 similar a la siguiente:</p> sprites.svg <pre><code>    &lt;svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" style=\"display:none\"&gt;\n      &lt;symbol id=\"icono1\" viewBox=\"0 0 W1 H1\"&gt;\n        &lt;g&gt;\n         &lt;path /&gt;\n         &lt;path /&gt;\n        &lt;/g&gt;\n      &lt;/symbol&gt;\n      &lt;symbol id=\"icono2\" viewBox=\"0 0 W2 H2\"&gt;\n        &lt;g&gt;\n          &lt;path /&gt;\n          &lt;path /&gt;\n        &lt;/g&gt;\n      &lt;/symbol&gt;\n      &lt;symbol id=\"icono3\" viewBox=\"0 0 W3 H3\"&gt;\n        &lt;g&gt;\n          &lt;path /&gt;\n          &lt;path /&gt;\n        &lt;/g&gt;\n      &lt;/symbol&gt;\n    &lt;/svg&gt;\n</code></pre> <p>Como vemos consistir\u00e1 en agrupar dentro de una etiqueta <code>&lt;svg&gt;</code> tantas etiquetas <code>&lt;symbol&gt;</code>como im\u00e1genes vectoriales vayamos a utilizar en nuestra p\u00e1gina. Cada s\u00edmbolo tendr\u00e1 un id que para identificarlo y un viewBox (que estar\u00e1 definido en el c\u00f3digo de cada una de nuestras im\u00e1genes SVG), que especificar\u00e1 las coordenadas iniciales, el ancho y alto del area de visi\u00f3n; para nuestra imagen.</p>"},{"location":"WEB/ud4/#anadir-imagenes-al-fichero-mediante-su-codigo-xml","title":"A\u00d1ADIR IM\u00c1GENES AL FICHERO, MEDIANTE SU C\u00d3DIGO XML","text":"<p>Dentro de cada una de esas etiquetas symbol, pegaremos el c\u00f3digo de nuestras im\u00e1genes SVG. Para obtener dichoo c\u00f3digo, solo tendremos que pulsar boton derecho sobre el archivo de imagen y seleccionar \"Abrir con Bloc de Notas\". Veremos algo parecido a esto:</p> <p>google-maps.svg</p> <pre><code>    &lt;svg xmlns=\"http://www.w3.org/2000/svg\"  viewBox=\"0 0 48 48\" width=\"100px\" height=\"100px\"&gt;\n        &lt;path fill=\"#48b564\" d=\"M35.76,26.36h0.01c0,0-3.77,5.53-6.94,18.5C38,21.4,37.17,24.09,35.76,26.36z\"/&gt;\n        &lt;path fill=\"#fcc60e\" d=\"M28.24,22L17.89,2.46,5.5,5.5,5.5C25.71,24,27.24,23.22,28.24,22z\"/&gt;\n        &lt;path fill=\"#2c85eb\" d=\"M28.4,4.74l-8.57,4,24,4C25.54,4,27.02,4.26,28.4,4.74z\"/&gt;\n        &lt;path fill=\"#ed5748\" d=\"M19.83,14.92L19.76,15l-8.32, L19.83,14.92z\"/&gt;\n        &lt;path fill=\"#5695f6\" d=\"M28.24,22c0.79-0.46-5.5-5.5-5.5c-1.71,0-3.24,0.78-4.24,8.17,7.38L28.24,22z\"/&gt;\n    &lt;/svg&gt;\n</code></pre> <p>Como vemos, aparecen los valores del viewBox y los diferentes <code>&lt;path&gt;</code> o capas de las que consta la imagen. Para a\u00f1adir esta imagen a nuestro fichero de sprites, simplemente copiaremos su definici\u00f3n de capas en nuestro c\u00f3digo, omitiendo las etiquetas <code>&lt;svg&gt;</code>. Por ejemplo, para a\u00f1adir el icono de Google Maps que vemos m\u00e1s arriba, nos debe quedar algo as\u00ed:</p> <pre><code>    &lt;svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" style=\"display:none\"&gt;\n    &lt;symbol id=\"google-maps\" viewBox=\"0 0 48 48\"&gt;\n        &lt;g&gt;\n            &lt;path fill=\"#48b564\" d=\"M35.76,36h0.01c0,0-3.77,5.53-6.94,18.5C38,21.4,37.17,24.09,35.76,26.36z\"/&gt;\n            &lt;path fill=\"#fcc60e\" d=\"M28.24,22L17.89,2.46,5.5,5.5,5.5C25.71,24,27.24,23.22,28.24,22z\"/&gt;\n            &lt;path fill=\"#2c85eb\" d=\"M28.4,4.74l-8.57,4,24,4C25.54,4,27.02,4.26,28.4,4.74z\"/&gt;\n            &lt;path fill=\"#ed5748\" d=\"M19.83,14.92L19.76,15l-8.32, L19.83,14.92z\"/&gt;\n            &lt;path fill=\"#5695f6\" d=\"M28.24,-0.46-5.5-5.5-5.5c-1.71,0-3.24,0.78-4.24,8.17,7.38L28.24,22z\"/&gt;\n        &lt;/g&gt;\n    &lt;/symbol&gt;\n    &lt;/svg&gt;\n</code></pre>"},{"location":"WEB/ud4/#usar-las-imagenes-de-spritessvg-en-mi-html","title":"USAR LAS IM\u00c1GENES DE SPRITES.SVG EN MI HTML","text":"<p>Por \u00faltimo, para usar dentro de nuestro HTML, cualquiera de las im\u00e1gnes SVG que almacenemos en nuestro fichero de sprites, solo tendremos que llamarla por el id que le hemos dado, con la etiqueta <code>&lt;use&gt;</code>:</p> <p>Vista Previa</p> <p> </p> <pre><code>    &lt;!-- EJEMPLO DE USO ICONO GOOGLE MAPS\n         DESDE UN FICHERO DE SPRITES --&gt;\n    &lt;svg width=\"80\"&gt;\n       &lt;use xlink:href=\"./sprites.svg#google-maps\"/&gt;\n    &lt;/svg&gt;\n</code></pre>"},{"location":"WEB/ud5/","title":"FRAMEWORKS CSS","text":"Logo Bootstrap Logo Tailwind"},{"location":"WEB/ud5/#bootstrap","title":"BOOTSTRAP","text":""},{"location":"WEB/ud5/#por-que-usar-bootstrap","title":"\u00bfPOR QUE USAR BOOTSTRAP?","text":"<p> VENTAJAS:</p> <p> INCONVENIENTES:</p>"},{"location":"WEB/ud5/#instalacionuso-bootstrap","title":"INSTALACI\u00d3N/USO BOOTSTRAP","text":"<p>Para usar Bootstrap podemos descargar los ficheros necesarios localmente desde el enlace oficial; o directamente enlazar nuestros HTML con los repositorios en la nube, a\u00f1adiendo las siguientes lineas:</p> <p>En el <code>HEAD</code> de nuestra p\u00e1gina a\u00f1adimos:</p> <pre><code>&lt;link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/css/bootstrap.min.css\" rel=\"stylesheet\" integrity=\"sha384-sRIl4kxILFvY47J16cr9ZwB07vP4J8+LH7qKQnuqkuIAvNWLzeN8tE5YBujZqJLB\" crossorigin=\"anonymous\"&gt;\n</code></pre> <p>Y al final del <code>BODY</code> a\u00f1adimos:</p> <pre><code>&lt;script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/js/bootstrap.bundle.min.js\" integrity=\"sha384-FKyoEForCGlyvwx9Hj09JcYn3nv7wiPVlz7YYwJrWVcXK/BmnVDxM+D2scQbITxI\" crossorigin=\"anonymous\"&gt;&lt;/script&gt;\n</code></pre> <p>Junto a este \u00faltimo script podemos icluir los de Popper y JavaScript. Pero solo si tenemos pensado utilizar <code>dropdowns</code>, <code>popovers</code> o <code>tooltips</code>; en caso contrario mejor ahorrarnos esos kilobytes de carga en nuestro c\u00f3digo:</p> <pre><code>&lt;script src=\"https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/umd/popper.min.js\" integrity=\"sha384-I7E8VVD/ismYTF4hNIPjVp/Zjvgyol6VFvRkX/vR+Vc4jQkC+hVqc2pM8ODewa9r\" crossorigin=\"anonymous\"&gt;&lt;/script&gt;\n&lt;script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/js/bootstrap.min.js\" integrity=\"sha384-G/EV+4j2dNv+tEPo3++6LCgdCROaejBqfUeNjuKAiuXbjrxilcCdDz6ZAVfHWe1Y\" crossorigin=\"anonymous\"&gt;&lt;/script&gt;\n</code></pre>"},{"location":"WEB/ud5/#contenedores-bootstrap","title":"CONTENEDORES BOOTSTRAP","text":"<p>Bootstrap ofrece 2 tipos de contenedores:</p> <ul> <li> <p><code>container</code>: deja unos m\u00e1rgenes a izquierda y derecha, proporcionales al tama\u00f1o de pantalla, de modo que siempre se mantiene centrado.</p> <pre><code>&lt;body&gt;\n    &lt;div class=\"container\"&gt;\n    &lt;/div&gt;\n&lt;/body&gt;\n</code></pre> </li> <li> <p><code>container-fluid</code>: ocupa el 100% de lo que podemos ver en el navegador (viewport).</p> <pre><code>&lt;body&gt;\n    &lt;div class=\"container-fluid\"&gt;\n    &lt;/div&gt;\n&lt;/body&gt;\n</code></pre> </li> </ul>"},{"location":"WEB/ud5/#grid-bootstrap","title":"GRID BOOTSTRAP","text":"<p>A partir de l a versi\u00f3n 4, Bootstrap esta basado en Flexbox y es completamente responsivo.</p>"},{"location":"WEB/ud5/#filas","title":"FILAS","text":"<p>Por lo tanto, teniendo en cuenta que es poco com\u00fan encontrar p\u00e1ginas con layouts tan complejos como para necesitar m\u00e1s de un contenedor, la estructura general que va a seguir un layout hecho con Bootstrap, consistir\u00e1 en una rejilla (grid) compuesta por varias filas y dentro de cada fila podemos definir hasta 12 columnas.</p> <pre><code>&lt;body&gt;\n    &lt;div class=\"container\"&gt;\n        &lt;div class=\"row\"&gt;&lt;/div&gt;\n        &lt;div class=\"row\"&gt;&lt;/div&gt;\n    &lt;/div&gt;\n&lt;/body&gt;\n</code></pre>"},{"location":"WEB/ud5/#columnas","title":"COLUMNAS","text":"<p>A la hora de definir columnas, podemos indicar el ancho que van a ocupar o que tengan un ancho autom\u00e1tico.</p> <p>Para el primer caso, existen las clases desde <code>col-1</code> hasta <code>col-12</code>, que lo que van a hacer es crear una columna cuyo ancho abarque el numero especificado en el nombre de la clase. Es decir, si hemos dicho que por defecto en Bootstrap el viewport se divide en 12 columnas, si queremos crear una columna que ocupe la mitad de la pantalla, usaremos la clase <code>col-6</code>.</p> <pre><code>&lt;body&gt;\n    &lt;div class=\"container\"&gt;\n        &lt;div class=\"row\"&gt;\n            &lt;div class=\"col-6\"&gt;&lt;/div&gt;\n            &lt;div class=\"col-3\"&gt;&lt;/div&gt;\n            &lt;div class=\"col-3\"&gt;&lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/body&gt;\n</code></pre> <p>Por otro lado, para definir columnas de ancho autom\u00e1tico existe la clase <code>col</code>. En este caso, el ancho de las columnas creadas se definir\u00e1 distribuyendo a partes iguales el ancho total del viewport, entre la cantidad de columnas que tenga esa fila.</p> <pre><code>&lt;body&gt;\n    &lt;div class=\"container\"&gt;\n        &lt;div class=\"row\"&gt;\n            &lt;div class=\"col\"&gt;&lt;/div&gt;\n            &lt;div class=\"col\"&gt;&lt;/div&gt;\n            &lt;div class=\"col\"&gt;&lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/body&gt;\n</code></pre> <p>Adem\u00e1s, hay que tener en cuenta que cada columna que definamos, tendr\u00e1 un padding por defecto a izquierda y derecha de 15px, llamado <code>GUTTER</code>, que podremos personalizar.</p>"},{"location":"WEB/ud5/#breakpoints-bootstrap","title":"BREAKPOINTS BOOTSTRAP","text":"<p>Como ya hemos visto en unidades anteriores hablando del dise\u00f1o responsivo, un breakpoint es un tama\u00f1o de pantalla (en pixels) donde se produce un cambio en la disposici\u00f3n de los elementos de una p\u00e1gina web.</p> <p>En el caso de Bootstrap, se basa en 4 breakpoints definidos por Twitter (actualmente X), que son en 576px, en 768px, en 992px y en  1200px.</p> <p>Con estos 4 breakpoints podemos diferenciar entre 5 tipos de pantallas:</p> <ul> <li> : Entre 0 y 576px : <code>col-1</code>...<code>col-12</code></li> <li> : Entre 576px y 768px : <code>col-sm-1</code>...<code>col-sm-12</code></li> <li> : Entre 768px y 992px : <code>col-md-1</code>...<code>col-md-12</code></li> <li> : Entre 993px y 1200px : <code>col-lg-1</code>...<code>col-lg-12</code></li> <li> : A partir de 1200px : <code>col-xl-1</code>...<code>col-xl-12</code></li> </ul> <p>En la lista anterior, tambi\u00e9n vemos que existen clases para definir columnas basandose en estos breakpoints. Es decir, que dependiendo del ancho que tenga la pantalla se muestre una cantidad de columnas u otra. Por ejemplo:</p> <pre><code>&lt;body&gt;\n    &lt;div class=\"container\"&gt;\n        &lt;div class=\"row\"&gt;\n            &lt;div class=\"col-sm-6 col-md-4 col-lg-2\"&gt;&lt;/div&gt;\n            &lt;div class=\"col-sm-6 col-md-4 col-lg-2\"&gt;&lt;/div&gt;\n            &lt;div class=\"col-sm-6 col-md-4 col-lg-2\"&gt;&lt;/div&gt;\n            &lt;div class=\"col-sm-6 col-md-4 col-lg-2\"&gt;&lt;/div&gt;\n            &lt;div class=\"col-sm-6 col-md-4 col-lg-2\"&gt;&lt;/div&gt;\n            &lt;div class=\"col-sm-6 col-md-4 col-lg-2\"&gt;&lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/body&gt;\n</code></pre> <p>Esta opci\u00f3n tambien es compatible con definici\u00f3n de columnas de ancho autom\u00e1tico, a\u00f1adiendo a la clase \"col\" el tama\u00f1o breakpoint donde lo queramos aplicar, por ejemplo, <code>col-md</code>. Usando este tipo de clases, ser\u00eda posible definir m\u00e1s de 12 columnas en una fila, aunque no se me ocurren ejemplos en los que sea preferible o necesario el uso de m\u00e1s de 12 elementos en una fila.</p> <p>Por otro lado, siempre podemos forzar un salto de l\u00ednea dentro de una fila con la clase <code>w-100</code>. Por ejemplo:</p> <pre><code>&lt;div class=\"row\" &gt;\n    &lt;div class=\"col\"&gt;&lt;/div&gt;\n    &lt;div class=\"col\"&gt;&lt;/div&gt;\n    &lt;div class=\"w-100\"&gt;&lt;/div&gt;   &lt;!--Salto de linea--&gt;\n    &lt;div class=\"col\" &gt;&lt;/div&gt;\n&lt;/div&gt;\n</code></pre>"},{"location":"WEB/ud5/#personalizacion-de-columnas","title":"PERSONALIZACI\u00d3N DE COLUMNAS","text":"<p>Dentro de la definici\u00f3n de columnas dentro de las filas de nuestra rejilla Bootstrap, existen varios par\u00e1metros que podemos configurar para personalizar la ubicaci\u00f3n de estas:</p>"},{"location":"WEB/ud5/#desplazamiento","title":"DESPLAZAMIENTO","text":""},{"location":"WEB/ud5/#alineamiento","title":"ALINEAMIENTO","text":""},{"location":"WEB/ud5/#ordenacion","title":"ORDENACI\u00d3N","text":""},{"location":"WEB/ud5/#margenes","title":"M\u00c1RGENES","text":""},{"location":"WEB/ud5/#contenido","title":"CONTENIDO","text":"<p>En este apartado vamos a ver algunos ejemplos de como insertar los contenidos m\u00e1s comunes en una p\u00e1gina web, para ampliar la informaci\u00f3n sobre su uso y el resto de contenidos, consultar la documentaci\u00f3n oficial.</p>"},{"location":"WEB/ud5/#textos","title":"TEXTOS","text":""},{"location":"WEB/ud5/#imagenes","title":"IM\u00c1GENES","text":""},{"location":"WEB/ud5/#figuras","title":"FIGURAS","text":""},{"location":"WEB/ud5/#formularios","title":"FORMULARIOS","text":"<p>Bootstrap nos ofrece una serie de componentes de formulario preestilizados, de los que podemos consultar ejemplos y pautas de uso en la documentaci\u00f3n oficial del framework. Los principales son:</p>"},{"location":"WEB/ud5/#form-control","title":"FORM CONTROL","text":"<p><code>form-control</code>, <code>form-label</code>, <code>form-control-color</code>, <code>col-form-label</code>, <code>visually-hidden</code></p>"},{"location":"WEB/ud5/#selects","title":"SELECTS","text":"<p><code>form-select</code></p>"},{"location":"WEB/ud5/#checks-radios","title":"CHECKS &amp; RADIOS","text":"<p><code>form-check</code>, <code>form-check-input</code>, <code>form-check-label</code>, <code>form-switch</code>, <code>form-btn</code>, <code>form-check-inline</code>, <code>form-check-reverse</code></p>"},{"location":"WEB/ud5/#range","title":"RANGE","text":"<p><code>form-range</code></p>"},{"location":"WEB/ud5/#validation","title":"VALIDATION","text":"<p><code>needs-validation</code>, <code>valid-feedback</code>, <code>invalid-feedback</code>, <code>is-invalid</code>, <code>was-validated</code>, <code>valid-tooltip</code>, <code>invalid-tooltip</code></p>"},{"location":"WEB/ud5/#componentes","title":"COMPONENTES","text":"<p>A continuaci\u00f3n veremos ejemplos de algunos de los componentes predefinidos que proporciona Bootstrap, para m\u00e1s informaci\u00f3n sobre su uso y el de otros componentes, consultar la documentaci\u00f3n oficial.</p>"},{"location":"WEB/ud5/#botones","title":"BOTONES","text":""},{"location":"WEB/ud5/#tarjetas","title":"TARJETAS","text":""},{"location":"WEB/ud5/#modales","title":"MODALES","text":""},{"location":"WEB/ud5/#navbar","title":"NAVBAR","text":""},{"location":"WEB/ud5/#tailwind","title":"TAILWIND","text":""},{"location":"WEB/ud5/#por-que-usar-tailwind","title":"\u00bfPOR QUE USAR TAILWIND?","text":"<p>Tailwind es un framework algo especial debido a que est\u00e1 orientado a utilidades. Esto quiere decir que proporciona clases de bajo nivel, que en lugar de definir elementos HTML preestilizados (div, btn, row, column...), definen un estilo CSS concreto o utilidad (bg-red, text-center, rounded, gap, pt, size...). Permiti\u00e9ndonos crear cualquier dise\u00f1o directamente desde nuestro HTML.</p> <p> VENTAJAS:</p> <ul> <li> <p>Altamente personalizable, gracias a las clases utility first</p> </li> <li> <p>Configuraci\u00f3n centralizada y velocidad de desarrollo</p> </li> <li> <p>Compilador que reduce el CSS resulante, solo con las clases utilizadas (Just-In-Time)</p> </li> <li> <p>Numerosos plugins, amplia documentaci\u00f3n y soporte de la comunidad</p> </li> </ul> <p> INCONVENIENTES:</p> <ul> <li> <p>Puede acabar generando demasiado ruido (sobrecargado) en el HTML y que resulte complejo de leer</p> </li> <li> <p>Mantener y depurar las clases utilizadas puede ser engorroso en ocasiones</p> </li> <li> <p>Curva de aprendizaje larga al principio, para aquellos que vienen de CSS tradicional</p> </li> </ul>"},{"location":"WEB/ud5/#instalacionuso-tailwind","title":"INSTALACI\u00d3N/USO TAILWIND","text":""},{"location":"WEB/ud5/#desarrollo","title":"DESARROLLO","text":"<p>Para usarlo en entornos de desarrollo, la forma m\u00e1s r\u00e1pida de empezar a usar Tailwind es a\u00f1adiendo su enlace CDN (Red de Entrega de Contenido) al <code>&lt;head&gt;</code> de nuestro HTML:</p> <pre><code>&lt;script src=\"https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4\"&gt;&lt;/script&gt;\n</code></pre>"},{"location":"WEB/ud5/#produccion","title":"PRODUCCI\u00d3N","text":"<p>Sin embargo, esta opci\u00f3n no es v\u00e1lida para entornos de producci\u00f3n. Para estos casos, la forma m\u00e1s sencilla y r\u00e1pida de empezar a usar Tailwind es con la herramienta CLI de Tailwind. Podemos instalarla mediante el gestor de paquetes de Node.js con el comando:</p> <pre><code>npm install tailwindcss @tailwindcss/cli\n</code></pre> <p>Luego importaremos Tailwind en nuestro fichero CSS principal (en este ejemplo llamado input.css):</p> <pre><code>@import \"tailwindcss\";\n</code></pre> <p>Arrancamos el proceso de compilaci\u00f3n con la opci\u00f3n de que se mantenga a la escucha de cambios. Lo cual va a ir generando un CSS reducido en base a las clases que estemos usando (en este ejemplo llamado output.css):</p> <pre><code>npx @tailwindcss/cli -i ./src/input.css -o ./src/output.css --watch\n</code></pre> <p>Por \u00fatlimo, enlazamos el CSS compilado en el <code>&lt;head&gt;</code> de nuestro HTML y podemos comenzar a dar estilos con las clases Tailwind:</p> <pre><code>&lt;link href=\"./output.css\" rel=\"stylesheet\"&gt;\n</code></pre> <p>Opci\u00f3n sin Node.js</p> <p>La CLI de Tailwind tambi\u00e9n est\u00e1 disponible como ejecutable independiente si queremos usarla sin instalar Node.js.</p>"}]}